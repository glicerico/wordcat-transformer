{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate sentence probability with BERT\n",
    "## From https://github.com/huggingface/transformers/issues/37, with bugs fixed and updated to newest transformers version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "with torch.no_grad():\n",
    "    model = BertForMaskedLM.from_pretrained('bert-large-uncased')\n",
    "    model.eval()\n",
    "    # Load pre-trained model tokenizer (vocabulary)\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_predictions(probs, k=5):\n",
    "    probs = probs.detach().numpy()\n",
    "    top_indexes = np.argpartition(probs, -k)[-k:]\n",
    "    sorted_indexes = top_indexes[np.argsort(-probs[top_indexes])]\n",
    "    top_tokens = tokenizer.convert_ids_to_tokens(sorted_indexes)\n",
    "    print(f\"Ordered top predicted tokens: {top_tokens}\")\n",
    "    print(f\"Ordered top predicted values: {probs[sorted_indexes]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS_TOKEN = '[CLS]'\n",
    "EOS_TOKEN = '[SEP]'\n",
    "MASK_TOKEN = '[MASK]'\n",
    "\n",
    "def get_sentence_prob(sentence, verbose=False):\n",
    "    sm = torch.nn.Softmax(dim=0) # used to convert last hidden state to probs\n",
    "    \n",
    "    # Pre-process sentence, adding special tokens\n",
    "    tokenized_input = tokenizer.tokenize(sentence)\n",
    "    sent_len = len(tokenized_input)\n",
    "    if tokenized_input[0] != BOS_TOKEN:\n",
    "        tokenized_input.insert(0, BOS_TOKEN)\n",
    "    if tokenized_input[-1] != EOS_TOKEN:\n",
    "        tokenized_input.append(EOS_TOKEN)\n",
    "    ids_input = tokenizer.convert_tokens_to_ids(tokenized_input)\n",
    "    print(f\"Processing sentence: {tokenized_input}\")\n",
    "    #print(f\"Sentence ids: {ids_input}\")\n",
    "    \n",
    "    #sent_prob = 1\n",
    "    sum_lp = 0\n",
    "    # Mask non-special tokens and calculate their probabilities\n",
    "    for i in range(1,len(tokenized_input)-1): # Ignore first and last tokens\n",
    "        current_tokenized = tokenized_input[:]\n",
    "        current_tokenized[i] = MASK_TOKEN\n",
    "        if verbose: print(current_tokenized)\n",
    "        masked_input = torch.tensor([tokenizer.convert_tokens_to_ids(current_tokenized)])\n",
    "        outputs = model(masked_input)\n",
    "        predictions = outputs[0]\n",
    "        current_probs = sm(predictions[0, i]) # Softmax to get probabilities\n",
    "        current_prob = current_probs[ids_input[i]] # Prediction for masked word\n",
    "        #sent_prob *= current_prob\n",
    "        \n",
    "        sum_lp += np.log(current_prob.detach().numpy())\n",
    "        \n",
    "        print(f\"Word: {tokenized_input[i]} \\t Prob: {current_prob}\")\n",
    "        if verbose: print_top_predictions(current_probs)\n",
    "\n",
    "    #print(f\"\\nSentence probability: {sent_prob.item()}\\n\")\n",
    "    print(f\"\\nNormalized sentence prob: log(P(sentence)) / sent_length: {sum_lp / sent_len}\\n\")\n",
    "    return sum_lp / sent_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence: ['[CLS]', 'color', '##less', 'green', 'ideas', 'sleep', 'furiously', '.', '[SEP]']\n",
      "Word: color \t Prob: 0.07855580002069473\n",
      "Word: ##less \t Prob: 0.26501238346099854\n",
      "Word: green \t Prob: 0.007004397921264172\n",
      "Word: ideas \t Prob: 7.900826858531218e-06\n",
      "Word: sleep \t Prob: 4.1728594624146353e-07\n",
      "Word: furiously \t Prob: 0.00012131692346883938\n",
      "Word: . \t Prob: 0.9802482724189758\n",
      "\n",
      "Normalized sentence prob: log(P(sentence)) / sent_length: -6.329747859122498\n",
      "\n",
      "Processing sentence: ['[CLS]', 'genius', 'dumb', 'mirrors', 'eat', 'endless', '##ly', '.', '[SEP]']\n",
      "Word: genius \t Prob: 1.0253714322061569e-07\n",
      "Word: dumb \t Prob: 2.9548760949182906e-07\n",
      "Word: mirrors \t Prob: 0.0001510217844042927\n",
      "Word: eat \t Prob: 3.409974306123331e-05\n",
      "Word: endless \t Prob: 0.2609398365020752\n",
      "Word: ##ly \t Prob: 0.304989218711853\n",
      "Word: . \t Prob: 0.9387707710266113\n",
      "\n",
      "Normalized sentence prob: log(P(sentence)) / sent_length: -7.543730827314513\n",
      "\n",
      "Processing sentence: ['[CLS]', 'hair', '##less', 'ugly', 'men', 'complain', 'constantly', '.', '[SEP]']\n",
      "Word: hair \t Prob: 0.16870781779289246\n",
      "Word: ##less \t Prob: 0.5767462253570557\n",
      "Word: ugly \t Prob: 0.001009104773402214\n",
      "Word: men \t Prob: 0.41636860370635986\n",
      "Word: complain \t Prob: 0.0019120604265481234\n",
      "Word: constantly \t Prob: 0.12682481110095978\n",
      "Word: . \t Prob: 0.9834535717964172\n",
      "\n",
      "Normalized sentence prob: log(P(sentence)) / sent_length: -2.635146169524108\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-2.635146169524108"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentence_prob(\"Colorless green ideas sleep furiously.\")\n",
    "get_sentence_prob(\"Genius dumb mirrors eat endlessly.\")\n",
    "get_sentence_prob(\"Hairless ugly men complain constantly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence: ['[CLS]', 'the', 'test', 'was', 'a', 'success', '.', '[SEP]']\n",
      "Word: the \t Prob: 0.9590326547622681\n",
      "Word: test \t Prob: 0.006375086028128862\n",
      "Word: was \t Prob: 0.9607516527175903\n",
      "Word: a \t Prob: 0.9966248273849487\n",
      "Word: success \t Prob: 0.4098852872848511\n",
      "Word: . \t Prob: 0.9452541470527649\n",
      "\n",
      "Normalized sentence prob: log(P(sentence)) / sent_length: -1.0147979485336691\n",
      "\n",
      "Processing sentence: ['[CLS]', 'the', 'party', 'was', 'a', 'success', '.', '[SEP]']\n",
      "Word: the \t Prob: 0.9431305527687073\n",
      "Word: party \t Prob: 0.005764061585068703\n",
      "Word: was \t Prob: 0.9452731013298035\n",
      "Word: a \t Prob: 0.9702098369598389\n",
      "Word: success \t Prob: 0.40087464451789856\n",
      "Word: . \t Prob: 0.9529269337654114\n",
      "\n",
      "Normalized sentence prob: log(P(sentence)) / sent_length: -1.04391859130313\n",
      "\n",
      "Processing sentence: ['[CLS]', 'the', 'plan', 'was', 'a', 'success', '.', '[SEP]']\n",
      "Word: the \t Prob: 0.8995306491851807\n",
      "Word: plan \t Prob: 0.0032632441725581884\n",
      "Word: was \t Prob: 0.9528480172157288\n",
      "Word: a \t Prob: 0.9953371286392212\n",
      "Word: success \t Prob: 0.1864214837551117\n",
      "Word: . \t Prob: 0.9668962359428406\n",
      "\n",
      "Normalized sentence prob: log(P(sentence)) / sent_length: -1.2662163944138836\n",
      "\n",
      "Processing sentence: ['[CLS]', 'the', 'was', 'test', 'a', 'success', '.', '[SEP]']\n",
      "Word: the \t Prob: 0.00016744330059736967\n",
      "Word: was \t Prob: 0.000507477845530957\n",
      "Word: test \t Prob: 1.2884626130471588e-06\n",
      "Word: a \t Prob: 0.05625243857502937\n",
      "Word: success \t Prob: 0.004137144889682531\n",
      "Word: . \t Prob: 0.9286532998085022\n",
      "\n",
      "Normalized sentence prob: log(P(sentence)) / sent_length: -6.38044339666764\n",
      "\n",
      "Processing sentence: ['[CLS]', 'the', 'test', 'was', 'success', 'a', '.', '[SEP]']\n",
      "Word: the \t Prob: 0.7925955057144165\n",
      "Word: test \t Prob: 0.0014595912070944905\n",
      "Word: was \t Prob: 0.013523681089282036\n",
      "Word: success \t Prob: 2.3357206373475492e-05\n",
      "Word: a \t Prob: 8.80095103639178e-05\n",
      "Word: . \t Prob: 0.7495615482330322\n",
      "\n",
      "Normalized sentence prob: log(P(sentence)) / sent_length: -5.226048556466897\n",
      "\n",
      "Processing sentence: ['[CLS]', 'the', 'farewell', 'party', 'was', 'definitely', 'not', 'a', 'success', '.', '[SEP]']\n",
      "Word: the \t Prob: 0.8389569520950317\n",
      "Word: farewell \t Prob: 1.969956429093145e-05\n",
      "Word: party \t Prob: 0.0887012779712677\n",
      "Word: was \t Prob: 0.9911748170852661\n",
      "Word: definitely \t Prob: 0.022694334387779236\n",
      "Word: not \t Prob: 0.9847730398178101\n",
      "Word: a \t Prob: 0.997913658618927\n",
      "Word: success \t Prob: 0.08599837124347687\n",
      "Word: . \t Prob: 0.9771884679794312\n",
      "\n",
      "Normalized sentence prob: log(P(sentence)) / sent_length: -2.1912700758677803\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-2.1912700758677803"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentence_prob(\"The test was a success.\")\n",
    "get_sentence_prob(\"The party was a success.\")\n",
    "get_sentence_prob(\"The plan was a success.\")\n",
    "get_sentence_prob(\"The was test a success.\")\n",
    "get_sentence_prob(\"The test was success a.\")\n",
    "get_sentence_prob(\"The farewell party was definitely not a success.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence: ['[CLS]', 'he', 'answered', 'une', '##qui', '##vo', '##cal', '##ly', '.', '[SEP]']\n",
      "Word: he \t Prob: 0.2814375162124634\n",
      "Word: answered \t Prob: 0.006721243727952242\n",
      "Word: une \t Prob: 0.9973625540733337\n",
      "Word: ##qui \t Prob: 0.9999865293502808\n",
      "Word: ##vo \t Prob: 0.9999856948852539\n",
      "Word: ##cal \t Prob: 0.9999865293502808\n",
      "Word: ##ly \t Prob: 0.9979932308197021\n",
      "Word: . \t Prob: 0.9998167157173157\n",
      "\n",
      "Normalized sentence prob: log(P(sentence)) / sent_length: -0.784400124636818\n",
      "\n",
      "Processing sentence: ['[CLS]', 'he', 'answered', 'quickly', '.', '[SEP]']\n",
      "Word: he \t Prob: 0.2151750773191452\n",
      "Word: answered \t Prob: 0.026344342157244682\n",
      "Word: quickly \t Prob: 0.05330450460314751\n",
      "Word: . \t Prob: 0.9981406927108765\n",
      "\n",
      "Normalized sentence prob: log(P(sentence)) / sent_length: -2.0266001676791348\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-2.0266001676791348"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentence_prob(\"He answered unequivocally.\")\n",
    "get_sentence_prob(\"He answered quickly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence: ['[CLS]', 'the', 'guy', 'with', 'small', 'hands', 'demanded', 'a', 'qui', '##d', 'pro', 'quo', '.', '[SEP]']\n",
      "Word: the \t Prob: 0.6742717027664185\n",
      "Word: guy \t Prob: 0.006106184795498848\n",
      "Word: with \t Prob: 0.9959086179733276\n",
      "Word: small \t Prob: 0.001629635225981474\n",
      "Word: hands \t Prob: 0.20016466081142426\n",
      "Word: demanded \t Prob: 0.03818148002028465\n",
      "Word: a \t Prob: 0.5014763474464417\n",
      "Word: qui \t Prob: 0.9985383749008179\n",
      "Word: ##d \t Prob: 0.9992328882217407\n",
      "Word: pro \t Prob: 0.9958876967430115\n",
      "Word: quo \t Prob: 0.9983682036399841\n",
      "Word: . \t Prob: 0.9850805401802063\n",
      "\n",
      "Normalized sentence prob: log(P(sentence)) / sent_length: -1.4586090460895018\n",
      "\n",
      "Processing sentence: ['[CLS]', 'the', 'guy', 'with', 'small', 'hands', 'demanded', 'an', 'exchange', '.', '[SEP]']\n",
      "Word: the \t Prob: 0.6960532069206238\n",
      "Word: guy \t Prob: 0.002731535118073225\n",
      "Word: with \t Prob: 0.9953562617301941\n",
      "Word: small \t Prob: 0.001821734826080501\n",
      "Word: hands \t Prob: 0.21409577131271362\n",
      "Word: demanded \t Prob: 0.21094851195812225\n",
      "Word: an \t Prob: 0.8602176904678345\n",
      "Word: exchange \t Prob: 0.0040652137249708176\n",
      "Word: . \t Prob: 0.9960935711860657\n",
      "\n",
      "Normalized sentence prob: log(P(sentence)) / sent_length: -2.3705652872514396\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-2.3705652872514396"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentence_prob(\"The guy with small hands demanded a quid pro quo.\")\n",
    "get_sentence_prob(\"The guy with small hands demanded an exchange.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence: ['[CLS]', 'this', 'is', 'a', 'sentence', '.', '[SEP]']\n",
      "Word: this \t Prob: 0.060409143567085266\n",
      "Word: is \t Prob: 0.71123206615448\n",
      "Word: a \t Prob: 0.3749244213104248\n",
      "Word: sentence \t Prob: 0.00016662826237734407\n",
      "Word: . \t Prob: 0.966092050075531\n",
      "\n",
      "Normalized sentence prob: log(P(sentence)) / sent_length: -2.572528720647097\n",
      "\n",
      "Processing sentence: ['[CLS]', 'this', 'is', 'a', 'mac', '##ram', '##e', '.', '[SEP]']\n",
      "Word: this \t Prob: 0.055456843227148056\n",
      "Word: is \t Prob: 0.8841150999069214\n",
      "Word: a \t Prob: 0.35453030467033386\n",
      "Word: mac \t Prob: 0.04465892165899277\n",
      "Word: ##ram \t Prob: 0.19538208842277527\n",
      "Word: ##e \t Prob: 0.9994390606880188\n",
      "Word: . \t Prob: 0.9644730091094971\n",
      "\n",
      "Normalized sentence prob: log(P(sentence)) / sent_length: -1.2615019382376755\n",
      "\n",
      "Processing sentence: ['[CLS]', 'this', 'is', 'a', 'joke', '.', '[SEP]']\n",
      "Word: this \t Prob: 0.9431005716323853\n",
      "Word: is \t Prob: 0.5840965509414673\n",
      "Word: a \t Prob: 0.6737552881240845\n",
      "Word: joke \t Prob: 0.018048686906695366\n",
      "Word: . \t Prob: 0.9846997857093811\n",
      "\n",
      "Normalized sentence prob: log(P(sentence)) / sent_length: -1.0042520724236965\n",
      "\n",
      "Processing sentence: ['[CLS]', 'are', 'you', 'kidding', '.', '[SEP]']\n",
      "Word: are \t Prob: 0.9994117021560669\n",
      "Word: you \t Prob: 0.9883422255516052\n",
      "Word: kidding \t Prob: 0.04795767739415169\n",
      "Word: . \t Prob: 6.15520207247755e-07\n",
      "\n",
      "Normalized sentence prob: log(P(sentence)) / sent_length: -4.337637407676084\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-4.337637407676084"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentence_prob(\"This is a sentence.\")\n",
    "get_sentence_prob(\"This is a macrame.\", verbose=False)\n",
    "get_sentence_prob(\"This is a joke.\", verbose=False)\n",
    "get_sentence_prob(\"Are you kidding.\", verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence: ['[CLS]', 'rachel', 'was', 'wearing', 'a', 'lovely', 'satin', 'dress', 'last', 'night', '.', '[SEP]']\n",
      "Word: rachel \t Prob: 0.0008810244617052376\n",
      "Word: was \t Prob: 0.9967688322067261\n",
      "Word: wearing \t Prob: 0.9564428329467773\n",
      "Word: a \t Prob: 0.9443942904472351\n",
      "Word: lovely \t Prob: 0.00043303932761773467\n",
      "Word: satin \t Prob: 0.002335268072783947\n",
      "Word: dress \t Prob: 0.3856201171875\n",
      "Word: last \t Prob: 0.013361506164073944\n",
      "Word: night \t Prob: 0.9468490481376648\n",
      "Word: . \t Prob: 0.9899153709411621\n",
      "\n",
      "Normalized sentence prob: log(P(sentence)) / sent_length: -2.6276748973177746\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-2.6276748973177746"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentence_prob(\"Rachel was wearing a lovely satin dress last night.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentence_prob(\"Rachel was wearing a lovely satin dress last night.\")\n",
    "get_sentence_prob(\"Grandma was wearing a lovely satin dress last night.\")\n",
    "get_sentence_prob(\"Mother was wearing a lovely satin dress last night.\")\n",
    "get_sentence_prob(\"She was wearing a lovely satin dress last night.\")\n",
    "get_sentence_prob(\"He was wearing a lovely satin dress last night.\")\n",
    "get_sentence_prob(\"I was wearing a lovely satin dress last night.\")\n",
    "get_sentence_prob(\"Angela was wearing a lovely satin dress last night.\")\n",
    "get_sentence_prob(\"Roberta was wearing a lovely satin dress last night.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence: ['[CLS]', 'the', 'man', 'ate', 'the', 'steak', '.', '[SEP]']\n",
      "Word: the \t Prob: 0.9430958032608032\n",
      "Word: man \t Prob: 0.15097321569919586\n",
      "Word: ate \t Prob: 0.11828337609767914\n",
      "Word: the \t Prob: 0.10330334305763245\n",
      "Word: steak \t Prob: 0.004455209709703922\n",
      "Word: . \t Prob: 0.9944341778755188\n",
      "\n",
      "Normalized sentence prob: log(P(sentence)) / sent_length: -1.9622100537332396\n",
      "\n",
      "Processing sentence: ['[CLS]', 'the', 'man', 'who', 'arrived', 'late', 'ate', 'the', 'steak', 'with', 'a', 'glass', 'of', 'wine', '.', '[SEP]']\n",
      "Word: the \t Prob: 0.9333303570747375\n",
      "Word: man \t Prob: 0.06445129215717316\n",
      "Word: who \t Prob: 0.9256716966629028\n",
      "Word: arrived \t Prob: 0.10185236483812332\n",
      "Word: late \t Prob: 0.003638619789853692\n",
      "Word: ate \t Prob: 0.15281958878040314\n",
      "Word: the \t Prob: 0.005081328563392162\n",
      "Word: steak \t Prob: 0.013520020060241222\n",
      "Word: with \t Prob: 0.37167930603027344\n",
      "Word: a \t Prob: 0.9855746030807495\n",
      "Word: glass \t Prob: 0.8360260725021362\n",
      "Word: of \t Prob: 0.9999445676803589\n",
      "Word: wine \t Prob: 0.5925145745277405\n",
      "Word: . \t Prob: 0.9916564226150513\n",
      "\n",
      "Normalized sentence prob: log(P(sentence)) / sent_length: -1.7119918778703973\n",
      "\n",
      "Processing sentence: ['[CLS]', 'the', 'steak', 'was', 'eaten', 'by', 'the', 'man', '.', '[SEP]']\n",
      "Word: the \t Prob: 0.8093088269233704\n",
      "Word: steak \t Prob: 0.00023209427308756858\n",
      "Word: was \t Prob: 0.9134219884872437\n",
      "Word: eaten \t Prob: 0.033210448920726776\n",
      "Word: by \t Prob: 0.9850094318389893\n",
      "Word: the \t Prob: 0.15505804121494293\n",
      "Word: man \t Prob: 0.0038277464918792248\n",
      "Word: . \t Prob: 0.9761257767677307\n",
      "\n",
      "Normalized sentence prob: log(P(sentence)) / sent_length: -2.4430116151925176\n",
      "\n",
      "Processing sentence: ['[CLS]', 'the', 'stake', 'ate', 'the', 'man', '.', '[SEP]']\n",
      "Word: the \t Prob: 0.850401759147644\n",
      "Word: stake \t Prob: 0.0001372832921333611\n",
      "Word: ate \t Prob: 0.0016624326817691326\n",
      "Word: the \t Prob: 0.592517614364624\n",
      "Word: man \t Prob: 0.0034936044830828905\n",
      "Word: . \t Prob: 0.9986978769302368\n",
      "\n",
      "Normalized sentence prob: log(P(sentence)) / sent_length: -3.6060804301135554\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-3.6060804301135554"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentence_prob(\"The man ate the steak.\")\n",
    "get_sentence_prob(\"The man who arrived late ate the steak with a glass of wine.\")\n",
    "get_sentence_prob(\"The steak was eaten by the man.\")\n",
    "get_sentence_prob(\"The stake ate the man.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence: ['[CLS]', 'he', 'was', 'born', 'in', 'berlin', '.', '[SEP]']\n",
      "Word: he \t Prob: 0.7967859506607056\n",
      "Word: was \t Prob: 0.9999992847442627\n",
      "Word: born \t Prob: 0.9977497458457947\n",
      "Word: in \t Prob: 0.9979470372200012\n",
      "Word: berlin \t Prob: 0.02355594001710415\n",
      "Word: . \t Prob: 0.9999347925186157\n",
      "\n",
      "Normalized sentence prob: log(P(sentence)) / sent_length: -0.6633200494943973\n",
      "\n",
      "Processing sentence: ['[CLS]', 'he', 'was', 'born', 'in', 'santiago', '.', '[SEP]']\n",
      "Word: he \t Prob: 0.7612152695655823\n",
      "Word: was \t Prob: 0.9999862909317017\n",
      "Word: born \t Prob: 0.9960402250289917\n",
      "Word: in \t Prob: 0.997549831867218\n",
      "Word: santiago \t Prob: 0.0008775214664638042\n",
      "Word: . \t Prob: 0.9998825788497925\n",
      "\n",
      "Normalized sentence prob: log(P(sentence)) / sent_length: -1.2196333849568266\n",
      "\n",
      "Processing sentence: ['[CLS]', 'he', 'was', 'born', 'in', 'france', '.', '[SEP]']\n",
      "Word: he \t Prob: 0.7930527329444885\n",
      "Word: was \t Prob: 0.9999958276748657\n",
      "Word: born \t Prob: 0.9916587471961975\n",
      "Word: in \t Prob: 0.9998917579650879\n",
      "Word: france \t Prob: 0.002677186392247677\n",
      "Word: . \t Prob: 0.9997918009757996\n",
      "\n",
      "Normalized sentence prob: log(P(sentence)) / sent_length: -1.0272585537861687\n",
      "\n",
      "Processing sentence: ['[CLS]', 'he', 'was', 'born', 'in', 'window', '.', '[SEP]']\n",
      "Word: he \t Prob: 0.6543523073196411\n",
      "Word: was \t Prob: 0.9999873638153076\n",
      "Word: born \t Prob: 8.784436067799106e-05\n",
      "Word: in \t Prob: 0.7220567464828491\n",
      "Word: window \t Prob: 1.4590033288186532e-06\n",
      "Word: . \t Prob: 0.9915589094161987\n",
      "\n",
      "Normalized sentence prob: log(P(sentence)) / sent_length: -3.922658653011846\n",
      "\n",
      "Processing sentence: ['[CLS]', 'he', 'was', 'born', 'in', 'was', '.', '[SEP]']\n",
      "Word: he \t Prob: 0.7139879465103149\n",
      "Word: was \t Prob: 0.999954104423523\n",
      "Word: born \t Prob: 0.002806838136166334\n",
      "Word: in \t Prob: 0.24731287360191345\n",
      "Word: was \t Prob: 1.7501730553703965e-06\n",
      "Word: . \t Prob: 0.9949527978897095\n",
      "\n",
      "Normalized sentence prob: log(P(sentence)) / sent_length: -3.478431378123787\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-3.478431378123787"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get_sentence_prob(\"I fed my cat some of it and he damn near passed out\")\n",
    "get_sentence_prob(\"He was born in Berlin.\")\n",
    "get_sentence_prob(\"He was born in Santiago.\")\n",
    "get_sentence_prob(\"He was born in France.\")\n",
    "get_sentence_prob(\"He was born in window.\")\n",
    "get_sentence_prob(\"He was born in was.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentence_prob(\"I fed my cat some of it and he damn near passed out.\")\n",
    "get_sentence_prob(\"I fed my dog some of it and he damn near passed out.\")\n",
    "get_sentence_prob(\"I fed my window some of it and he damn near passed out.\")\n",
    "get_sentence_prob(\"I fed my the some of it and he damn near passed out.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Should have similar/high probs\\n\")\n",
    "get_sentence_prob(\"I forgot to take my medicine.\")\n",
    "get_sentence_prob(\"I forgot to take my medicines.\")\n",
    "get_sentence_prob(\"I forgot to take my medication.\")\n",
    "get_sentence_prob(\"I forgot to take my pills.\")\n",
    "print(\"Should have low probs\\n\")\n",
    "get_sentence_prob(\"I forgot to take my turn.\")\n",
    "get_sentence_prob(\"I forgot to take my medical.\")\n",
    "get_sentence_prob(\"I forgot to take my medically.\")\n",
    "get_sentence_prob(\"I forgot to take my turned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model (weights)\n",
    "with torch.no_grad():\n",
    "    model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "    model.eval()\n",
    "    # Load pre-trained model tokenizer (vocabulary)\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_sentence_prob(\"I fed my cat some of it and he damn near passed out\")\n",
    "get_sentence_prob(\"He was born in Berlin.\")\n",
    "get_sentence_prob(\"He was born in Santiago.\")\n",
    "get_sentence_prob(\"He was born in France.\")\n",
    "get_sentence_prob(\"He was born in window.\")\n",
    "get_sentence_prob(\"He was born in was.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentence_prob(\"I fed my cat some of it and he damn near passed out.\")\n",
    "get_sentence_prob(\"I fed my dog some of it and he damn near passed out.\")\n",
    "get_sentence_prob(\"I fed my window some of it and he damn near passed out.\")\n",
    "get_sentence_prob(\"I fed my the some of it and he damn near passed out.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Should have similar/high probs\\n\")\n",
    "get_sentence_prob(\"I forgot to take my medicine.\")\n",
    "get_sentence_prob(\"I forgot to take my medicines.\")\n",
    "get_sentence_prob(\"I forgot to take my medication.\")\n",
    "get_sentence_prob(\"I forgot to take my pills.\")\n",
    "print(\"Should have low probs\\n\")\n",
    "get_sentence_prob(\"I forgot to take my turn.\")\n",
    "get_sentence_prob(\"I forgot to take my medical.\")\n",
    "get_sentence_prob(\"I forgot to take my medically.\")\n",
    "get_sentence_prob(\"I forgot to take my turned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:transformers]",
   "language": "python",
   "name": "conda-env-transformers-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
