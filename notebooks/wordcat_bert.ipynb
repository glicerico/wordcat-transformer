{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word category formation using BERT predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The idea is to generate word embeddings by:\n",
    "- Get a list of sentences\n",
    "- Mask a word in each sentence (repeat a sentence in the list if you want to mask different positions)\n",
    "- For each sentence, obtain the logit vector for the masked word from BERT's prediction (last hidden layer)\n",
    "- Cluster sentences logit vectors. The clusters should reflect words that fit together both syntactically and semantically.\n",
    "- Build each word category by finding the highest valued words in the vectors belonging to a cluster (perhaps by most common top words, all words above some threshold, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import numpy as np\n",
    "import torch\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose some simple sentences with masked adjectives and nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sentences = \"\"\"_ fat cat ate the mouse.\n",
    "The _ cat ate the mouse.\n",
    "The fat _ ate the mouse.\n",
    "The fat cat _ the mouse.\n",
    "The fat cat ate _ mouse.\n",
    "The fat cat ate the _.\n",
    "_ was wearing a lovely satin dress last night.\n",
    "She _ wearing a lovely satin dress last night.\n",
    "She was _ a lovely satin dress last night.\n",
    "She was wearing _ lovely satin dress last night.\n",
    "She was wearing a _ satin dress last night.\n",
    "She was wearing a lovely _ dress last night.\n",
    "She was wearing a lovely satin _ last night.\n",
    "She was wearing a lovely satin dress _ night.\n",
    "She was wearing a lovely satin dress last _.\n",
    "_ was receiving quite a hefty salary.\n",
    "He _ receiving quite a hefty salary.\n",
    "He was _ quite a hefty salary.\n",
    "He was receiving _ a hefty salary.\n",
    "He was receiving quite _ hefty salary.\n",
    "He was receiving quite a _ salary.\n",
    "He was receiving quite a hefty _.\n",
    "_ also bought a used sofa for his new apartment.\n",
    "He _ bought a used sofa for his new apartment.\n",
    "He also _ a used sofa for his new apartment.\n",
    "He also bought _ used sofa for his new apartment.\n",
    "He also bought a _ sofa for his new apartment.\n",
    "He also bought a used _ for his new apartment.\n",
    "He also bought a used sofa _ his new apartment.\n",
    "He also bought a used sofa for _ new apartment.\n",
    "He also bought a used sofa for his _ apartment.\n",
    "He also bought a used sofa for his new _.\n",
    "_ was born and grew up in Havana.\n",
    "I _ born and grew up in Havana.\n",
    "I was _ and grew up in Havana.\n",
    "I was born _ grew up in Havana.\n",
    "I was born and _ up in Havana.\n",
    "I was born and grew _ in Havana.\n",
    "I was born and grew up _ Havana.\n",
    "I was born and grew up in _.\n",
    "_ Beijing metropolitan area added more than a million people in the past decade.\n",
    "The _ metropolitan area added more than a million people in the past decade.\n",
    "The Beijing _ area added more than a million people in the past decade.\n",
    "The Beijing metropolitan _ added more than a million people in the past decade.\n",
    "The Beijing metropolitan area _ more than a million people in the past decade.\n",
    "The Beijing metropolitan area added _ than a million people in the past decade.\n",
    "The Beijing metropolitan area added more _ a million people in the past decade.\n",
    "The Beijing metropolitan area added more than _ million people in the past decade.\n",
    "The Beijing metropolitan area added more than a _ people in the past decade.\n",
    "The Beijing metropolitan area added more than a million _ in the past decade.\n",
    "The Beijing metropolitan area added more than a million people _ the past decade.\n",
    "The Beijing metropolitan area added more than a million people in _ past decade.\n",
    "The Beijing metropolitan area added more than a million people in the _ decade.\n",
    "The Beijing metropolitan area added more than a million people in the past _.\n",
    "_ races are held around the lake and farmlands.\n",
    "Bike _ are held around the lake and farmlands.\n",
    "Bike races _ held around the lake and farmlands.\n",
    "Bike races are _ around the lake and farmlands.\n",
    "Bike races are held _ the lake and farmlands.\n",
    "Bike races are held around _ lake and farmlands.\n",
    "Bike races are held around the _ and farmlands.\n",
    "Bike races are held around the lake _ farmlands.\n",
    "Bike races are held around the lake and _.\n",
    "_ racist cousin called me last night.\n",
    "My _ cousin called me last night.\n",
    "My racist _ called me last night.\n",
    "My racist cousin _ me last night.\n",
    "My racist cousin called _ last night.\n",
    "My racist cousin called me _ night.\n",
    "My racist cousin called me last _.\n",
    "_ device is considered to be available if it is not being used by another adult.\n",
    "A _ is considered to be available if it is not being used by another adult.\n",
    "A device _ considered to be available if it is not being used by another adult.\n",
    "A device is _ to be available if it is not being used by another adult.\n",
    "A device is considered _ be available if it is not being used by another adult.\n",
    "A device is considered to _ available if it is not being used by another adult.\n",
    "A device is considered to be _ if it is not being used by another adult.\n",
    "A device is considered to be available _ it is not being used by another adult.\n",
    "A device is considered to be available if _ is not being used by another adult.\n",
    "A device is considered to be available if it _ not being used by another adult.\n",
    "A device is considered to be available if it is _ being used by another adult.\n",
    "A device is considered to be available if it is not _ used by another adult.\n",
    "A device is considered to be available if it is not being _ by another adult.\n",
    "A device is considered to be available if it is not being used _ another adult.\n",
    "A device is considered to be available if it is not being used by _ adult.\n",
    "A device is considered to be available if it is not being used by another _.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process sentences with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place [MASK] tokens\n",
    "MASK = '[MASK]'\n",
    "sentences = re.sub(r'\\b_+\\b', '[MASK]', text_sentences).split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# tokenize input\n",
    "input_ids = [tokenizer.encode(s, add_special_tokens=True) for s in sentences]\n",
    "\n",
    "# Find location of MASKS\n",
    "tok_MASK = tokenizer.convert_tokens_to_ids(MASK)\n",
    "mask_positions = [s.index(tok_MASK) for s in input_ids] \n",
    "\n",
    "# Make all sentence arrays equal length by padding\n",
    "max_len = max(len(i) for i in input_ids)\n",
    "padded_input = np.array([i + [0]* (max_len - len(i)) for i in input_ids])\n",
    "\n",
    "attention_mask = np.where(padded_input != 0, 1, 0)  # Create mask to ignore padding\n",
    "\n",
    "input = torch.tensor(padded_input)\n",
    "attention_mask = torch.tensor(attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get hidden layers\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embeddings for the masked word of each sentence\n",
    "embeddings = [lh[m].numpy() for lh, m in zip(last_hidden_states[0], mask_positions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_predictions(probs, k=5, thres=0.01):\n",
    "    \"\"\"\n",
    "    Print and return top-k predictions for a given probs list.\n",
    "    Also return predictions above threshold\n",
    "    \"\"\"\n",
    "    # Get top-k tokens\n",
    "    probs = probs.detach().numpy()\n",
    "    top_indexes = np.argpartition(probs, -k)[-k:]\n",
    "    sorted_indexes = top_indexes[np.argsort(-probs[top_indexes])]\n",
    "    top_tokens = tokenizer.convert_ids_to_tokens(sorted_indexes)\n",
    "    print(f\"Ordered top predicted tokens: {top_tokens}\")\n",
    "    print(f\"Ordered top predicted values: {probs[sorted_indexes]}\\n\")\n",
    "    \n",
    "    # Get all tokens above threshold\n",
    "    high_indexes = np.where(probs > thres)\n",
    "    high_tokens = tokenizer.convert_ids_to_tokens(high_indexes[0])\n",
    "    return top_tokens, high_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert last layer logit predictions to probabilities\n",
    "We can see what are the highest predictions for the blank in each sentence, and their probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:\n",
      "[MASK] fat cat ate the mouse.\n",
      "Ordered top predicted tokens: ['the', 'a', 'that', 'my', 'his']\n",
      "Ordered top predicted values: [0.9451467  0.03199202 0.00576943 0.00449885 0.00188601]\n",
      "\n",
      "Sentence:\n",
      "The [MASK] cat ate the mouse.\n",
      "Ordered top predicted tokens: ['black', 'cheshire', 'big', 'little', 'fat']\n",
      "Ordered top predicted values: [0.13267049 0.08640933 0.06516975 0.03538685 0.03100599]\n",
      "\n",
      "Sentence:\n",
      "The fat [MASK] ate the mouse.\n",
      "Ordered top predicted tokens: ['man', 'cat', 'rat', 'dog', 'mouse']\n",
      "Ordered top predicted values: [0.318098   0.13372828 0.05779354 0.05538516 0.04909774]\n",
      "\n",
      "Sentence:\n",
      "The fat cat [MASK] the mouse.\n",
      "Ordered top predicted tokens: ['.', 'and', ',', 'or', ';']\n",
      "Ordered top predicted values: [0.5628975  0.32685623 0.05045042 0.00994903 0.0039914 ]\n",
      "\n",
      "Sentence:\n",
      "The fat cat ate [MASK] mouse.\n",
      "Ordered top predicted tokens: ['the', 'a', 'my', 'his', 'her']\n",
      "Ordered top predicted values: [0.74722546 0.17293347 0.02507927 0.01785319 0.01100375]\n",
      "\n",
      "Sentence:\n",
      "The fat cat ate the [MASK].\n",
      "Ordered top predicted tokens: ['cat', 'dog', 'fish', 'mouse', 'rabbit']\n",
      "Ordered top predicted values: [0.08816774 0.05007546 0.02719888 0.02323546 0.01906023]\n",
      "\n",
      "Sentence:\n",
      "[MASK] was wearing a lovely satin dress last night.\n",
      "Ordered top predicted tokens: ['she', 'i', 'he', 'mom', 'rachel']\n",
      "Ordered top predicted values: [8.6794078e-01 5.9024639e-02 9.1355704e-03 9.4336300e-04 7.9108187e-04]\n",
      "\n",
      "Sentence:\n",
      "She [MASK] wearing a lovely satin dress last night.\n",
      "Ordered top predicted tokens: ['was', 'remembered', 'is', 'started', 'came']\n",
      "Ordered top predicted values: [9.9300015e-01 1.5500017e-03 1.1397203e-03 3.1307980e-04 3.0609168e-04]\n",
      "\n",
      "Sentence:\n",
      "She was [MASK] a lovely satin dress last night.\n",
      "Ordered top predicted tokens: ['wearing', 'in', 'sporting', 'given', 'holding']\n",
      "Ordered top predicted values: [9.3784040e-01 5.9583347e-02 4.6118992e-04 2.7536048e-04 2.4864008e-04]\n",
      "\n",
      "Sentence:\n",
      "She was wearing [MASK] lovely satin dress last night.\n",
      "Ordered top predicted tokens: ['a', 'that', 'this', 'her', 'the']\n",
      "Ordered top predicted values: [0.9103036  0.04379193 0.02698831 0.00567588 0.00541728]\n",
      "\n",
      "Sentence:\n",
      "She was wearing a [MASK] satin dress last night.\n",
      "Ordered top predicted tokens: ['white', 'black', 'red', 'pink', 'blue']\n",
      "Ordered top predicted values: [0.2137275  0.17099911 0.15223213 0.10065077 0.08298444]\n",
      "\n",
      "Sentence:\n",
      "She was wearing a lovely [MASK] dress last night.\n",
      "Ordered top predicted tokens: ['white', 'black', 'red', 'pink', 'blue']\n",
      "Ordered top predicted values: [0.20945124 0.16496556 0.13129269 0.08869011 0.05542691]\n",
      "\n",
      "Sentence:\n",
      "She was wearing a lovely satin [MASK] last night.\n",
      "Ordered top predicted tokens: ['dress', 'gown', 'robe', 'outfit', 'skirt']\n",
      "Ordered top predicted values: [0.5891389  0.2869085  0.05737393 0.00814749 0.00740931]\n",
      "\n",
      "Sentence:\n",
      "She was wearing a lovely satin dress [MASK] night.\n",
      "Ordered top predicted tokens: ['that', 'at', 'last', 'all', 'this']\n",
      "Ordered top predicted values: [0.8625142  0.04993699 0.03795301 0.02136831 0.00511164]\n",
      "\n",
      "Sentence:\n",
      "She was wearing a lovely satin dress last [MASK].\n",
      "Ordered top predicted tokens: ['night', 'week', 'time', 'evening', 'year']\n",
      "Ordered top predicted values: [0.9323713  0.01501213 0.01464472 0.01272894 0.00536616]\n",
      "\n",
      "Sentence:\n",
      "[MASK] was receiving quite a hefty salary.\n",
      "Ordered top predicted tokens: ['he', 'she', 'i', 'they', 'jack']\n",
      "Ordered top predicted values: [0.49830726 0.22909752 0.07788146 0.00247537 0.0016114 ]\n",
      "\n",
      "Sentence:\n",
      "He [MASK] receiving quite a hefty salary.\n",
      "Ordered top predicted tokens: ['was', 'is', 'began', 'started', 'reported']\n",
      "Ordered top predicted values: [0.9746323  0.01355517 0.00235867 0.00142978 0.00103251]\n",
      "\n",
      "Sentence:\n",
      "He was [MASK] quite a hefty salary.\n",
      "Ordered top predicted tokens: ['paid', 'paying', 'earning', 'receiving', 'getting']\n",
      "Ordered top predicted values: [0.24649604 0.21718043 0.10727409 0.07074019 0.06329449]\n",
      "\n",
      "Sentence:\n",
      "He was receiving [MASK] a hefty salary.\n",
      "Ordered top predicted tokens: ['only', 'quite', 'almost', 'about', 'such']\n",
      "Ordered top predicted values: [0.34561858 0.13524179 0.06833335 0.05970965 0.02801461]\n",
      "\n",
      "Sentence:\n",
      "He was receiving quite [MASK] hefty salary.\n",
      "Ordered top predicted tokens: ['a', 'the', 'his', 'another', 'some']\n",
      "Ordered top predicted values: [9.9120986e-01 6.7637521e-03 9.6797192e-04 3.9347459e-04 1.5436264e-04]\n",
      "\n",
      "Sentence:\n",
      "He was receiving quite a [MASK] salary.\n",
      "Ordered top predicted tokens: ['good', 'handsome', 'high', 'generous', 'decent']\n",
      "Ordered top predicted values: [0.18829058 0.09613485 0.09576207 0.0917473  0.0544567 ]\n",
      "\n",
      "Sentence:\n",
      "He was receiving quite a hefty [MASK].\n",
      "Ordered top predicted tokens: ['tip', 'salary', 'bonus', 'reward', 'payment']\n",
      "Ordered top predicted values: [0.09087707 0.09000216 0.0860626  0.05597968 0.0379158 ]\n",
      "\n",
      "Sentence:\n",
      "[MASK] also bought a used sofa for his new apartment.\n",
      "Ordered top predicted tokens: ['he', 'they', 'she', 'i', 'we']\n",
      "Ordered top predicted values: [0.8476094  0.02660317 0.02044333 0.00572221 0.00224113]\n",
      "\n",
      "Sentence:\n",
      "He [MASK] bought a used sofa for his new apartment.\n",
      "Ordered top predicted tokens: ['had', 'also', 'even', 'then', 'has']\n",
      "Ordered top predicted values: [0.5760932  0.27618936 0.08598793 0.01154122 0.00804081]\n",
      "\n",
      "Sentence:\n",
      "He also [MASK] a used sofa for his new apartment.\n",
      "Ordered top predicted tokens: ['bought', 'purchased', 'built', 'donated', 'acquired']\n",
      "Ordered top predicted values: [0.21444675 0.18907939 0.09320132 0.04516202 0.03490899]\n",
      "\n",
      "Sentence:\n",
      "He also bought [MASK] used sofa for his new apartment.\n",
      "Ordered top predicted tokens: ['a', 'the', 'another', 'his', 'one']\n",
      "Ordered top predicted values: [9.7882962e-01 1.6272021e-02 1.3320646e-03 8.7696873e-04 7.4139080e-04]\n",
      "\n",
      "Sentence:\n",
      "He also bought a [MASK] sofa for his new apartment.\n",
      "Ordered top predicted tokens: ['new', 'comfortable', 'luxurious', 'large', 'luxury']\n",
      "Ordered top predicted values: [0.6247967  0.05839209 0.02877485 0.0248212  0.01501671]\n",
      "\n",
      "Sentence:\n",
      "He also bought a used [MASK] for his new apartment.\n",
      "Ordered top predicted tokens: ['car', 'mattress', 'room', 'garage', 'piano']\n",
      "Ordered top predicted values: [0.1737774  0.04123747 0.03930406 0.03768738 0.03624529]\n",
      "\n",
      "Sentence:\n",
      "He also bought a used sofa [MASK] his new apartment.\n",
      "Ordered top predicted tokens: ['for', 'in', 'at', 'from', 'near']\n",
      "Ordered top predicted values: [0.7536453  0.20951778 0.02005241 0.0108633  0.00110122]\n",
      "\n",
      "Sentence:\n",
      "He also bought a used sofa for [MASK] new apartment.\n",
      "Ordered top predicted tokens: ['his', 'the', 'their', 'a', 'her']\n",
      "Ordered top predicted values: [0.6675286  0.21705402 0.05393533 0.04698005 0.00678181]\n",
      "\n",
      "Sentence:\n",
      "He also bought a used sofa for his [MASK] apartment.\n",
      "Ordered top predicted tokens: ['new', 'own', 'london', 'manhattan', 'second']\n",
      "Ordered top predicted values: [0.46736577 0.13679208 0.02956074 0.02135551 0.00970083]\n",
      "\n",
      "Sentence:\n",
      "He also bought a used sofa for his new [MASK].\n",
      "Ordered top predicted tokens: ['apartment', 'home', 'house', 'wife', 'club']\n",
      "Ordered top predicted values: [0.14949663 0.09815061 0.05985351 0.05535661 0.02990979]\n",
      "\n",
      "Sentence:\n",
      "[MASK] was born and grew up in Havana.\n",
      "Ordered top predicted tokens: ['he', 'she', 'rodriguez', 'gonzalez', 'castro']\n",
      "Ordered top predicted values: [0.33532813 0.06240913 0.02653962 0.02547684 0.02248553]\n",
      "\n",
      "Sentence:\n",
      "I [MASK] born and grew up in Havana.\n",
      "Ordered top predicted tokens: ['was', 'am', '##was', 'were', 'been']\n",
      "Ordered top predicted values: [9.9929535e-01 1.9821023e-04 1.0388579e-04 7.6706798e-05 3.6440259e-05]\n",
      "\n",
      "Sentence:\n",
      "I was [MASK] and grew up in Havana.\n",
      "Ordered top predicted tokens: ['born', 'jewish', 'spanish', 'adopted', 'young']\n",
      "Ordered top predicted values: [0.7711361  0.04727779 0.00564388 0.00553638 0.00543874]\n",
      "\n",
      "Sentence:\n",
      "I was born [MASK] grew up in Havana.\n",
      "Ordered top predicted tokens: ['and', 'but', 'or', ',', '&']\n",
      "Ordered top predicted values: [9.9316227e-01 3.5432018e-03 1.4482576e-03 8.1454322e-04 2.9375308e-04]\n",
      "\n",
      "Sentence:\n",
      "I was born and [MASK] up in Havana.\n",
      "Ordered top predicted tokens: ['grew', 'brought', 'growing', 'grown', 'raised']\n",
      "Ordered top predicted values: [0.8734867  0.11734151 0.00250741 0.00235818 0.00203098]\n",
      "\n",
      "Sentence:\n",
      "I was born and grew [MASK] in Havana.\n",
      "Ordered top predicted tokens: ['up', '##up', 'down', 'raised', '##ups']\n",
      "Ordered top predicted values: [9.9997783e-01 2.6151224e-06 2.5652409e-06 1.2053741e-06 5.9566872e-07]\n",
      "\n",
      "Sentence:\n",
      "I was born and grew up [MASK] Havana.\n",
      "Ordered top predicted tokens: ['in', 'near', 'around', 'on', 'outside']\n",
      "Ordered top predicted values: [9.9813348e-01 6.9417461e-04 2.7216767e-04 2.6694880e-04 9.7389369e-05]\n",
      "\n",
      "Sentence:\n",
      "I was born and grew up in [MASK].\n",
      "Ordered top predicted tokens: ['chicago', 'california', 'texas', 'london', 'england']\n",
      "Ordered top predicted values: [0.03689728 0.03364525 0.02513845 0.02230389 0.018717  ]\n",
      "\n",
      "Sentence:\n",
      "[MASK] Beijing metropolitan area added more than a million people in the past decade.\n",
      "Ordered top predicted tokens: ['the', 'this', 'its', 'greater', 'a']\n",
      "Ordered top predicted values: [9.9884856e-01 2.9264510e-04 2.4745113e-04 1.5349650e-04 6.2563595e-05]\n",
      "\n",
      "Sentence:\n",
      "The [MASK] metropolitan area added more than a million people in the past decade.\n",
      "Ordered top predicted tokens: ['chicago', 'washington', 'seattle', 'atlanta', 'detroit']\n",
      "Ordered top predicted values: [0.22472836 0.05055556 0.03419264 0.03207787 0.02761591]\n",
      "\n",
      "Sentence:\n",
      "The Beijing [MASK] area added more than a million people in the past decade.\n",
      "Ordered top predicted tokens: ['metropolitan', 'metro', 'urban', 'industrial', 'new']\n",
      "Ordered top predicted values: [0.9294059  0.03807342 0.01209903 0.00262589 0.00196663]\n",
      "\n",
      "Sentence:\n",
      "The Beijing metropolitan [MASK] added more than a million people in the past decade.\n",
      "Ordered top predicted tokens: ['area', 'region', 'has', 'subway', 'population']\n",
      "Ordered top predicted values: [0.9423685  0.02886115 0.0127381  0.00263932 0.00158582]\n",
      "\n",
      "Sentence:\n",
      "The Beijing metropolitan area [MASK] more than a million people in the past decade.\n",
      "Ordered top predicted tokens: ['attracted', 'has', 'employed', 'had', 'employs']\n",
      "Ordered top predicted values: [0.15752615 0.10981262 0.08998814 0.06868622 0.05912089]\n",
      "\n",
      "Sentence:\n",
      "The Beijing metropolitan area added [MASK] than a million people in the past decade.\n",
      "Ordered top predicted tokens: ['more', 'fewer', 'less', 'greater', 'larger']\n",
      "Ordered top predicted values: [9.9681997e-01 1.3902275e-03 1.0767359e-03 4.5106537e-04 3.3146858e-05]\n",
      "\n",
      "Sentence:\n",
      "The Beijing metropolitan area added more [MASK] a million people in the past decade.\n",
      "Ordered top predicted tokens: ['than', 'half', 'of', 'to', 'like']\n",
      "Ordered top predicted values: [9.99181211e-01 3.51583643e-04 2.40459442e-04 1.43449812e-04\n",
      " 1.38442565e-05]\n",
      "\n",
      "Sentence:\n",
      "The Beijing metropolitan area added more than [MASK] million people in the past decade.\n",
      "Ordered top predicted tokens: ['one', '10', 'a', '20', 'two']\n",
      "Ordered top predicted values: [0.04724086 0.04480017 0.03915531 0.03615021 0.03577068]\n",
      "\n",
      "Sentence:\n",
      "The Beijing metropolitan area added more than a [MASK] people in the past decade.\n",
      "Ordered top predicted tokens: ['million', 'billion', 'thousand', 'trillion', 'hundred']\n",
      "Ordered top predicted values: [0.76484424 0.19514959 0.03411166 0.00298944 0.0016909 ]\n",
      "\n",
      "Sentence:\n",
      "The Beijing metropolitan area added more than a million [MASK] in the past decade.\n",
      "Ordered top predicted tokens: ['people', 'jobs', 'residents', 'inhabitants', 'cities']\n",
      "Ordered top predicted values: [0.27747178 0.23053841 0.12672257 0.06608785 0.03503622]\n",
      "\n",
      "Sentence:\n",
      "The Beijing metropolitan area added more than a million people [MASK] the past decade.\n",
      "Ordered top predicted tokens: ['in', 'over', 'during', 'within', 'through']\n",
      "Ordered top predicted values: [0.48448032 0.4262195  0.05952647 0.02437967 0.00115795]\n",
      "\n",
      "Sentence:\n",
      "The Beijing metropolitan area added more than a million people in [MASK] past decade.\n",
      "Ordered top predicted tokens: ['the', 'this', 'its', 'a', 'that']\n",
      "Ordered top predicted values: [9.9929798e-01 3.4535682e-04 1.1704041e-04 6.1104438e-05 6.0381895e-05]\n",
      "\n",
      "Sentence:\n",
      "The Beijing metropolitan area added more than a million people in the [MASK] decade.\n",
      "Ordered top predicted tokens: ['next', 'last', 'following', 'same', 'first']\n",
      "Ordered top predicted values: [0.33028722 0.1631044  0.15992421 0.09668696 0.08808192]\n",
      "\n",
      "Sentence:\n",
      "The Beijing metropolitan area added more than a million people in the past [MASK].\n",
      "Ordered top predicted tokens: ['decade', 'year', 'century', 'years', 'decades']\n",
      "Ordered top predicted values: [0.6717132  0.16024946 0.11152893 0.02553026 0.02019292]\n",
      "\n",
      "Sentence:\n",
      "[MASK] races are held around the lake and farmlands.\n",
      "Ordered top predicted tokens: ['the', 'horse', 'many', 'these', 'boat']\n",
      "Ordered top predicted values: [0.2979782  0.12615193 0.05783908 0.04433875 0.03348668]\n",
      "\n",
      "Sentence:\n",
      "Bike [MASK] are held around the lake and farmlands.\n",
      "Ordered top predicted tokens: ['races', 'rides', 'tours', 'days', 'events']\n",
      "Ordered top predicted values: [0.5795625  0.1930804  0.08109502 0.01155138 0.00969578]\n",
      "\n",
      "Sentence:\n",
      "Bike races [MASK] held around the lake and farmlands.\n",
      "Ordered top predicted tokens: ['are', 'were', 'is', ',', '-']\n",
      "Ordered top predicted values: [9.6918857e-01 2.8898938e-02 6.6144334e-04 3.6474274e-04 1.2715103e-04]\n",
      "\n",
      "Sentence:\n",
      "Bike races are [MASK] around the lake and farmlands.\n",
      "Ordered top predicted tokens: ['held', 'run', 'conducted', 'arranged', 'organized']\n",
      "Ordered top predicted values: [0.7545702  0.04007456 0.03601876 0.03590756 0.03534804]\n",
      "\n",
      "Sentence:\n",
      "Bike races are held [MASK] the lake and farmlands.\n",
      "Ordered top predicted tokens: ['around', 'on', 'along', 'at', 'near']\n",
      "Ordered top predicted values: [0.42173743 0.3127655  0.11935162 0.06705581 0.02189605]\n",
      "\n",
      "Sentence:\n",
      "Bike races are held around [MASK] lake and farmlands.\n",
      "Ordered top predicted tokens: ['the', 'a', 'this', 'both', 'its']\n",
      "Ordered top predicted values: [9.7701001e-01 8.4780371e-03 1.4053996e-03 1.3200185e-03 2.6807026e-04]\n",
      "\n",
      "Sentence:\n",
      "Bike races are held around the [MASK] and farmlands.\n",
      "Ordered top predicted tokens: ['village', 'park', 'town', 'city', 'forest']\n",
      "Ordered top predicted values: [0.15070313 0.09536388 0.0665911  0.05703236 0.04966085]\n",
      "\n",
      "Sentence:\n",
      "Bike races are held around the lake [MASK] farmlands.\n",
      "Ordered top predicted tokens: ['and', 'in', 'on', 'surrounding', 'with']\n",
      "Ordered top predicted values: [0.8360901  0.07935613 0.01238885 0.00675396 0.00643334]\n",
      "\n",
      "Sentence:\n",
      "Bike races are held around the lake and [MASK].\n",
      "Ordered top predicted tokens: ['beach', 'river', 'lake', 'park', 'beaches']\n",
      "Ordered top predicted values: [0.19558807 0.10054731 0.09875162 0.06711072 0.0227002 ]\n",
      "\n",
      "Sentence:\n",
      "[MASK] racist cousin called me last night.\n",
      "Ordered top predicted tokens: ['my', 'your', 'his', 'a', 'the']\n",
      "Ordered top predicted values: [0.84591275 0.07917064 0.02119026 0.0157796  0.01323496]\n",
      "\n",
      "Sentence:\n",
      "My [MASK] cousin called me last night.\n",
      "Ordered top predicted tokens: ['little', 'first', 'other', 'second', 'older']\n",
      "Ordered top predicted values: [0.17687091 0.11616216 0.08078156 0.06596243 0.06010778]\n",
      "\n",
      "Sentence:\n",
      "My racist [MASK] called me last night.\n",
      "Ordered top predicted tokens: ['friend', 'neighbor', 'boyfriend', 'father', 'brother']\n",
      "Ordered top predicted values: [0.24061793 0.0719889  0.06706642 0.06234702 0.05771114]\n",
      "\n",
      "Sentence:\n",
      "My racist cousin [MASK] me last night.\n",
      "Ordered top predicted tokens: ['called', 'attacked', 'visited', 'left', 'told']\n",
      "Ordered top predicted values: [0.24278261 0.09246124 0.05170121 0.0447345  0.04387511]\n",
      "\n",
      "Sentence:\n",
      "My racist cousin called [MASK] last night.\n",
      "Ordered top predicted tokens: ['me', 'us', 'you', 'him', 'her']\n",
      "Ordered top predicted values: [0.9357591  0.01535697 0.01120117 0.00580344 0.00389533]\n",
      "\n",
      "Sentence:\n",
      "My racist cousin called me [MASK] night.\n",
      "Ordered top predicted tokens: ['last', 'that', 'one', 'friday', 'saturday']\n",
      "Ordered top predicted values: [0.79564553 0.09555402 0.04278419 0.01370805 0.00935419]\n",
      "\n",
      "Sentence:\n",
      "My racist cousin called me last [MASK].\n",
      "Ordered top predicted tokens: ['night', 'week', 'month', 'year', 'weekend']\n",
      "Ordered top predicted values: [0.8327592  0.10077035 0.0110896  0.01070417 0.00785117]\n",
      "\n",
      "Sentence:\n",
      "[MASK] device is considered to be available if it is not being used by another adult.\n",
      "Ordered top predicted tokens: ['the', 'this', 'a', 'no', 'that']\n",
      "Ordered top predicted values: [0.49252933 0.38195854 0.07231849 0.01511488 0.00762706]\n",
      "\n",
      "Sentence:\n",
      "A [MASK] is considered to be available if it is not being used by another adult.\n",
      "Ordered top predicted tokens: ['computer', 'child', 'resource', 'bathroom', 'restroom']\n",
      "Ordered top predicted values: [0.08350828 0.04493558 0.04292014 0.02862823 0.02655324]\n",
      "\n",
      "Sentence:\n",
      "A device [MASK] considered to be available if it is not being used by another adult.\n",
      "Ordered top predicted tokens: ['is', 'not', 'was', 'being', 'often']\n",
      "Ordered top predicted values: [9.8374325e-01 3.1986355e-03 1.9428738e-03 1.0355138e-03 9.3573134e-04]\n",
      "\n",
      "Sentence:\n",
      "A device is [MASK] to be available if it is not being used by another adult.\n",
      "Ordered top predicted tokens: ['said', 'required', 'unlikely', 'likely', 'considered']\n",
      "Ordered top predicted values: [0.17529716 0.1592348  0.08111338 0.06861633 0.05759166]\n",
      "\n",
      "Sentence:\n",
      "A device is considered [MASK] be available if it is not being used by another adult.\n",
      "Ordered top predicted tokens: ['to', 'must', 'should', 'may', 'not']\n",
      "Ordered top predicted values: [9.9890840e-01 2.3468852e-04 1.7463937e-04 1.6938157e-04 8.2477120e-05]\n",
      "\n",
      "Sentence:\n",
      "A device is considered to [MASK] available if it is not being used by another adult.\n",
      "Ordered top predicted tokens: ['be', 'remain', 'become', 'stay', 'have']\n",
      "Ordered top predicted values: [9.9595106e-01 2.4222089e-03 1.2664802e-03 1.4042320e-04 4.1809730e-05]\n",
      "\n",
      "Sentence:\n",
      "A device is considered to be [MASK] if it is not being used by another adult.\n",
      "Ordered top predicted tokens: ['safe', 'useful', 'dangerous', 'illegal', 'valid']\n",
      "Ordered top predicted values: [0.11508177 0.11391906 0.07876049 0.04220375 0.03573717]\n",
      "\n",
      "Sentence:\n",
      "A device is considered to be available [MASK] it is not being used by another adult.\n",
      "Ordered top predicted tokens: ['if', 'when', 'while', 'provided', 'where']\n",
      "Ordered top predicted values: [0.6243603  0.29487884 0.0145128  0.01426019 0.01081422]\n",
      "\n",
      "Sentence:\n",
      "A device is considered to be available if [MASK] is not being used by another adult.\n",
      "Ordered top predicted tokens: ['it', 'one', 'she', 'he', 'this']\n",
      "Ordered top predicted values: [9.9014521e-01 6.1486075e-03 9.8094787e-04 5.1343930e-04 2.7273421e-04]\n",
      "\n",
      "Sentence:\n",
      "A device is considered to be available if it [MASK] not being used by another adult.\n",
      "Ordered top predicted tokens: ['is', 'was', 'are', 'means', 'isn']\n",
      "Ordered top predicted values: [9.9672192e-01 1.2930901e-03 1.2093845e-03 1.3585869e-04 4.5149245e-05]\n",
      "\n",
      "Sentence:\n",
      "A device is considered to be available if it is [MASK] being used by another adult.\n",
      "Ordered top predicted tokens: ['not', 'already', 'currently', 'also', 'actively']\n",
      "Ordered top predicted values: [0.833109   0.0334968  0.03225623 0.01391788 0.01107708]\n",
      "\n",
      "Sentence:\n",
      "A device is considered to be available if it is not [MASK] used by another adult.\n",
      "Ordered top predicted tokens: ['being', 'currently', 'often', 'actively', 'frequently']\n",
      "Ordered top predicted values: [0.8656893  0.01254983 0.01095647 0.01005607 0.00926219]\n",
      "\n",
      "Sentence:\n",
      "A device is considered to be available if it is not being [MASK] by another adult.\n",
      "Ordered top predicted tokens: ['used', 'utilized', 'operated', 'worn', 'purchased']\n",
      "Ordered top predicted values: [0.8139734  0.02033664 0.0196798  0.01906324 0.01271394]\n",
      "\n",
      "Sentence:\n",
      "A device is considered to be available if it is not being used [MASK] another adult.\n",
      "Ordered top predicted tokens: ['by', 'with', 'for', 'on', 'against']\n",
      "Ordered top predicted values: [0.92791545 0.03752535 0.01570404 0.00989701 0.00322472]\n",
      "\n",
      "Sentence:\n",
      "A device is considered to be available if it is not being used by [MASK] adult.\n",
      "Ordered top predicted tokens: ['an', 'the', 'any', 'another', 'one']\n",
      "Ordered top predicted values: [0.88334054 0.07983281 0.0236817  0.00717818 0.0015536 ]\n",
      "\n",
      "Sentence:\n",
      "A device is considered to be available if it is not being used by another [MASK].\n",
      "Ordered top predicted tokens: ['person', 'user', 'party', 'device', 'entity']\n",
      "Ordered top predicted values: [0.27529848 0.25013295 0.09434847 0.07847174 0.04001943]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert last hidden state to probs and find tokens\n",
    "sm = torch.nn.Softmax(dim=0) \n",
    "#id_large = tokenizer.convert_tokens_to_ids('large')\n",
    "all_high_tokens = []\n",
    "i = 0\n",
    "for lh, m in zip(last_hidden_states[0], mask_positions):\n",
    "    print(\"Sentence:\")\n",
    "    print(sentences[i])\n",
    "    i += 1\n",
    "    probs = sm(lh[m])\n",
    "    #print(f\"Probability of 'large': {probs[id_large]}\")\n",
    "    _, high_tokens = get_top_predictions(probs)\n",
    "    all_high_tokens.append(high_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  9, 12, 13,  1, 12, 14, 14, 13,  1, 11, 11,  7,  1,  7, 14, 15,\n",
       "       17, 14,  1,  6, 12, 14, 14, 15,  1,  6,  8,  1,  1,  6,  8,  2,  2,\n",
       "        2,  1, 16, 13, 13,  5, 13,  6, 19, 19, 15,  3, 13,  5,  5, 18, 13,\n",
       "        1,  3,  3, 13, 18, 13, 10, 13, 13, 10, 13, 10,  1,  9,  8, 15,  1,\n",
       "        1,  7, 17,  8, 17,  4, 17, 17,  4, 17, 17,  0, 17, 17, 15, 13, 17,\n",
       "       17], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cluster embeddings with KMeans\n",
    "from sklearn.cluster import KMeans, OPTICS, DBSCAN, cluster_optics_dbscan\n",
    "k = 20\n",
    "estimator = KMeans(init=\"k-means++\", n_clusters=k, n_jobs=4)\n",
    "estimator.fit(embeddings)\n",
    "estimator.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Form word categories\n",
    "Take all words above a threshold from vectors that belong to a cluster to form word categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 0:\n",
      "is\n",
      "\n",
      "Category 1:\n",
      "at, your, and, their, from, last, me, one, that, us, you, friday, this, the, for, a, my, in, all, his, her\n",
      "\n",
      "Category 2:\n",
      "gonzalez, garcia, lopez, rodriguez, she, gomez, was, born, jewish, castro, sanchez, rivera, diaz, hernandez, perez, he\n",
      "\n",
      "Category 3:\n",
      "last, years, century, previous, following, next, ensuing, past, decades, year, same, first, decade, more\n",
      "\n",
      "Category 4:\n",
      "dangerous, harmless, intended, illegal, suitable, safe, known, invalid, appropriate, valuable, secure, considered, hazardous, useful, effective, useless, required, safer, harmful, legitimate, permitted, allowed, likely, legal, deemed, helpful, expected, valid, unsafe, not, inappropriate, guaranteed, said, unlikely\n",
      "\n",
      "Category 5:\n",
      "3, toronto, 5, 1, florida, 60, million, 15, 2, 12, texas, one, brooklyn, germany, 10, london, 7, 40, six, 8, 25, 6, five, thousand, ten, three, england, california, canada, a, 200, 100, 20, france, philadelphia, two, four, billion, 30, mexico, chicago, 4, 50, 11\n",
      "\n",
      "Category 6:\n",
      "generous, handsome, indianapolis, detroit, toronto, small, denver, louisville, high, manhattan, steady, good, minneapolis, austin, low, atlanta, pittsburgh, cleveland, london, new, houston, modest, own, large, leather, nice, comfortable, luxury, washington, substantial, decent, philadelphia, seattle, dallas, portland, fine, considerable, chicago, luxurious, respectable\n",
      "\n",
      "Category 7:\n",
      "week, robe, month, gown, night, time, year, evening, dress\n",
      "\n",
      "Category 8:\n",
      "restroom, home, girlfriend, child, father, space, place, brother, computer, house, roommate, condom, wife, bedroom, automobile, toilet, bathroom, room, hotel, shelter, one, restaurant, garage, studio, card, carpet, piano, boss, boyfriend, neighbors, family, friend, facility, vehicle, school, uncle, friends, office, apartment, service, device, husband, cousin, program, permit, partner, resource, dad, bed, neighbor, store, mother, club, residence, mattress, car\n",
      "\n",
      "Category 9:\n",
      "wild, brown, old, first, fat, older, oldest, dear, second, new, black, own, cheshire, great, gray, youngest, white, big, younger, third, dead, yellow, giant, little, favorite, mother, red, other\n",
      "\n",
      "Category 10:\n",
      "offered, hills, lake, river, marina, woods, park, run, conducted, fields, forest, mountains, trails, trail, organized, town, beaches, parks, countryside, island, city, pond, lakes, held, beach, village, gardens, arranged, forests, villages, farms, towns\n",
      "\n",
      "Category 11:\n",
      "wedding, blue, black, pink, silver, yellow, little, silk, purple, red, long, white, evening, green\n",
      "\n",
      "Category 12:\n",
      "check, donation, boy, offer, baby, price, payment, bird, bonus, debt, man, pig, tip, salary, one, fee, visit, girl, food, reward, egg, mouse, sum, rabbit, amount, rat, gift, dog, thing, meat, woman, cat, commission, beating, promotion, fruit, chicken, ransom, fish\n",
      "\n",
      "Category 13:\n",
      "over, these, during, at, various, and, most, several, ., near, many, water, on, by, around, within, with, up, the, than, numerous, for, local, horse, boat, in, ,, were, along, wearing, are, other\n",
      "\n",
      "Category 14:\n",
      "him, over, even, only, was, around, about, with, he, i, almost, had, approximately, also, quite, she, such, nearly, then, they\n",
      "\n",
      "Category 15:\n",
      "added, visited, called, purchased, left, told, worn, found, hosted, provided, hosts, reached, built, is, made, displaced, grabbed, was, attracts, kissed, approached, shot, donated, commissioned, serves, absorbed, raped, employed, constructed, bought, designed, has, used, operated, acquired, lost, had, woke, utilized, caught, attracted, beat, texted, employs, received, served, ordered, attacked, hit\n",
      "\n",
      "Category 16:\n",
      "grew, brought\n",
      "\n",
      "Category 17:\n",
      "it, doing, application, being, already, any, company, earning, actively, often, paid, no, user, provided, getting, on, is, receiving, owed, if, an, party, to, this, while, the, customer, person, organization, given, paying, when, also, device, because, making, a, where, entity, currently, provider, be, not\n",
      "\n",
      "Category 18:\n",
      "businesses, people, cities, passengers, inhabitants, visitors, jobs, days, races, tours, buildings, rides, residents, tourists\n",
      "\n",
      "Category 19:\n",
      "metropolitan, has, metro, region, urban, area\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_categories = {}\n",
    "for cl in range(k):\n",
    "    cluster_members = np.where(estimator.labels_ == cl)\n",
    "    word_categories[cl] = sum((all_high_tokens[i] for i in cluster_members[0]), [])\n",
    "    word_categories[cl] = set(word_categories[cl])\n",
    "    print(f\"Category {cl}:\")\n",
    "    print(\", \".join(word_categories[cl]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:transformers]",
   "language": "python",
   "name": "conda-env-transformers-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
