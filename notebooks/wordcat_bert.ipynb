{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word category formation using BERT predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The idea is to generate word embeddings by:\n",
    "- Get a list of sentences\n",
    "- Mask a word in each sentence (repeat a sentence in the list if you want to mask different positions)\n",
    "- For each sentence, obtain the logit vector for the masked word from BERT's prediction (last hidden layer)\n",
    "- Cluster sentences logit vectors. The clusters should reflect words that fit together both syntactically and semantically.\n",
    "- Build each word category by finding the highest valued words in the vectors belonging to a cluster (perhaps by most common top words, all words above some threshold, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import numpy as np\n",
    "import torch\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose some simple sentences with masked adjectives and nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sentences = \"\"\"The _ cat ate the mouse.\n",
    "She was wearing a lovely _ dress last night.\n",
    "He was receiving quite a _ salary.\n",
    "He also bought a _ sofa for his new apartment.\n",
    "I was born and grew up in _.\n",
    "The _ metropolitan area added more than a million people in the past decade.\n",
    "Bike races are held around the _ and farmlands.\n",
    "My _ called me last night.\n",
    "Mozart's _ came from a remote country.\n",
    "A device is considered to be available if it is not being used by another _.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process sentences with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The [MASK] cat ate the mouse.',\n",
       " 'She was wearing a lovely [MASK] dress last night.',\n",
       " 'He was receiving quite a [MASK] salary.',\n",
       " 'He also bought a [MASK] sofa for his new apartment.',\n",
       " 'I was born and grew up in [MASK].',\n",
       " 'The [MASK] metropolitan area added more than a million people in the past decade.',\n",
       " 'Bike races are held around the [MASK] and farmlands.',\n",
       " 'My [MASK] called me last night.',\n",
       " \"Mozart's [MASK] came from a remote country.\",\n",
       " 'A device is considered to be available if it is not being used by another [MASK].']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Place [MASK] tokens\n",
    "MASK = '[MASK]'\n",
    "sentences = re.sub(r'\\b_+\\b', '[MASK]', text_sentences).split('\\n')\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# tokenize input\n",
    "input_ids = [tokenizer.encode(s, add_special_tokens=True) for s in sentences]\n",
    "\n",
    "# Find location of MASKS\n",
    "tok_MASK = tokenizer.convert_tokens_to_ids(MASK)\n",
    "mask_positions = [s.index(tok_MASK) for s in input_ids] \n",
    "\n",
    "# Make all sentence arrays equal length by padding\n",
    "max_len = max(len(i) for i in input_ids)\n",
    "padded_input = np.array([i + [0]* (max_len - len(i)) for i in input_ids])\n",
    "\n",
    "attention_mask = np.where(padded_input != 0, 1, 0)  # Create mask to ignore padding\n",
    "\n",
    "input = torch.tensor(padded_input)\n",
    "attention_mask = torch.tensor(attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get hidden layers\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embeddings for the masked word of each sentence\n",
    "embeddings = [lh[m].numpy() for lh, m in zip(last_hidden_states[0], mask_positions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_predictions(probs, k=5, thres=0.01):\n",
    "    \"\"\"\n",
    "    Print and return top-k predictions for a given probs list.\n",
    "    Also return predictions above threshold\n",
    "    \"\"\"\n",
    "    # Get top-k tokens\n",
    "    probs = probs.detach().numpy()\n",
    "    top_indexes = np.argpartition(probs, -k)[-k:]\n",
    "    sorted_indexes = top_indexes[np.argsort(-probs[top_indexes])]\n",
    "    top_tokens = tokenizer.convert_ids_to_tokens(sorted_indexes)\n",
    "    print(f\"Ordered top predicted tokens: {top_tokens}\")\n",
    "    print(f\"Ordered top predicted values: {probs[sorted_indexes]}\\n\")\n",
    "    \n",
    "    # Get all tokens above threshold\n",
    "    high_indexes = np.where(probs > thres)\n",
    "    high_tokens = tokenizer.convert_ids_to_tokens(high_indexes[0])\n",
    "    return top_tokens, high_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert last layer logit predictions to probabilities\n",
    "We can see what are the highest predictions for the blank in each sentence, and their probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:\n",
      "The [MASK] cat ate the mouse.\n",
      "Ordered top predicted tokens: ['black', 'cheshire', 'big', 'little', 'fat']\n",
      "Ordered top predicted values: [0.13267049 0.08640933 0.06516975 0.03538685 0.03100599]\n",
      "\n",
      "Sentence:\n",
      "She was wearing a lovely [MASK] dress last night.\n",
      "Ordered top predicted tokens: ['white', 'black', 'red', 'pink', 'blue']\n",
      "Ordered top predicted values: [0.20945124 0.16496556 0.13129269 0.08869011 0.05542691]\n",
      "\n",
      "Sentence:\n",
      "He was receiving quite a [MASK] salary.\n",
      "Ordered top predicted tokens: ['good', 'handsome', 'high', 'generous', 'decent']\n",
      "Ordered top predicted values: [0.18829058 0.09613485 0.09576207 0.0917473  0.0544567 ]\n",
      "\n",
      "Sentence:\n",
      "He also bought a [MASK] sofa for his new apartment.\n",
      "Ordered top predicted tokens: ['new', 'comfortable', 'luxurious', 'large', 'luxury']\n",
      "Ordered top predicted values: [0.6247967  0.05839209 0.02877485 0.0248212  0.01501671]\n",
      "\n",
      "Sentence:\n",
      "I was born and grew up in [MASK].\n",
      "Ordered top predicted tokens: ['chicago', 'california', 'texas', 'london', 'england']\n",
      "Ordered top predicted values: [0.03689728 0.03364525 0.02513845 0.02230389 0.018717  ]\n",
      "\n",
      "Sentence:\n",
      "The [MASK] metropolitan area added more than a million people in the past decade.\n",
      "Ordered top predicted tokens: ['chicago', 'washington', 'seattle', 'atlanta', 'detroit']\n",
      "Ordered top predicted values: [0.22472836 0.05055556 0.03419264 0.03207787 0.02761591]\n",
      "\n",
      "Sentence:\n",
      "Bike races are held around the [MASK] and farmlands.\n",
      "Ordered top predicted tokens: ['village', 'park', 'town', 'city', 'forest']\n",
      "Ordered top predicted values: [0.15070313 0.09536388 0.0665911  0.05703236 0.04966085]\n",
      "\n",
      "Sentence:\n",
      "My [MASK] called me last night.\n",
      "Ordered top predicted tokens: ['mom', 'mother', 'dad', 'father', 'parents']\n",
      "Ordered top predicted values: [0.27431244 0.20736365 0.1541641  0.07473796 0.03835735]\n",
      "\n",
      "Sentence:\n",
      "Mozart's [MASK] came from a remote country.\n",
      "Ordered top predicted tokens: ['music', 'voice', 'family', 'father', 'mother']\n",
      "Ordered top predicted values: [0.29921883 0.10453673 0.09061044 0.04193356 0.0398896 ]\n",
      "\n",
      "Sentence:\n",
      "A device is considered to be available if it is not being used by another [MASK].\n",
      "Ordered top predicted tokens: ['person', 'user', 'party', 'device', 'entity']\n",
      "Ordered top predicted values: [0.27529848 0.25013295 0.09434847 0.07847174 0.04001943]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert last hidden state to probs and find tokens\n",
    "sm = torch.nn.Softmax(dim=0) \n",
    "#id_large = tokenizer.convert_tokens_to_ids('large')\n",
    "all_high_tokens = []\n",
    "i = 0\n",
    "for lh, m in zip(last_hidden_states[0], mask_positions):\n",
    "    print(\"Sentence:\")\n",
    "    print(sentences[i])\n",
    "    i += 1\n",
    "    probs = sm(lh[m])\n",
    "    #print(f\"Probability of 'large': {probs[id_large]}\")\n",
    "    _, high_tokens = get_top_predictions(probs)\n",
    "    all_high_tokens.append(high_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 2, 2, 2, 3, 3, 4], dtype=int32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cluster embeddings with KMeans\n",
    "from sklearn.cluster import KMeans, OPTICS, DBSCAN, cluster_optics_dbscan\n",
    "k = 5\n",
    "estimator = KMeans(init=\"k-means++\", n_clusters=k, n_jobs=4)\n",
    "estimator.fit(embeddings)\n",
    "estimator.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Form word categories\n",
    "Take all words above a threshold from vectors that belong to a cluster to form word categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 0:\n",
      "fine, high, low, steady, comfortable, respectable, good, small, nice, modest, decent, generous, considerable, large, handsome, substantial\n",
      "\n",
      "Category 1:\n",
      "luxurious, mother, old, giant, silver, comfortable, big, dead, green, fat, wild, purple, cheshire, yellow, red, evening, wedding, silk, little, white, new, small, great, leather, large, brown, luxury, blue, black, gray, pink\n",
      "\n",
      "Category 2:\n",
      "dallas, washington, london, woods, seattle, canada, philadelphia, france, gardens, lakes, portland, fields, atlanta, villages, austin, forest, pittsburgh, minneapolis, california, england, florida, mexico, parks, forests, toronto, park, farms, village, countryside, lake, hills, mountains, louisville, brooklyn, cleveland, indianapolis, town, texas, germany, denver, city, towns, detroit, chicago, houston\n",
      "\n",
      "Category 3:\n",
      "friend, parents, family, mother, dad, aunt, name, mom, music, wife, violin, brother, sister, voice, grandfather, orchestra, father\n",
      "\n",
      "Category 4:\n",
      "device, company, provider, customer, organization, person, application, user, party, entity\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_categories = {}\n",
    "for cl in range(k):\n",
    "    cluster_members = np.where(estimator.labels_ == cl)\n",
    "    word_categories[cl] = sum((all_high_tokens[i] for i in cluster_members[0]), [])\n",
    "    word_categories[cl] = set(word_categories[cl])\n",
    "    print(f\"Category {cl}:\")\n",
    "    print(\", \".join(word_categories[cl]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:transformers]",
   "language": "python",
   "name": "conda-env-transformers-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
