{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate sentence probability with BERT\n",
    "## Calculating probability more properly:\n",
    "P_f, P_b: Probability forward pass, backward pass, respectively\n",
    "P_f = P(w_0) * P(w_1|w_0) * P(w_2|w_0, w_1) * ... * P(w_N)\n",
    "P_b = P(w_N-1|w_N) * P(w_N-2|w_N-1, w_N) * ... * P(w_0|w_1, w_2, ... ,w_N)\n",
    "\n",
    "P_f, P_b become smaller as the number of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "with torch.no_grad():\n",
    "    model = BertForMaskedLM.from_pretrained('bert-large-uncased')\n",
    "    model.eval()\n",
    "    # Load pre-trained model tokenizer (vocabulary)\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_predictions(probs, k=5):\n",
    "    probs = probs.detach().numpy()\n",
    "    top_indexes = np.argpartition(probs, -k)[-k:]\n",
    "    sorted_indexes = top_indexes[np.argsort(-probs[top_indexes])]\n",
    "    top_tokens = tokenizer.convert_ids_to_tokens(sorted_indexes)\n",
    "    print(f\"Ordered top predicted tokens: {top_tokens}\")\n",
    "    print(f\"Ordered top predicted values: {probs[sorted_indexes]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[1,2,3,4]\n",
    "a[0:-1] = [i for i in range(10,11)]\n",
    "a\n",
    "np.power(8,1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forward_prob(tokenized_input, sm, verbose=False):\n",
    "    sent_len = len(tokenized_input)\n",
    "    ids_input = tokenizer.convert_tokens_to_ids(tokenized_input)\n",
    "    print(f\"Processing sentence: {tokenized_input}\")\n",
    "    #print(f\"Sentence ids: {ids_input}\")\n",
    "    sent_prob = 1\n",
    "#     sum_lp = 0\n",
    "    # Mask non-special tokens in forward direction; calculate their probabilities\n",
    "    for i in range(1, len(tokenized_input) - 1): # Don't loop first and last tokens\n",
    "        current_tokenized = tokenized_input[:]\n",
    "        current_tokenized[i:-1] = [MASK_TOKEN for j in range(len(tokenized_input) - 1 - i)]\n",
    "        if verbose: print(current_tokenized)\n",
    "        masked_input = torch.tensor([tokenizer.convert_tokens_to_ids(current_tokenized)])\n",
    "        outputs = model(masked_input)\n",
    "        predictions = outputs[0]\n",
    "        current_probs = sm(predictions[0, i]) # Softmax to get probabilities\n",
    "        current_prob = current_probs[ids_input[i]] # Prediction for masked word\n",
    "        sent_prob *= current_prob\n",
    "\n",
    "#         sum_lp += np.log(current_prob.detach().numpy())\n",
    "\n",
    "        print(f\"Word: {tokenized_input[i]} \\t Prob: {current_prob}\")\n",
    "        if verbose: print_top_predictions(current_probs)\n",
    "\n",
    "    geom_mean_sent_prob = np.power(sent_prob.item(), 1/sent_len)  # Calculate geometric mean\n",
    "    print(f\"\\nGeometric-mean sentence probability: {geom_mean_sent_prob}\\n\")\n",
    "#     print(f\"\\nNormalized forward sentence prob: log(P(sentence)) / sent_length: {sum_lp / sent_len}\\n\")\n",
    "#     return sum_lp / sent_len\n",
    "    return geom_mean_sent_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_backward_prob(tokenized_input, sm, verbose=False):\n",
    "    sent_len = len(tokenized_input)\n",
    "    ids_input = tokenizer.convert_tokens_to_ids(tokenized_input)\n",
    "    print(f\"Processing sentence: {tokenized_input}\")\n",
    "    #print(f\"Sentence ids: {ids_input}\")\n",
    "    #sent_prob = 1\n",
    "    sum_lp = 0\n",
    "    # Mask non-special tokens in backward direction; calculate their probabilities\n",
    "    for i in reversed(range(1, len(tokenized_input) - 1)): # Don't loop first and last tokens\n",
    "        current_tokenized = tokenized_input[:]\n",
    "        current_tokenized[1:i+1] = [MASK_TOKEN for j in range(i)]\n",
    "        if verbose: print(current_tokenized)\n",
    "        masked_input = torch.tensor([tokenizer.convert_tokens_to_ids(current_tokenized)])\n",
    "        outputs = model(masked_input)\n",
    "        predictions = outputs[0]\n",
    "        current_probs = sm(predictions[0, i]) # Softmax to get probabilities\n",
    "        current_prob = current_probs[ids_input[i]] # Prediction for masked word\n",
    "        #sent_prob *= current_prob\n",
    "\n",
    "        sum_lp += np.log(current_prob.detach().numpy())\n",
    "\n",
    "        print(f\"Word: {tokenized_input[i]} \\t Prob: {current_prob}\")\n",
    "        if verbose: print_top_predictions(current_probs)\n",
    "\n",
    "    #print(f\"\\nSentence probability: {sent_prob.item()}\\n\")\n",
    "    print(f\"\\nNormalized backward sentence prob: log(P(sentence)) / sent_length: {sum_lp / sent_len}\\n\")\n",
    "    return sum_lp / sent_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS_TOKEN = '[CLS]'\n",
    "EOS_TOKEN = '[SEP]'\n",
    "MASK_TOKEN = '[MASK]'\n",
    "\n",
    "def get_sentence_prob(sentence, verbose=False):\n",
    "    sm = torch.nn.Softmax(dim=0) # used to convert last hidden state to probs\n",
    "    \n",
    "    # Pre-process sentence, adding special tokens\n",
    "    tokenized_input = tokenizer.tokenize(sentence)\n",
    "    if tokenized_input[0] != BOS_TOKEN:\n",
    "        tokenized_input.insert(0, BOS_TOKEN)\n",
    "    if tokenized_input[-1] != EOS_TOKEN:\n",
    "        tokenized_input.append(EOS_TOKEN)\n",
    "    \n",
    "    forward_prob = get_forward_prob(tokenized_input, sm, verbose=verbose)\n",
    "    backward_prob = get_backward_prob(tokenized_input, sm, verbose=verbose)\n",
    "    avg_prob = (forward_prob + backward_prob) / 2\n",
    "    print(f\"\\nAverage normalized sentence prob: log(P(sentence)) / sent_length: {avg_prob}\\n\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence: ['[CLS]', 'he', 'answered', 'une', '##qui', '##vo', '##cal', '##ly', '.', '[SEP]']\n",
      "Word: he \t Prob: 0.0005044482531957328\n",
      "Word: answered \t Prob: 0.0002913153439294547\n",
      "Word: une \t Prob: 2.243901064957754e-07\n",
      "Word: ##qui \t Prob: 0.0005762826185673475\n",
      "Word: ##vo \t Prob: 0.05035709589719772\n",
      "Word: ##cal \t Prob: 0.9999289512634277\n",
      "Word: ##ly \t Prob: 0.9982821941375732\n",
      "Word: . \t Prob: 0.9998167157173157\n",
      "\n",
      "Geometric-mean sentence probability: 0.015776195271175384\n",
      "\n",
      "Processing sentence: ['[CLS]', 'he', 'answered', 'une', '##qui', '##vo', '##cal', '##ly', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.7406781911849976\n",
      "Word: ##ly \t Prob: 0.0010952855227515101\n",
      "Word: ##cal \t Prob: 2.658714583958499e-05\n",
      "Word: ##vo \t Prob: 3.2233551792160142e-06\n",
      "Word: ##qui \t Prob: 0.0008089180919341743\n",
      "Word: une \t Prob: 0.9987058639526367\n",
      "Word: answered \t Prob: 0.010978045873343945\n",
      "Word: he \t Prob: 0.2814375162124634\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -4.319790983572602\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -2.1520073941507136\n",
      "\n",
      "Processing sentence: ['[CLS]', 'he', 'answered', 'quickly', '.', '[SEP]']\n",
      "['[CLS]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[SEP]']\n",
      "Word: he \t Prob: 0.0012037473497912288\n",
      "Ordered top predicted tokens: ['in', 'and', '\"', '[', '(']\n",
      "Ordered top predicted values: [0.04898074 0.04841739 0.04020055 0.03066272 0.02607192]\n",
      "['[CLS]', 'he', '[MASK]', '[MASK]', '[MASK]', '[SEP]']\n",
      "Word: answered \t Prob: 0.003327467478811741\n",
      "Ordered top predicted tokens: ['was', 'looked', 'asked', 'said', 'is']\n",
      "Ordered top predicted values: [0.4028537  0.05901183 0.05432703 0.04291577 0.03971536]\n",
      "['[CLS]', 'he', 'answered', '[MASK]', '[MASK]', '[SEP]']\n",
      "Word: quickly \t Prob: 0.06010275334119797\n",
      "Ordered top predicted tokens: ['it', 'immediately', 'quickly', 'her', 'quietly']\n",
      "Ordered top predicted values: [0.3002007  0.1476826  0.06010275 0.03919926 0.03147311]\n",
      "['[CLS]', 'he', 'answered', 'quickly', '[MASK]', '[SEP]']\n",
      "Word: . \t Prob: 0.9981406927108765\n",
      "Ordered top predicted tokens: ['.', ';', '!', '?', '...']\n",
      "Ordered top predicted values: [9.9814069e-01 1.8559413e-03 2.1156122e-06 1.1307502e-06 6.6726315e-08]\n",
      "\n",
      "Geometric-mean sentence probability: 0.07884773394623691\n",
      "\n",
      "Processing sentence: ['[CLS]', 'he', 'answered', 'quickly', '.', '[SEP]']\n",
      "['[CLS]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[SEP]']\n",
      "Word: . \t Prob: 0.9574853777885437\n",
      "Ordered top predicted tokens: ['.', ';', '|', '?', '!']\n",
      "Ordered top predicted values: [9.5748538e-01 4.0964618e-02 1.0687120e-03 2.2205077e-04 2.2124879e-04]\n",
      "['[CLS]', '[MASK]', '[MASK]', '[MASK]', '.', '[SEP]']\n",
      "Word: quickly \t Prob: 1.494371304033848e-06\n",
      "Ordered top predicted tokens: ['vol', 'press', 'p', 'j', 'ii']\n",
      "Ordered top predicted values: [0.06490542 0.05437048 0.03844456 0.0262519  0.01432491]\n",
      "['[CLS]', '[MASK]', '[MASK]', 'quickly', '.', '[SEP]']\n",
      "Word: answered \t Prob: 0.016331685706973076\n",
      "Ordered top predicted tokens: ['asked', 'said', 'thought', 'nodded', 'blinked']\n",
      "Ordered top predicted values: [0.2587772  0.1465675  0.12193974 0.08968459 0.04111334]\n",
      "['[CLS]', '[MASK]', 'answered', 'quickly', '.', '[SEP]']\n",
      "Word: he \t Prob: 0.2151750773191452\n",
      "Ordered top predicted tokens: ['i', 'she', 'he', 'jack', 'nick']\n",
      "Ordered top predicted values: [0.2943303  0.2310972  0.21517508 0.00285249 0.00283264]\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -3.1847002437959113\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -1.5529262549248373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_sentence_prob(\"He answered unequivocally.\")\n",
    "get_sentence_prob(\"He answered quickly.\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence: ['[CLS]', 'the', 'guy', 'with', 'small', 'hands', 'demanded', 'a', 'qui', '##d', 'pro', 'quo', '.', '[SEP]']\n",
      "Word: the \t Prob: 0.020117253065109253\n",
      "Word: guy \t Prob: 4.888691910309717e-05\n",
      "Word: with \t Prob: 0.0006999199977144599\n",
      "Word: small \t Prob: 4.887327304459177e-05\n",
      "Word: hands \t Prob: 0.0014287744415923953\n",
      "Word: demanded \t Prob: 2.932926236098865e-06\n",
      "Word: a \t Prob: 0.000463048490928486\n",
      "Word: qui \t Prob: 3.862149696942652e-06\n",
      "Word: ##d \t Prob: 0.23301775753498077\n",
      "Word: pro \t Prob: 3.778058089665137e-05\n",
      "Word: quo \t Prob: 0.9989466071128845\n",
      "Word: . \t Prob: 0.9850805401802063\n",
      "\n",
      "Geometric-mean sentence probability: 0.002836646561912836\n",
      "\n",
      "Processing sentence: ['[CLS]', 'the', 'guy', 'with', 'small', 'hands', 'demanded', 'a', 'qui', '##d', 'pro', 'quo', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.8537910580635071\n",
      "Word: quo \t Prob: 6.576073587893916e-07\n",
      "Word: pro \t Prob: 0.004886653274297714\n",
      "Word: ##d \t Prob: 7.432691973008332e-07\n",
      "Word: qui \t Prob: 0.5241817235946655\n",
      "Word: a \t Prob: 0.06345833837985992\n",
      "Word: demanded \t Prob: 1.76298769360983e-07\n",
      "Word: hands \t Prob: 7.560867379652336e-05\n",
      "Word: small \t Prob: 0.008030521683394909\n",
      "Word: with \t Prob: 0.06413324922323227\n",
      "Word: guy \t Prob: 0.0006307517760433257\n",
      "Word: the \t Prob: 0.6742717027664185\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -5.543179563113621\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -2.770171458275854\n",
      "\n",
      "Processing sentence: ['[CLS]', 'the', 'guy', 'with', 'small', 'hands', 'demanded', 'an', 'exchange', '.', '[SEP]']\n",
      "Word: the \t Prob: 0.00395584711804986\n",
      "Word: guy \t Prob: 0.00023759041505400091\n",
      "Word: with \t Prob: 0.00551602290943265\n",
      "Word: small \t Prob: 2.2452195480582304e-06\n",
      "Word: hands \t Prob: 0.12713825702667236\n",
      "Word: demanded \t Prob: 0.0003027346101589501\n",
      "Word: an \t Prob: 0.0007860533078201115\n",
      "Word: exchange \t Prob: 0.003408455988392234\n",
      "Word: . \t Prob: 0.9960935711860657\n",
      "\n",
      "Geometric-mean sentence probability: 0.006687079668616467\n",
      "\n",
      "Processing sentence: ['[CLS]', 'the', 'guy', 'with', 'small', 'hands', 'demanded', 'an', 'exchange', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.7714381814002991\n",
      "Word: exchange \t Prob: 2.3502572730649263e-05\n",
      "Word: an \t Prob: 0.004323412664234638\n",
      "Word: demanded \t Prob: 0.00019403055193834007\n",
      "Word: hands \t Prob: 6.0928286984562874e-05\n",
      "Word: small \t Prob: 0.007092668209224939\n",
      "Word: with \t Prob: 0.13349278271198273\n",
      "Word: guy \t Prob: 0.0005619829171337187\n",
      "Word: the \t Prob: 0.6960532069206238\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -4.493062544952739\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -2.2431877326420615\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_sentence_prob(\"The guy with small hands demanded a quid pro quo.\")\n",
    "get_sentence_prob(\"The guy with small hands demanded an exchange.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence: ['[CLS]', 'this', 'is', 'a', 'sentence', '.', '[SEP]']\n",
      "Word: this \t Prob: 0.00012813373177777976\n",
      "Word: is \t Prob: 0.3984246850013733\n",
      "Word: a \t Prob: 0.06797751039266586\n",
      "Word: sentence \t Prob: 0.00013198245142120868\n",
      "Word: . \t Prob: 0.966092050075531\n",
      "\n",
      "Geometric-mean sentence probability: 0.046100048266749315\n",
      "\n",
      "Processing sentence: ['[CLS]', 'this', 'is', 'a', 'sentence', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.8030216097831726\n",
      "Word: sentence \t Prob: 9.854356903815642e-07\n",
      "Word: a \t Prob: 0.23075106739997864\n",
      "Word: is \t Prob: 0.06603307276964188\n",
      "Word: this \t Prob: 0.060409143567085266\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -3.0057408596788133\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -1.479820405706032\n",
      "\n",
      "Processing sentence: ['[CLS]', 'this', 'is', 'a', 'mac', '##ram', '##e', '.', '[SEP]']\n",
      "Word: this \t Prob: 0.00017661201127339154\n",
      "Word: is \t Prob: 0.13002026081085205\n",
      "Word: a \t Prob: 0.7468298077583313\n",
      "Word: mac \t Prob: 3.489916707621887e-05\n",
      "Word: ##ram \t Prob: 3.345703225932084e-05\n",
      "Word: ##e \t Prob: 0.9994305968284607\n",
      "Word: . \t Prob: 0.9644730091094971\n",
      "\n",
      "Geometric-mean sentence probability: 0.02993488362293282\n",
      "\n",
      "Processing sentence: ['[CLS]', 'this', 'is', 'a', 'mac', '##ram', '##e', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.6934828162193298\n",
      "Word: ##e \t Prob: 0.0015561149921268225\n",
      "Word: ##ram \t Prob: 0.00035895415931008756\n",
      "Word: mac \t Prob: 0.031789381057024\n",
      "Word: a \t Prob: 0.03886374458670616\n",
      "Word: is \t Prob: 0.1228228434920311\n",
      "Word: this \t Prob: 0.055456843227148056\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -2.938820709784826\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -1.4544429130809464\n",
      "\n",
      "Processing sentence: ['[CLS]', 'this', 'is', 'a', 'joke', '.', '[SEP]']\n",
      "Word: this \t Prob: 0.00012813373177777976\n",
      "Word: is \t Prob: 0.3984246850013733\n",
      "Word: a \t Prob: 0.06797751039266586\n",
      "Word: joke \t Prob: 0.024301037192344666\n",
      "Word: . \t Prob: 0.9846997857093811\n",
      "\n",
      "Geometric-mean sentence probability: 0.09738048766057691\n",
      "\n",
      "Processing sentence: ['[CLS]', 'this', 'is', 'a', 'joke', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.8030216097831726\n",
      "Word: joke \t Prob: 1.940953552548308e-06\n",
      "Word: a \t Prob: 0.8843458294868469\n",
      "Word: is \t Prob: 0.013980957679450512\n",
      "Word: this \t Prob: 0.9431005716323853\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -2.546178943876709\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -1.224399228108066\n",
      "\n",
      "Processing sentence: ['[CLS]', 'are', 'you', 'kidding', '?', '[SEP]']\n",
      "Word: are \t Prob: 2.6256346245645545e-05\n",
      "Word: you \t Prob: 0.5316267609596252\n",
      "Word: kidding \t Prob: 0.015205665491521358\n",
      "Word: ? \t Prob: 0.9999946355819702\n",
      "\n",
      "Geometric-mean sentence probability: 0.07723379469145132\n",
      "\n",
      "Processing sentence: ['[CLS]', 'are', 'you', 'kidding', '?', '[SEP]']\n",
      "Word: ? \t Prob: 0.00022205077402759343\n",
      "Word: kidding \t Prob: 0.00046649519936181605\n",
      "Word: you \t Prob: 0.06721578538417816\n",
      "Word: are \t Prob: 0.9999508857727051\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -3.130460580391324\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -1.5266133928499364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_sentence_prob(\"This is a sentence.\")\n",
    "get_sentence_prob(\"This is a macrame.\", verbose=False)\n",
    "get_sentence_prob(\"This is a joke.\", verbose=False)\n",
    "get_sentence_prob(\"Are you kidding?\", verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence: ['[CLS]', 'rachel', 'was', 'wearing', 'a', 'lovely', 'satin', 'dress', 'last', 'night', '.', '[SEP]']\n",
      "Word: rachel \t Prob: 1.345694727206137e-05\n",
      "Word: was \t Prob: 0.2645097076892853\n",
      "Word: wearing \t Prob: 3.774421929847449e-05\n",
      "Word: a \t Prob: 0.9133190512657166\n",
      "Word: lovely \t Prob: 0.0004488571430556476\n",
      "Word: satin \t Prob: 0.0010469065746292472\n",
      "Word: dress \t Prob: 0.02077450044453144\n",
      "Word: last \t Prob: 0.003023444674909115\n",
      "Word: night \t Prob: 0.9490013122558594\n",
      "Word: . \t Prob: 0.9899153709411621\n",
      "\n",
      "Geometric-mean sentence probability: 0.019693121325489497\n",
      "\n",
      "Processing sentence: ['[CLS]', 'rachel', 'was', 'wearing', 'a', 'lovely', 'satin', 'dress', 'last', 'night', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.8182555437088013\n",
      "Word: night \t Prob: 0.0001843223290052265\n",
      "Word: last \t Prob: 0.05977332592010498\n",
      "Word: dress \t Prob: 2.075352995234425e-06\n",
      "Word: satin \t Prob: 1.9559594875317998e-05\n",
      "Word: lovely \t Prob: 8.846891432767734e-05\n",
      "Word: a \t Prob: 0.8966140151023865\n",
      "Word: wearing \t Prob: 0.1172424703836441\n",
      "Word: was \t Prob: 0.9986034035682678\n",
      "Word: rachel \t Prob: 0.0008810244617052376\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -4.513779013116921\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -2.247042945895716\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_sentence_prob(\"Rachel was wearing a lovely satin dress last night.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence: ['[CLS]', 'rachel', 'was', 'wearing', 'a', 'lovely', 'satin', 'dress', 'last', 'night', '.', '[SEP]']\n",
      "Word: rachel \t Prob: 1.345694727206137e-05\n",
      "Word: was \t Prob: 0.2645097076892853\n",
      "Word: wearing \t Prob: 3.774421929847449e-05\n",
      "Word: a \t Prob: 0.9133190512657166\n",
      "Word: lovely \t Prob: 0.0004488571430556476\n",
      "Word: satin \t Prob: 0.0010469065746292472\n",
      "Word: dress \t Prob: 0.02077450044453144\n",
      "Word: last \t Prob: 0.003023444674909115\n",
      "Word: night \t Prob: 0.9490013122558594\n",
      "Word: . \t Prob: 0.9899153709411621\n",
      "\n",
      "Geometric-mean sentence probability: 0.019693121325489497\n",
      "\n",
      "Processing sentence: ['[CLS]', 'rachel', 'was', 'wearing', 'a', 'lovely', 'satin', 'dress', 'last', 'night', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.8182555437088013\n",
      "Word: night \t Prob: 0.0001843223290052265\n",
      "Word: last \t Prob: 0.05977332592010498\n",
      "Word: dress \t Prob: 2.075352995234425e-06\n",
      "Word: satin \t Prob: 1.9559594875317998e-05\n",
      "Word: lovely \t Prob: 8.846891432767734e-05\n",
      "Word: a \t Prob: 0.8966140151023865\n",
      "Word: wearing \t Prob: 0.1172424703836441\n",
      "Word: was \t Prob: 0.9986034035682678\n",
      "Word: rachel \t Prob: 0.0008810244617052376\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -4.513779013116921\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -2.247042945895716\n",
      "\n",
      "Processing sentence: ['[CLS]', 'grandma', 'was', 'wearing', 'a', 'lovely', 'satin', 'dress', 'last', 'night', '.', '[SEP]']\n",
      "Word: grandma \t Prob: 3.624638566179783e-06\n",
      "Word: was \t Prob: 0.002532388549298048\n",
      "Word: wearing \t Prob: 0.0006332382909022272\n",
      "Word: a \t Prob: 0.898884654045105\n",
      "Word: lovely \t Prob: 0.001705632428638637\n",
      "Word: satin \t Prob: 0.0009882483864203095\n",
      "Word: dress \t Prob: 0.01763792522251606\n",
      "Word: last \t Prob: 0.0032694607507437468\n",
      "Word: night \t Prob: 0.9110978245735168\n",
      "Word: . \t Prob: 0.9937726855278015\n",
      "\n",
      "Geometric-mean sentence probability: 0.01666797286128835\n",
      "\n",
      "Processing sentence: ['[CLS]', 'grandma', 'was', 'wearing', 'a', 'lovely', 'satin', 'dress', 'last', 'night', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.8182555437088013\n",
      "Word: night \t Prob: 0.0001843223290052265\n",
      "Word: last \t Prob: 0.05977332592010498\n",
      "Word: dress \t Prob: 2.075352995234425e-06\n",
      "Word: satin \t Prob: 1.9559594875317998e-05\n",
      "Word: lovely \t Prob: 8.846891432767734e-05\n",
      "Word: a \t Prob: 0.8966140151023865\n",
      "Word: wearing \t Prob: 0.1172424703836441\n",
      "Word: was \t Prob: 0.9986034035682678\n",
      "Word: grandma \t Prob: 0.00012786401202902198\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -4.674622186779743\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -2.3289771069592273\n",
      "\n",
      "Processing sentence: ['[CLS]', 'mother', 'was', 'wearing', 'a', 'lovely', 'satin', 'dress', 'last', 'night', '.', '[SEP]']\n",
      "Word: mother \t Prob: 4.2665709770517424e-05\n",
      "Word: was \t Prob: 0.007873929105699062\n",
      "Word: wearing \t Prob: 7.239717524498701e-05\n",
      "Word: a \t Prob: 0.8792627453804016\n",
      "Word: lovely \t Prob: 0.000798792636487633\n",
      "Word: satin \t Prob: 0.0017313766293227673\n",
      "Word: dress \t Prob: 0.019959256052970886\n",
      "Word: last \t Prob: 0.0012650423450395465\n",
      "Word: night \t Prob: 0.9516106843948364\n",
      "Word: . \t Prob: 0.9858760237693787\n",
      "\n",
      "Geometric-mean sentence probability: 0.01726323917974152\n",
      "\n",
      "Processing sentence: ['[CLS]', 'mother', 'was', 'wearing', 'a', 'lovely', 'satin', 'dress', 'last', 'night', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.8182555437088013\n",
      "Word: night \t Prob: 0.0001843223290052265\n",
      "Word: last \t Prob: 0.05977332592010498\n",
      "Word: dress \t Prob: 2.075352995234425e-06\n",
      "Word: satin \t Prob: 1.9559594875317998e-05\n",
      "Word: lovely \t Prob: 8.846891432767734e-05\n",
      "Word: a \t Prob: 0.8966140151023865\n",
      "Word: wearing \t Prob: 0.1172424703836441\n",
      "Word: was \t Prob: 0.9986034035682678\n",
      "Word: mother \t Prob: 0.0005006226128898561\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -4.5608817425963935\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -2.271809251708326\n",
      "\n",
      "Processing sentence: ['[CLS]', 'she', 'was', 'wearing', 'a', 'lovely', 'satin', 'dress', 'last', 'night', '.', '[SEP]']\n",
      "Word: she \t Prob: 0.0002144854370271787\n",
      "Word: was \t Prob: 0.9033569693565369\n",
      "Word: wearing \t Prob: 0.00018437218386679888\n",
      "Word: a \t Prob: 0.9347352981567383\n",
      "Word: lovely \t Prob: 0.0006815208471380174\n",
      "Word: satin \t Prob: 0.0013114860048517585\n",
      "Word: dress \t Prob: 0.024374864995479584\n",
      "Word: last \t Prob: 0.00163528963457793\n",
      "Word: night \t Prob: 0.9620522856712341\n",
      "Word: . \t Prob: 0.9905979037284851\n",
      "\n",
      "Geometric-mean sentence probability: 0.03195531365036538\n",
      "\n",
      "Processing sentence: ['[CLS]', 'she', 'was', 'wearing', 'a', 'lovely', 'satin', 'dress', 'last', 'night', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.8182555437088013\n",
      "Word: night \t Prob: 0.0001843223290052265\n",
      "Word: last \t Prob: 0.05977332592010498\n",
      "Word: dress \t Prob: 2.075352995234425e-06\n",
      "Word: satin \t Prob: 1.9559594875317998e-05\n",
      "Word: lovely \t Prob: 8.846891432767734e-05\n",
      "Word: a \t Prob: 0.8966140151023865\n",
      "Word: wearing \t Prob: 0.1172424703836441\n",
      "Word: was \t Prob: 0.9986034035682678\n",
      "Word: she \t Prob: 0.6096646189689636\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -3.96881409859634\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -1.9684293924729874\n",
      "\n",
      "Processing sentence: ['[CLS]', 'he', 'was', 'wearing', 'a', 'lovely', 'satin', 'dress', 'last', 'night', '.', '[SEP]']\n",
      "Word: he \t Prob: 0.0003202789230272174\n",
      "Word: was \t Prob: 0.6659026145935059\n",
      "Word: wearing \t Prob: 0.00015709105355199426\n",
      "Word: a \t Prob: 0.9291734099388123\n",
      "Word: lovely \t Prob: 0.00010252989159198478\n",
      "Word: satin \t Prob: 0.0006155010196380317\n",
      "Word: dress \t Prob: 0.014229005202651024\n",
      "Word: last \t Prob: 0.0015683234669268131\n",
      "Word: night \t Prob: 0.9635945558547974\n",
      "Word: . \t Prob: 0.984560489654541\n",
      "\n",
      "Geometric-mean sentence probability: 0.024261508318773987\n",
      "\n",
      "Processing sentence: ['[CLS]', 'he', 'was', 'wearing', 'a', 'lovely', 'satin', 'dress', 'last', 'night', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.8182555437088013\n",
      "Word: night \t Prob: 0.0001843223290052265\n",
      "Word: last \t Prob: 0.05977332592010498\n",
      "Word: dress \t Prob: 2.075352995234425e-06\n",
      "Word: satin \t Prob: 1.9559594875317998e-05\n",
      "Word: lovely \t Prob: 8.846891432767734e-05\n",
      "Word: a \t Prob: 0.8966140151023865\n",
      "Word: wearing \t Prob: 0.1172424703836441\n",
      "Word: was \t Prob: 0.9986034035682678\n",
      "Word: he \t Prob: 0.0063450220040977\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -4.349250643213357\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -2.1624945674472915\n",
      "\n",
      "Processing sentence: ['[CLS]', 'i', 'was', 'wearing', 'a', 'lovely', 'satin', 'dress', 'last', 'night', '.', '[SEP]']\n",
      "Word: i \t Prob: 0.000585844274610281\n",
      "Word: was \t Prob: 0.5617194771766663\n",
      "Word: wearing \t Prob: 4.494710447033867e-05\n",
      "Word: a \t Prob: 0.8895069360733032\n",
      "Word: lovely \t Prob: 0.0006695505580864847\n",
      "Word: satin \t Prob: 0.0009180004708468914\n",
      "Word: dress \t Prob: 0.02124287374317646\n",
      "Word: last \t Prob: 0.006269972771406174\n",
      "Word: night \t Prob: 0.9602768421173096\n",
      "Word: . \t Prob: 0.9892110824584961\n",
      "\n",
      "Geometric-mean sentence probability: 0.03168316924411985\n",
      "\n",
      "Processing sentence: ['[CLS]', 'i', 'was', 'wearing', 'a', 'lovely', 'satin', 'dress', 'last', 'night', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.8182555437088013\n",
      "Word: night \t Prob: 0.0001843223290052265\n",
      "Word: last \t Prob: 0.05977332592010498\n",
      "Word: dress \t Prob: 2.075352995234425e-06\n",
      "Word: satin \t Prob: 1.9559594875317998e-05\n",
      "Word: lovely \t Prob: 8.846891432767734e-05\n",
      "Word: a \t Prob: 0.8966140151023865\n",
      "Word: wearing \t Prob: 0.1172424703836441\n",
      "Word: was \t Prob: 0.9986034035682678\n",
      "Word: i \t Prob: 0.2957271933555603\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -4.029103397090997\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -1.9987101139234384\n",
      "\n",
      "Processing sentence: ['[CLS]', 'angela', 'was', 'wearing', 'a', 'lovely', 'satin', 'dress', 'last', 'night', '.', '[SEP]']\n",
      "Word: angela \t Prob: 8.668032023706473e-06\n",
      "Word: was \t Prob: 0.0008761899080127478\n",
      "Word: wearing \t Prob: 6.847303302492946e-05\n",
      "Word: a \t Prob: 0.9196966290473938\n",
      "Word: lovely \t Prob: 0.00040084568900056183\n",
      "Word: satin \t Prob: 0.001516903517767787\n",
      "Word: dress \t Prob: 0.015366233885288239\n",
      "Word: last \t Prob: 0.0025214876513928175\n",
      "Word: night \t Prob: 0.9481052756309509\n",
      "Word: . \t Prob: 0.9826761484146118\n",
      "\n",
      "Geometric-mean sentence probability: 0.012164449014934544\n",
      "\n",
      "Processing sentence: ['[CLS]', 'angela', 'was', 'wearing', 'a', 'lovely', 'satin', 'dress', 'last', 'night', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.8182555437088013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: night \t Prob: 0.0001843223290052265\n",
      "Word: last \t Prob: 0.05977332592010498\n",
      "Word: dress \t Prob: 2.075352995234425e-06\n",
      "Word: satin \t Prob: 1.9559594875317998e-05\n",
      "Word: lovely \t Prob: 8.846891432767734e-05\n",
      "Word: a \t Prob: 0.8966140151023865\n",
      "Word: wearing \t Prob: 0.1172424703836441\n",
      "Word: was \t Prob: 0.9986034035682678\n",
      "Word: angela \t Prob: 2.9840008210157976e-05\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -4.795881876110798\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -2.3918587135479314\n",
      "\n",
      "Processing sentence: ['[CLS]', 'roberta', 'was', 'wearing', 'a', 'lovely', 'satin', 'dress', 'last', 'night', '.', '[SEP]']\n",
      "Word: roberta \t Prob: 3.867816758429399e-06\n",
      "Word: was \t Prob: 0.0005287343519739807\n",
      "Word: wearing \t Prob: 0.0002253064449178055\n",
      "Word: a \t Prob: 0.8714913725852966\n",
      "Word: lovely \t Prob: 0.0008630887023173273\n",
      "Word: satin \t Prob: 0.0011990604689344764\n",
      "Word: dress \t Prob: 0.018998507410287857\n",
      "Word: last \t Prob: 0.0027865259908139706\n",
      "Word: night \t Prob: 0.9439453482627869\n",
      "Word: . \t Prob: 0.9862309098243713\n",
      "\n",
      "Geometric-mean sentence probability: 0.01286111814949228\n",
      "\n",
      "Processing sentence: ['[CLS]', 'roberta', 'was', 'wearing', 'a', 'lovely', 'satin', 'dress', 'last', 'night', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.8182555437088013\n",
      "Word: night \t Prob: 0.0001843223290052265\n",
      "Word: last \t Prob: 0.05977332592010498\n",
      "Word: dress \t Prob: 2.075352995234425e-06\n",
      "Word: satin \t Prob: 1.9559594875317998e-05\n",
      "Word: lovely \t Prob: 8.846891432767734e-05\n",
      "Word: a \t Prob: 0.8966140151023865\n",
      "Word: wearing \t Prob: 0.1172424703836441\n",
      "Word: was \t Prob: 0.9986034035682678\n",
      "Word: roberta \t Prob: 1.2631488971237559e-05\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -4.867520062883462\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -2.427329472366985\n",
      "\n",
      "Processing sentence: ['[CLS]', 'running', 'was', 'wearing', 'a', 'lovely', 'satin', 'dress', 'last', 'night', '.', '[SEP]']\n",
      "Word: running \t Prob: 7.049769010336604e-06\n",
      "Word: was \t Prob: 0.0003424289752729237\n",
      "Word: wearing \t Prob: 8.576368600188289e-06\n",
      "Word: a \t Prob: 0.7057843208312988\n",
      "Word: lovely \t Prob: 0.00019137808703817427\n",
      "Word: satin \t Prob: 0.0008118441910482943\n",
      "Word: dress \t Prob: 0.016466159373521805\n",
      "Word: last \t Prob: 0.0014500269899144769\n",
      "Word: night \t Prob: 0.9557685852050781\n",
      "Word: . \t Prob: 0.9879379868507385\n",
      "\n",
      "Geometric-mean sentence probability: 0.007805991084679395\n",
      "\n",
      "Processing sentence: ['[CLS]', 'running', 'was', 'wearing', 'a', 'lovely', 'satin', 'dress', 'last', 'night', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.8182555437088013\n",
      "Word: night \t Prob: 0.0001843223290052265\n",
      "Word: last \t Prob: 0.05977332592010498\n",
      "Word: dress \t Prob: 2.075352995234425e-06\n",
      "Word: satin \t Prob: 1.9559594875317998e-05\n",
      "Word: lovely \t Prob: 8.846891432767734e-05\n",
      "Word: a \t Prob: 0.8966140151023865\n",
      "Word: wearing \t Prob: 0.1172424703836441\n",
      "Word: was \t Prob: 0.9986034035682678\n",
      "Word: running \t Prob: 5.459548333419662e-07\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -5.129304377992715\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -2.5607491934540176\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_sentence_prob(\"Rachel was wearing a lovely satin dress last night.\")\n",
    "get_sentence_prob(\"Grandma was wearing a lovely satin dress last night.\")\n",
    "get_sentence_prob(\"Mother was wearing a lovely satin dress last night.\")\n",
    "get_sentence_prob(\"She was wearing a lovely satin dress last night.\")\n",
    "get_sentence_prob(\"He was wearing a lovely satin dress last night.\")\n",
    "get_sentence_prob(\"I was wearing a lovely satin dress last night.\")\n",
    "get_sentence_prob(\"Angela was wearing a lovely satin dress last night.\")\n",
    "get_sentence_prob(\"Roberta was wearing a lovely satin dress last night.\")\n",
    "get_sentence_prob(\"Running was wearing a lovely satin dress last night.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence: ['[CLS]', 'the', 'man', 'ate', 'the', 'steak', '.', '[SEP]']\n",
      "Word: the \t Prob: 0.006482909899204969\n",
      "Word: man \t Prob: 0.0008543190779164433\n",
      "Word: ate \t Prob: 0.00030972290551289916\n",
      "Word: the \t Prob: 0.16035766899585724\n",
      "Word: steak \t Prob: 0.004650171846151352\n",
      "Word: . \t Prob: 0.9944341778755188\n",
      "\n",
      "Geometric-mean sentence probability: 0.032588342448014056\n",
      "\n",
      "Processing sentence: ['[CLS]', 'the', 'man', 'ate', 'the', 'steak', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.7197229266166687\n",
      "Word: steak \t Prob: 8.405078006035183e-06\n",
      "Word: the \t Prob: 0.024790508672595024\n",
      "Word: ate \t Prob: 0.014627532102167606\n",
      "Word: man \t Prob: 4.835774234379642e-05\n",
      "Word: the \t Prob: 0.9430958032608032\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -3.7416474418714643\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -1.8545295497117251\n",
      "\n",
      "Processing sentence: ['[CLS]', 'the', 'man', 'who', 'arrived', 'late', 'ate', 'the', 'steak', 'with', 'a', 'glass', 'of', 'wine', '.', '[SEP]']\n",
      "Word: the \t Prob: 0.08750123530626297\n",
      "Word: man \t Prob: 0.00010430917609483004\n",
      "Word: who \t Prob: 0.29403290152549744\n",
      "Word: arrived \t Prob: 1.564584999869112e-05\n",
      "Word: late \t Prob: 0.0014849362196400762\n",
      "Word: ate \t Prob: 2.5576040570740588e-05\n",
      "Word: the \t Prob: 0.04323061928153038\n",
      "Word: steak \t Prob: 0.013004593551158905\n",
      "Word: with \t Prob: 0.42883676290512085\n",
      "Word: a \t Prob: 0.7873855233192444\n",
      "Word: glass \t Prob: 0.00016356499691028148\n",
      "Word: of \t Prob: 0.9950628876686096\n",
      "Word: wine \t Prob: 0.6224004626274109\n",
      "Word: . \t Prob: 0.9916564226150513\n",
      "\n",
      "Geometric-mean sentence probability: 0.025420745713864216\n",
      "\n",
      "Processing sentence: ['[CLS]', 'the', 'man', 'who', 'arrived', 'late', 'ate', 'the', 'steak', 'with', 'a', 'glass', 'of', 'wine', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.7609730958938599\n",
      "Word: wine \t Prob: 1.0455462870595511e-05\n",
      "Word: of \t Prob: 0.004286559764295816\n",
      "Word: glass \t Prob: 0.039599135518074036\n",
      "Word: a \t Prob: 0.9149152040481567\n",
      "Word: with \t Prob: 0.05156519636511803\n",
      "Word: steak \t Prob: 8.301284651679453e-06\n",
      "Word: the \t Prob: 0.19019478559494019\n",
      "Word: ate \t Prob: 0.005243169609457254\n",
      "Word: late \t Prob: 4.160567641520174e-06\n",
      "Word: arrived \t Prob: 0.0010477282339707017\n",
      "Word: who \t Prob: 0.5149261951446533\n",
      "Word: man \t Prob: 0.032015156000852585\n",
      "Word: the \t Prob: 0.9333303570747375\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -4.094468482304364\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -2.03452386829525\n",
      "\n",
      "Processing sentence: ['[CLS]', 'the', 'steak', 'was', 'eaten', 'by', 'the', 'man', '.', '[SEP]']\n",
      "Word: the \t Prob: 0.0031236112117767334\n",
      "Word: steak \t Prob: 8.519217772118282e-06\n",
      "Word: was \t Prob: 0.07083046436309814\n",
      "Word: eaten \t Prob: 0.00020068850426468998\n",
      "Word: by \t Prob: 0.1012411043047905\n",
      "Word: the \t Prob: 0.5529958009719849\n",
      "Word: man \t Prob: 0.002768035512417555\n",
      "Word: . \t Prob: 0.9761257767677307\n",
      "\n",
      "Geometric-mean sentence probability: 0.023755027861613636\n",
      "\n",
      "Processing sentence: ['[CLS]', 'the', 'steak', 'was', 'eaten', 'by', 'the', 'man', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.7406781911849976\n",
      "Word: man \t Prob: 0.00042284070514142513\n",
      "Word: the \t Prob: 0.024415303021669388\n",
      "Word: by \t Prob: 0.0018896032124757767\n",
      "Word: eaten \t Prob: 0.0015599207254126668\n",
      "Word: was \t Prob: 0.7328842878341675\n",
      "Word: steak \t Prob: 0.0003375005326233804\n",
      "Word: the \t Prob: 0.8093088269233704\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -3.303204420208931\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -1.6397246961736587\n",
      "\n",
      "Processing sentence: ['[CLS]', 'the', 'stake', 'ate', 'the', 'man', '.', '[SEP]']\n",
      "Word: the \t Prob: 0.006482909899204969\n",
      "Word: stake \t Prob: 4.5493732613977045e-05\n",
      "Word: ate \t Prob: 1.0680463446988142e-06\n",
      "Word: the \t Prob: 0.09574969112873077\n",
      "Word: man \t Prob: 0.0020853555761277676\n",
      "Word: . \t Prob: 0.9986978769302368\n",
      "\n",
      "Geometric-mean sentence probability: 0.009435347651865551\n",
      "\n",
      "Processing sentence: ['[CLS]', 'the', 'stake', 'ate', 'the', 'man', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.7197229266166687\n",
      "Word: man \t Prob: 0.00013108947314321995\n",
      "Word: the \t Prob: 0.06275036931037903\n",
      "Word: ate \t Prob: 9.676985428086482e-06\n",
      "Word: stake \t Prob: 5.784730092273094e-05\n",
      "Word: the \t Prob: 0.850401759147644\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -4.187827710062265\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -2.0891961812052\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_sentence_prob(\"The man ate the steak.\")\n",
    "get_sentence_prob(\"The man who arrived late ate the steak with a glass of wine.\")\n",
    "get_sentence_prob(\"The steak was eaten by the man.\")\n",
    "get_sentence_prob(\"The stake ate the man.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence: ['[CLS]', 'he', 'was', 'born', 'in', 'berlin', '.', '[SEP]']\n",
      "Word: he \t Prob: 0.0006875116960145533\n",
      "Word: was \t Prob: 0.611086905002594\n",
      "Word: born \t Prob: 0.0001007601385936141\n",
      "Word: in \t Prob: 0.9955852031707764\n",
      "Word: berlin \t Prob: 0.02386103756725788\n",
      "Word: . \t Prob: 0.9999347925186157\n",
      "\n",
      "Geometric-mean sentence probability: 0.0750414823747486\n",
      "\n",
      "Processing sentence: ['[CLS]', 'he', 'was', 'born', 'in', 'berlin', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.7197229266166687\n",
      "Word: berlin \t Prob: 7.354922854574397e-05\n",
      "Word: in \t Prob: 0.07671105861663818\n",
      "Word: born \t Prob: 0.0007875352748669684\n",
      "Word: was \t Prob: 0.999992847442627\n",
      "Word: he \t Prob: 0.7967859506607056\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -2.473491515967453\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -1.199225016796352\n",
      "\n",
      "Processing sentence: ['[CLS]', 'he', 'was', 'born', 'in', 'santiago', '.', '[SEP]']\n",
      "Word: he \t Prob: 0.0006875116960145533\n",
      "Word: was \t Prob: 0.611086905002594\n",
      "Word: born \t Prob: 0.0001007601385936141\n",
      "Word: in \t Prob: 0.9955852031707764\n",
      "Word: santiago \t Prob: 0.001118713291361928\n",
      "Word: . \t Prob: 0.9998825788497925\n",
      "\n",
      "Geometric-mean sentence probability: 0.05118907211973402\n",
      "\n",
      "Processing sentence: ['[CLS]', 'he', 'was', 'born', 'in', 'santiago', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.7197229266166687\n",
      "Word: santiago \t Prob: 1.3199482964409981e-05\n",
      "Word: in \t Prob: 0.002953069983050227\n",
      "Word: born \t Prob: 0.0027990778908133507\n",
      "Word: was \t Prob: 0.9999200105667114\n",
      "Word: he \t Prob: 0.7612152695655823\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -2.9425644878565436\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -1.4456877078684047\n",
      "\n",
      "Processing sentence: ['[CLS]', 'he', 'was', 'born', 'in', 'france', '.', '[SEP]']\n",
      "Word: he \t Prob: 0.0006875116960145533\n",
      "Word: was \t Prob: 0.611086905002594\n",
      "Word: born \t Prob: 0.0001007601385936141\n",
      "Word: in \t Prob: 0.9955852031707764\n",
      "Word: france \t Prob: 0.002361555816605687\n",
      "Word: . \t Prob: 0.9997918009757996\n",
      "\n",
      "Geometric-mean sentence probability: 0.056199474769340715\n",
      "\n",
      "Processing sentence: ['[CLS]', 'he', 'was', 'born', 'in', 'france', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.7197229266166687\n",
      "Word: france \t Prob: 3.507085784804076e-05\n",
      "Word: in \t Prob: 0.19816343486309052\n",
      "Word: born \t Prob: 0.0343296080827713\n",
      "Word: was \t Prob: 0.9999494552612305\n",
      "Word: he \t Prob: 0.7930527329444885\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -1.9761693590985487\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -0.9599849421646041\n",
      "\n",
      "Processing sentence: ['[CLS]', 'he', 'was', 'born', 'in', 'window', '.', '[SEP]']\n",
      "Word: he \t Prob: 0.0006875116960145533\n",
      "Word: was \t Prob: 0.611086905002594\n",
      "Word: born \t Prob: 0.0001007601385936141\n",
      "Word: in \t Prob: 0.9955852031707764\n",
      "Word: window \t Prob: 1.2145428627263755e-06\n",
      "Word: . \t Prob: 0.9915589094161987\n",
      "\n",
      "Geometric-mean sentence probability: 0.02178638659308009\n",
      "\n",
      "Processing sentence: ['[CLS]', 'he', 'was', 'born', 'in', 'window', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.7197229266166687\n",
      "Word: window \t Prob: 4.7352070396300405e-05\n",
      "Word: in \t Prob: 0.008949845097959042\n",
      "Word: born \t Prob: 2.647951987455599e-05\n",
      "Word: was \t Prob: 0.9994819760322571\n",
      "Word: he \t Prob: 0.6543523073196411\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -3.245834330104117\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -1.6120239717555183\n",
      "\n",
      "Processing sentence: ['[CLS]', 'he', 'was', 'born', 'in', 'was', '.', '[SEP]']\n",
      "Word: he \t Prob: 0.0006875116960145533\n",
      "Word: was \t Prob: 0.611086905002594\n",
      "Word: born \t Prob: 0.0001007601385936141\n",
      "Word: in \t Prob: 0.9955852031707764\n",
      "Word: was \t Prob: 1.0944118002953473e-06\n",
      "Word: . \t Prob: 0.9949527978897095\n",
      "\n",
      "Geometric-mean sentence probability: 0.02151377843404532\n",
      "\n",
      "Processing sentence: ['[CLS]', 'he', 'was', 'born', 'in', 'was', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.7197229266166687\n",
      "Word: was \t Prob: 5.345148383639753e-05\n",
      "Word: in \t Prob: 5.982379298075102e-05\n",
      "Word: born \t Prob: 0.00020530555048026145\n",
      "Word: was \t Prob: 0.999850869178772\n",
      "Word: he \t Prob: 0.7139879465103149\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -3.5897227986661164\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -1.7841045101160355\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_sentence_prob(\"He was born in Berlin.\")\n",
    "get_sentence_prob(\"He was born in Santiago.\")\n",
    "get_sentence_prob(\"He was born in France.\")\n",
    "get_sentence_prob(\"He was born in window.\")\n",
    "get_sentence_prob(\"He was born in was.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence: ['[CLS]', 'i', 'fed', 'my', 'cat', 'some', 'of', 'it', 'and', 'he', 'damn', 'near', 'passed', 'out', '.', '[SEP]']\n",
      "Word: i \t Prob: 0.0005238083540461957\n",
      "Word: fed \t Prob: 1.7332116840407252e-05\n",
      "Word: my \t Prob: 0.012338080443441868\n",
      "Word: cat \t Prob: 0.00244920514523983\n",
      "Word: some \t Prob: 0.007367619778960943\n",
      "Word: of \t Prob: 1.723681816656608e-05\n",
      "Word: it \t Prob: 0.00012771011097356677\n",
      "Word: and \t Prob: 0.5446289777755737\n",
      "Word: he \t Prob: 0.0061583081260323524\n",
      "Word: damn \t Prob: 2.3060283638187684e-05\n",
      "Word: near \t Prob: 0.4169158637523651\n",
      "Word: passed \t Prob: 7.57075467845425e-05\n",
      "Word: out \t Prob: 0.9994945526123047\n",
      "Word: . \t Prob: 0.9991564750671387\n",
      "\n",
      "Geometric-mean sentence probability: 0.006526921971877533\n",
      "\n",
      "Processing sentence: ['[CLS]', 'i', 'fed', 'my', 'cat', 'some', 'of', 'it', 'and', 'he', 'damn', 'near', 'passed', 'out', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.7609730958938599\n",
      "Word: out \t Prob: 0.0001479800557717681\n",
      "Word: passed \t Prob: 0.0015395785449072719\n",
      "Word: near \t Prob: 0.00010126514098374173\n",
      "Word: damn \t Prob: 0.7008697390556335\n",
      "Word: he \t Prob: 0.048276130110025406\n",
      "Word: and \t Prob: 0.5079375505447388\n",
      "Word: it \t Prob: 2.4723083697608672e-05\n",
      "Word: of \t Prob: 0.06822692602872849\n",
      "Word: some \t Prob: 0.0040093897841870785\n",
      "Word: cat \t Prob: 1.8786481632560026e-06\n",
      "Word: my \t Prob: 0.10841826349496841\n",
      "Word: fed \t Prob: 0.17128999531269073\n",
      "Word: i \t Prob: 0.9958482980728149\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -4.051020858780248\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -2.0222469684041853\n",
      "\n",
      "Processing sentence: ['[CLS]', 'i', 'fed', 'my', 'dog', 'some', 'of', 'it', 'and', 'he', 'damn', 'near', 'passed', 'out', '.', '[SEP]']\n",
      "Word: i \t Prob: 0.0005238083540461957\n",
      "Word: fed \t Prob: 1.7332116840407252e-05\n",
      "Word: my \t Prob: 0.012338080443441868\n",
      "Word: dog \t Prob: 0.001873779227025807\n",
      "Word: some \t Prob: 0.024183275178074837\n",
      "Word: of \t Prob: 6.944186316104606e-05\n",
      "Word: it \t Prob: 0.00018041624571196735\n",
      "Word: and \t Prob: 0.5516229867935181\n",
      "Word: he \t Prob: 0.0019600701052695513\n",
      "Word: damn \t Prob: 2.8778084015357308e-05\n",
      "Word: near \t Prob: 0.425414502620697\n",
      "Word: passed \t Prob: 8.339445776073262e-05\n",
      "Word: out \t Prob: 0.9994495511054993\n",
      "Word: . \t Prob: 0.9986190795898438\n",
      "\n",
      "Geometric-mean sentence probability: 0.007334035642970822\n",
      "\n",
      "Processing sentence: ['[CLS]', 'i', 'fed', 'my', 'dog', 'some', 'of', 'it', 'and', 'he', 'damn', 'near', 'passed', 'out', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.7609730958938599\n",
      "Word: out \t Prob: 0.0001479800557717681\n",
      "Word: passed \t Prob: 0.0015395785449072719\n",
      "Word: near \t Prob: 0.00010126514098374173\n",
      "Word: damn \t Prob: 0.7008697390556335\n",
      "Word: he \t Prob: 0.048276130110025406\n",
      "Word: and \t Prob: 0.5079375505447388\n",
      "Word: it \t Prob: 2.4723083697608672e-05\n",
      "Word: of \t Prob: 0.06822692602872849\n",
      "Word: some \t Prob: 0.0040093897841870785\n",
      "Word: dog \t Prob: 1.8579952666186728e-05\n",
      "Word: my \t Prob: 0.25622084736824036\n",
      "Word: fed \t Prob: 0.16240531206130981\n",
      "Word: i \t Prob: 0.9969239830970764\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -3.857309002560214\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -1.9249874834586216\n",
      "\n",
      "Processing sentence: ['[CLS]', 'i', 'fed', 'my', 'window', 'some', 'of', 'it', 'and', 'he', 'damn', 'near', 'passed', 'out', '.', '[SEP]']\n",
      "Word: i \t Prob: 0.0005238083540461957\n",
      "Word: fed \t Prob: 1.7332116840407252e-05\n",
      "Word: my \t Prob: 0.012338080443441868\n",
      "Word: window \t Prob: 3.074419146287255e-05\n",
      "Word: some \t Prob: 5.5066415370674804e-05\n",
      "Word: of \t Prob: 0.0002885802823584527\n",
      "Word: it \t Prob: 0.0003021394950337708\n",
      "Word: and \t Prob: 0.3958088457584381\n",
      "Word: he \t Prob: 5.880855678697117e-05\n",
      "Word: damn \t Prob: 9.875305295281578e-06\n",
      "Word: near \t Prob: 0.23852427303791046\n",
      "Word: passed \t Prob: 0.00013139680959284306\n",
      "Word: out \t Prob: 0.9993270635604858\n",
      "Word: . \t Prob: 0.999427080154419\n",
      "\n",
      "Geometric-mean sentence probability: 0.0031968005070678227\n",
      "\n",
      "Processing sentence: ['[CLS]', 'i', 'fed', 'my', 'window', 'some', 'of', 'it', 'and', 'he', 'damn', 'near', 'passed', 'out', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.7609730958938599\n",
      "Word: out \t Prob: 0.0001479800557717681\n",
      "Word: passed \t Prob: 0.0015395785449072719\n",
      "Word: near \t Prob: 0.00010126514098374173\n",
      "Word: damn \t Prob: 0.7008697390556335\n",
      "Word: he \t Prob: 0.048276130110025406\n",
      "Word: and \t Prob: 0.5079375505447388\n",
      "Word: it \t Prob: 2.4723083697608672e-05\n",
      "Word: of \t Prob: 0.06822692602872849\n",
      "Word: some \t Prob: 0.0040093897841870785\n",
      "Word: window \t Prob: 4.564195023704087e-06\n",
      "Word: my \t Prob: 0.055196020752191544\n",
      "Word: fed \t Prob: 0.00012052484089508653\n",
      "Word: i \t Prob: 0.9672557711601257\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -4.493258770322427\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -2.2450309849076797\n",
      "\n",
      "Processing sentence: ['[CLS]', 'i', 'fed', 'my', 'the', 'some', 'of', 'it', 'and', 'he', 'damn', 'near', 'passed', 'out', '.', '[SEP]']\n",
      "Word: i \t Prob: 0.0005238083540461957\n",
      "Word: fed \t Prob: 1.7332116840407252e-05\n",
      "Word: my \t Prob: 0.012338080443441868\n",
      "Word: the \t Prob: 0.0005163894966244698\n",
      "Word: some \t Prob: 3.3537235140101984e-05\n",
      "Word: of \t Prob: 0.017259739339351654\n",
      "Word: it \t Prob: 0.00356102897785604\n",
      "Word: and \t Prob: 0.40840384364128113\n",
      "Word: he \t Prob: 0.00035771005786955357\n",
      "Word: damn \t Prob: 2.1192281565163285e-06\n",
      "Word: near \t Prob: 0.21973887085914612\n",
      "Word: passed \t Prob: 0.00019226186850573868\n",
      "Word: out \t Prob: 0.9997089505195618\n",
      "Word: . \t Prob: 0.998624324798584\n",
      "\n",
      "Geometric-mean sentence probability: 0.005781177192842347\n",
      "\n",
      "Processing sentence: ['[CLS]', 'i', 'fed', 'my', 'the', 'some', 'of', 'it', 'and', 'he', 'damn', 'near', 'passed', 'out', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.7609730958938599\n",
      "Word: out \t Prob: 0.0001479800557717681\n",
      "Word: passed \t Prob: 0.0015395785449072719\n",
      "Word: near \t Prob: 0.00010126514098374173\n",
      "Word: damn \t Prob: 0.7008697390556335\n",
      "Word: he \t Prob: 0.048276130110025406\n",
      "Word: and \t Prob: 0.5079375505447388\n",
      "Word: it \t Prob: 2.4723083697608672e-05\n",
      "Word: of \t Prob: 0.06822692602872849\n",
      "Word: some \t Prob: 0.0040093897841870785\n",
      "Word: the \t Prob: 0.00020219777070451528\n",
      "Word: my \t Prob: 6.479790317825973e-05\n",
      "Word: fed \t Prob: 0.004314483143389225\n",
      "Word: i \t Prob: 0.8631967306137085\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -4.461528282612562\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -2.22787355270986\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_sentence_prob(\"I fed my cat some of it and he damn near passed out.\")\n",
    "get_sentence_prob(\"I fed my dog some of it and he damn near passed out.\")\n",
    "get_sentence_prob(\"I fed my window some of it and he damn near passed out.\")\n",
    "get_sentence_prob(\"I fed my the some of it and he damn near passed out.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should have similar/high probs\n",
      "\n",
      "Processing sentence: ['[CLS]', 'i', 'forgot', 'to', 'take', 'my', 'medicine', '.', '[SEP]']\n",
      "Word: i \t Prob: 0.0010684080189093947\n",
      "Word: forgot \t Prob: 0.00016382183821406215\n",
      "Word: to \t Prob: 0.06681681424379349\n",
      "Word: take \t Prob: 0.0745348259806633\n",
      "Word: my \t Prob: 0.2779442071914673\n",
      "Word: medicine \t Prob: 0.0129512008279562\n",
      "Word: . \t Prob: 0.9979066848754883\n",
      "\n",
      "Normalized forward sentence prob: log(P(sentence)) / sent_length: -2.9432893383006253\n",
      "\n",
      "Processing sentence: ['[CLS]', 'i', 'forgot', 'to', 'take', 'my', 'medicine', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.6934828162193298\n",
      "Word: medicine \t Prob: 4.02187870349735e-05\n",
      "Word: my \t Prob: 4.184951831120998e-05\n",
      "Word: take \t Prob: 0.012042323127388954\n",
      "Word: to \t Prob: 0.7947912812232971\n",
      "Word: forgot \t Prob: 0.007729522883892059\n",
      "Word: i \t Prob: 0.9906209707260132\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -3.343307657788197\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -3.143298498044411\n",
      "\n",
      "Processing sentence: ['[CLS]', 'i', 'forgot', 'to', 'take', 'my', 'medicines', '.', '[SEP]']\n",
      "Word: i \t Prob: 0.0010684080189093947\n",
      "Word: forgot \t Prob: 0.00016382183821406215\n",
      "Word: to \t Prob: 0.06681681424379349\n",
      "Word: take \t Prob: 0.0745348259806633\n",
      "Word: my \t Prob: 0.2779442071914673\n",
      "Word: medicines \t Prob: 0.0005950936465524137\n",
      "Word: . \t Prob: 0.989775538444519\n",
      "\n",
      "Normalized forward sentence prob: log(P(sentence)) / sent_length: -3.286445624091559\n",
      "\n",
      "Processing sentence: ['[CLS]', 'i', 'forgot', 'to', 'take', 'my', 'medicines', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.6934828162193298\n",
      "Word: medicines \t Prob: 3.528468369040638e-06\n",
      "Word: my \t Prob: 0.0002190234517911449\n",
      "Word: take \t Prob: 0.0018995603313669562\n",
      "Word: to \t Prob: 0.45271822810173035\n",
      "Word: forgot \t Prob: 0.021876074373722076\n",
      "Word: i \t Prob: 0.977046549320221\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -3.5834675228430166\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -3.4349565734672876\n",
      "\n",
      "Processing sentence: ['[CLS]', 'i', 'forgot', 'to', 'take', 'my', 'medication', '.', '[SEP]']\n",
      "Word: i \t Prob: 0.0010684080189093947\n",
      "Word: forgot \t Prob: 0.00016382183821406215\n",
      "Word: to \t Prob: 0.06681681424379349\n",
      "Word: take \t Prob: 0.0745348259806633\n",
      "Word: my \t Prob: 0.2779442071914673\n",
      "Word: medication \t Prob: 0.051329106092453\n",
      "Word: . \t Prob: 0.9989068508148193\n",
      "\n",
      "Normalized forward sentence prob: log(P(sentence)) / sent_length: -2.790170312121821\n",
      "\n",
      "Processing sentence: ['[CLS]', 'i', 'forgot', 'to', 'take', 'my', 'medication', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.6934828162193298\n",
      "Word: medication \t Prob: 2.1060770905023674e-06\n",
      "Word: my \t Prob: 0.0012697138590738177\n",
      "Word: take \t Prob: 0.004030628129839897\n",
      "Word: to \t Prob: 0.8402053713798523\n",
      "Word: forgot \t Prob: 0.021604016423225403\n",
      "Word: i \t Prob: 0.9980584979057312\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -3.292270846910671\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -3.041220579516246\n",
      "\n",
      "Processing sentence: ['[CLS]', 'i', 'forgot', 'to', 'take', 'my', 'pills', '.', '[SEP]']\n",
      "Word: i \t Prob: 0.0010684080189093947\n",
      "Word: forgot \t Prob: 0.00016382183821406215\n",
      "Word: to \t Prob: 0.06681681424379349\n",
      "Word: take \t Prob: 0.0745348259806633\n",
      "Word: my \t Prob: 0.2779442071914673\n",
      "Word: pills \t Prob: 0.05692721903324127\n",
      "Word: . \t Prob: 0.9981067180633545\n",
      "\n",
      "Normalized forward sentence prob: log(P(sentence)) / sent_length: -2.778757612621929\n",
      "\n",
      "Processing sentence: ['[CLS]', 'i', 'forgot', 'to', 'take', 'my', 'pills', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.6934828162193298\n",
      "Word: pills \t Prob: 2.228725679742638e-05\n",
      "Word: my \t Prob: 0.0016558078350499272\n",
      "Word: take \t Prob: 0.0074091386049985886\n",
      "Word: to \t Prob: 0.8428017497062683\n",
      "Word: forgot \t Prob: 0.031514398753643036\n",
      "Word: i \t Prob: 0.9979934692382812\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -2.890708266524598\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -2.8347329395732634\n",
      "\n",
      "Should have low probs\n",
      "\n",
      "Processing sentence: ['[CLS]', 'i', 'forgot', 'to', 'take', 'my', 'turn', '.', '[SEP]']\n",
      "Word: i \t Prob: 0.0010684080189093947\n",
      "Word: forgot \t Prob: 0.00016382183821406215\n",
      "Word: to \t Prob: 0.06681681424379349\n",
      "Word: take \t Prob: 0.0745348259806633\n",
      "Word: my \t Prob: 0.2779442071914673\n",
      "Word: turn \t Prob: 0.0013968853745609522\n",
      "Word: . \t Prob: 0.9957332015037537\n",
      "\n",
      "Normalized forward sentence prob: log(P(sentence)) / sent_length: -3.190969772843851\n",
      "\n",
      "Processing sentence: ['[CLS]', 'i', 'forgot', 'to', 'take', 'my', 'turn', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.6934828162193298\n",
      "Word: turn \t Prob: 4.771081876242533e-06\n",
      "Word: my \t Prob: 0.2669321894645691\n",
      "Word: take \t Prob: 0.004385394509881735\n",
      "Word: to \t Prob: 0.7648032903671265\n",
      "Word: forgot \t Prob: 0.0003833671216852963\n",
      "Word: i \t Prob: 0.9683481454849243\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -3.059557806700468\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -3.1252637897721596\n",
      "\n",
      "Processing sentence: ['[CLS]', 'i', 'forgot', 'to', 'take', 'my', 'medical', '.', '[SEP]']\n",
      "Word: i \t Prob: 0.0010684080189093947\n",
      "Word: forgot \t Prob: 0.00016382183821406215\n",
      "Word: to \t Prob: 0.06681681424379349\n",
      "Word: take \t Prob: 0.0745348259806633\n",
      "Word: my \t Prob: 0.2779442071914673\n",
      "Word: medical \t Prob: 1.1320313205942512e-05\n",
      "Word: . \t Prob: 0.9927952885627747\n",
      "\n",
      "Normalized forward sentence prob: log(P(sentence)) / sent_length: -3.726342761112998\n",
      "\n",
      "Processing sentence: ['[CLS]', 'i', 'forgot', 'to', 'take', 'my', 'medical', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.6934828162193298\n",
      "Word: medical \t Prob: 3.0078257623245008e-05\n",
      "Word: my \t Prob: 0.00015173984866123646\n",
      "Word: take \t Prob: 0.0012321736430749297\n",
      "Word: to \t Prob: 0.6954056620597839\n",
      "Word: forgot \t Prob: 0.004462035372853279\n",
      "Word: i \t Prob: 0.9303334355354309\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -3.56863092051612\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -3.647486840814559\n",
      "\n",
      "Processing sentence: ['[CLS]', 'i', 'forgot', 'to', 'take', 'my', 'medical', '##ly', '.', '[SEP]']\n",
      "Word: i \t Prob: 0.0015485387993976474\n",
      "Word: forgot \t Prob: 4.664463995140977e-05\n",
      "Word: to \t Prob: 0.027499310672283173\n",
      "Word: take \t Prob: 0.08735671639442444\n",
      "Word: my \t Prob: 0.23728741705417633\n",
      "Word: medical \t Prob: 0.0009902380406856537\n",
      "Word: ##ly \t Prob: 0.00012317694199737161\n",
      "Word: . \t Prob: 0.982501208782196\n",
      "\n",
      "Normalized forward sentence prob: log(P(sentence)) / sent_length: -3.985033762641251\n",
      "\n",
      "Processing sentence: ['[CLS]', 'i', 'forgot', 'to', 'take', 'my', 'medical', '##ly', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.7406781911849976\n",
      "Word: ##ly \t Prob: 0.0010952855227515101\n",
      "Word: medical \t Prob: 2.77360431937268e-05\n",
      "Word: my \t Prob: 7.509607712563593e-06\n",
      "Word: take \t Prob: 0.0014514537760987878\n",
      "Word: to \t Prob: 0.722886323928833\n",
      "Word: forgot \t Prob: 0.003880409523844719\n",
      "Word: i \t Prob: 0.4361361563205719\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -4.265034198760986\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -4.125033980701119\n",
      "\n",
      "Processing sentence: ['[CLS]', 'i', 'forgot', 'to', 'take', 'my', 'turned', '.', '[SEP]']\n",
      "Word: i \t Prob: 0.0010684080189093947\n",
      "Word: forgot \t Prob: 0.00016382183821406215\n",
      "Word: to \t Prob: 0.06681681424379349\n",
      "Word: take \t Prob: 0.0745348259806633\n",
      "Word: my \t Prob: 0.2779442071914673\n",
      "Word: turned \t Prob: 2.584178673714632e-06\n",
      "Word: . \t Prob: 0.9974840879440308\n",
      "\n",
      "Normalized forward sentence prob: log(P(sentence)) / sent_length: -3.8899514621330633\n",
      "\n",
      "Processing sentence: ['[CLS]', 'i', 'forgot', 'to', 'take', 'my', 'turned', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.6934828162193298\n",
      "Word: turned \t Prob: 1.6123369732667925e-06\n",
      "Word: my \t Prob: 2.0587198378052562e-05\n",
      "Word: take \t Prob: 0.001900182105600834\n",
      "Word: to \t Prob: 0.9658055901527405\n",
      "Word: forgot \t Prob: 0.0007600958924740553\n",
      "Word: i \t Prob: 0.9634267687797546\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -4.223846543580294\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -4.056899002856678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Should have similar/high probs\\n\")\n",
    "get_sentence_prob(\"I forgot to take my medicine.\")\n",
    "get_sentence_prob(\"I forgot to take my medicines.\")\n",
    "get_sentence_prob(\"I forgot to take my medication.\")\n",
    "get_sentence_prob(\"I forgot to take my pills.\")\n",
    "print(\"Should have low probs\\n\")\n",
    "get_sentence_prob(\"I forgot to take my turn.\")\n",
    "get_sentence_prob(\"I forgot to take my medical.\")\n",
    "get_sentence_prob(\"I forgot to take my medically.\")\n",
    "get_sentence_prob(\"I forgot to take my turned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence: ['[CLS]', 'we', 'will', 'explore', 'the', 'elements', 'used', 'to', 'construct', 'sentences', ',', 'and', 'what', 'parts', 'of', 'speech', 'are', 'used', 'to', 'expand', 'and', 'elaborate', 'on', 'them', '.', '[SEP]']\n",
      "Word: we \t Prob: 1.6642563423374668e-05\n",
      "Word: will \t Prob: 0.002434785244986415\n",
      "Word: explore \t Prob: 1.6068875993369147e-05\n",
      "Word: the \t Prob: 0.6480313539505005\n",
      "Word: elements \t Prob: 0.00011011799506377429\n",
      "Word: used \t Prob: 4.9860776925925165e-05\n",
      "Word: to \t Prob: 0.041129741817712784\n",
      "Word: construct \t Prob: 0.003627343336120248\n",
      "Word: sentences \t Prob: 7.629900551364699e-07\n",
      "Word: , \t Prob: 0.0999969020485878\n",
      "Word: and \t Prob: 0.08384449779987335\n",
      "Word: what \t Prob: 0.0009997623274102807\n",
      "Word: parts \t Prob: 0.005878846161067486\n",
      "Word: of \t Prob: 0.005989460740238428\n",
      "Word: speech \t Prob: 0.0002994531823787838\n",
      "Word: are \t Prob: 0.9055652022361755\n",
      "Word: used \t Prob: 0.10661078989505768\n",
      "Word: to \t Prob: 0.9451584219932556\n",
      "Word: expand \t Prob: 2.0943292838637717e-05\n",
      "Word: and \t Prob: 0.09903806447982788\n",
      "Word: elaborate \t Prob: 0.0006932351971045136\n",
      "Word: on \t Prob: 0.039937544614076614\n",
      "Word: them \t Prob: 0.423604816198349\n",
      "Word: . \t Prob: 0.9987418055534363\n",
      "\n",
      "Normalized forward sentence prob: log(P(sentence)) / sent_length: -4.896247161364254\n",
      "\n",
      "Processing sentence: ['[CLS]', 'we', 'will', 'explore', 'the', 'elements', 'used', 'to', 'construct', 'sentences', ',', 'and', 'what', 'parts', 'of', 'speech', 'are', 'used', 'to', 'expand', 'and', 'elaborate', 'on', 'them', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.6952449679374695\n",
      "Word: them \t Prob: 0.00023009766300674528\n",
      "Word: on \t Prob: 0.06231745705008507\n",
      "Word: elaborate \t Prob: 2.6263696781825274e-05\n",
      "Word: and \t Prob: 0.111882783472538\n",
      "Word: expand \t Prob: 3.0438391718234925e-07\n",
      "Word: to \t Prob: 0.626500129699707\n",
      "Word: used \t Prob: 0.008128069341182709\n",
      "Word: are \t Prob: 0.2639956772327423\n",
      "Word: speech \t Prob: 3.847288462566212e-05\n",
      "Word: of \t Prob: 0.022704225033521652\n",
      "Word: parts \t Prob: 0.29922837018966675\n",
      "Word: what \t Prob: 0.008585299365222454\n",
      "Word: and \t Prob: 0.008881714195013046\n",
      "Word: , \t Prob: 0.78018718957901\n",
      "Word: sentences \t Prob: 0.0035804409999400377\n",
      "Word: construct \t Prob: 5.39941611350514e-05\n",
      "Word: to \t Prob: 0.9706997871398926\n",
      "Word: used \t Prob: 0.7221975922584534\n",
      "Word: elements \t Prob: 8.632599201519042e-05\n",
      "Word: the \t Prob: 0.5417339205741882\n",
      "Word: explore \t Prob: 0.0008845478878356516\n",
      "Word: will \t Prob: 0.06851402670145035\n",
      "Word: we \t Prob: 0.01786622405052185\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -4.241458488771548\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -4.568852825067902\n",
      "\n",
      "Processing sentence: ['[CLS]', 'wikipedia', 'is', 'a', 'multi', '##ling', '##ual', 'online', 'encyclopedia', 'created', 'and', 'maintained', 'as', 'an', 'open', 'collaboration', 'project', 'by', 'a', 'community', 'of', 'volunteer', 'editors', '.', '[SEP]']\n",
      "Word: wikipedia \t Prob: 2.4891001885407604e-05\n",
      "Word: is \t Prob: 0.00014022781397216022\n",
      "Word: a \t Prob: 0.01839929260313511\n",
      "Word: multi \t Prob: 0.0018113007536157966\n",
      "Word: ##ling \t Prob: 0.00010994893818860874\n",
      "Word: ##ual \t Prob: 0.9995064735412598\n",
      "Word: online \t Prob: 0.004548950586467981\n",
      "Word: encyclopedia \t Prob: 0.31564435362815857\n",
      "Word: created \t Prob: 0.0002835589984897524\n",
      "Word: and \t Prob: 0.014770678244531155\n",
      "Word: maintained \t Prob: 0.019900022074580193\n",
      "Word: as \t Prob: 0.0014062287518754601\n",
      "Word: an \t Prob: 0.005623962730169296\n",
      "Word: open \t Prob: 0.25152459740638733\n",
      "Word: collaboration \t Prob: 5.353112101147417e-06\n",
      "Word: project \t Prob: 0.0010910829296335578\n",
      "Word: by \t Prob: 0.5551554560661316\n",
      "Word: a \t Prob: 0.0042177168652415276\n",
      "Word: community \t Prob: 0.005989608354866505\n",
      "Word: of \t Prob: 0.9838712215423584\n",
      "Word: volunteer \t Prob: 0.042091891169548035\n",
      "Word: editors \t Prob: 0.7438857555389404\n",
      "Word: . \t Prob: 0.9994000196456909\n",
      "\n",
      "Normalized forward sentence prob: log(P(sentence)) / sent_length: -4.33944572806824\n",
      "\n",
      "Processing sentence: ['[CLS]', 'wikipedia', 'is', 'a', 'multi', '##ling', '##ual', 'online', 'encyclopedia', 'created', 'and', 'maintained', 'as', 'an', 'open', 'collaboration', 'project', 'by', 'a', 'community', 'of', 'volunteer', 'editors', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.7018031477928162\n",
      "Word: editors \t Prob: 2.0948000383214094e-05\n",
      "Word: volunteer \t Prob: 7.905096572358161e-05\n",
      "Word: of \t Prob: 0.014275266788899899\n",
      "Word: community \t Prob: 0.0655047670006752\n",
      "Word: a \t Prob: 0.6050601005554199\n",
      "Word: by \t Prob: 0.016397399827837944\n",
      "Word: project \t Prob: 1.046458328346489e-05\n",
      "Word: collaboration \t Prob: 0.003476595738902688\n",
      "Word: open \t Prob: 0.00010294946696376428\n",
      "Word: an \t Prob: 0.9430293440818787\n",
      "Word: as \t Prob: 0.0015125788049772382\n",
      "Word: maintained \t Prob: 0.0007075816974975169\n",
      "Word: and \t Prob: 0.0005246482905931771\n",
      "Word: created \t Prob: 0.13486841320991516\n",
      "Word: encyclopedia \t Prob: 7.978633931315926e-08\n",
      "Word: online \t Prob: 0.5335986018180847\n",
      "Word: ##ual \t Prob: 4.4531649479040425e-08\n",
      "Word: ##ling \t Prob: 0.0009888175409287214\n",
      "Word: multi \t Prob: 0.9434198141098022\n",
      "Word: a \t Prob: 0.6362264156341553\n",
      "Word: is \t Prob: 0.983816385269165\n",
      "Word: wikipedia \t Prob: 0.26914334297180176\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -4.979650003910065\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -4.659547865989152\n",
      "\n",
      "Processing sentence: ['[CLS]', 'once', 'she', 'gave', 'her', 'a', 'little', 'cap', 'of', 'red', 'velvet', ',', 'which', 'suited', 'her', 'so', 'well', 'that', 'she', 'would', 'never', 'wear', 'anything', 'else', '.', '[SEP]']\n",
      "Word: once \t Prob: 1.7992379071074538e-05\n",
      "Word: she \t Prob: 0.009854196570813656\n",
      "Word: gave \t Prob: 0.0009010668145492673\n",
      "Word: her \t Prob: 0.07317624986171722\n",
      "Word: a \t Prob: 0.007067261263728142\n",
      "Word: little \t Prob: 0.02135993354022503\n",
      "Word: cap \t Prob: 1.70629245985765e-05\n",
      "Word: of \t Prob: 0.03889670968055725\n",
      "Word: red \t Prob: 0.04231778904795647\n",
      "Word: velvet \t Prob: 0.03853045776486397\n",
      "Word: , \t Prob: 0.33217841386795044\n",
      "Word: which \t Prob: 0.11341851204633713\n",
      "Word: suited \t Prob: 5.303218131302856e-06\n",
      "Word: her \t Prob: 0.5320029258728027\n",
      "Word: so \t Prob: 0.0020743473432958126\n",
      "Word: well \t Prob: 0.14377108216285706\n",
      "Word: that \t Prob: 0.6603685617446899\n",
      "Word: she \t Prob: 0.6794349551200867\n",
      "Word: would \t Prob: 0.09173430502414703\n",
      "Word: never \t Prob: 0.5110812783241272\n",
      "Word: wear \t Prob: 0.12809838354587555\n",
      "Word: anything \t Prob: 0.006769491825252771\n",
      "Word: else \t Prob: 0.7910427451133728\n",
      "Word: . \t Prob: 0.9912789463996887\n",
      "\n",
      "Normalized forward sentence prob: log(P(sentence)) / sent_length: -3.459413131269125\n",
      "\n",
      "Processing sentence: ['[CLS]', 'once', 'she', 'gave', 'her', 'a', 'little', 'cap', 'of', 'red', 'velvet', ',', 'which', 'suited', 'her', 'so', 'well', 'that', 'she', 'would', 'never', 'wear', 'anything', 'else', '.', '[SEP]']\n",
      "Word: . \t Prob: 0.6952449679374695\n",
      "Word: else \t Prob: 2.3227063138619997e-05\n",
      "Word: anything \t Prob: 0.07401714473962784\n",
      "Word: wear \t Prob: 2.900141453210381e-06\n",
      "Word: never \t Prob: 0.06443699449300766\n",
      "Word: would \t Prob: 0.016262738034129143\n",
      "Word: she \t Prob: 0.05965884402394295\n",
      "Word: that \t Prob: 0.007416556589305401\n",
      "Word: well \t Prob: 3.3975436963373795e-05\n",
      "Word: so \t Prob: 0.20700880885124207\n",
      "Word: her \t Prob: 0.019590923562645912\n",
      "Word: suited \t Prob: 0.40232884883880615\n",
      "Word: which \t Prob: 0.008497748523950577\n",
      "Word: , \t Prob: 0.9712464213371277\n",
      "Word: velvet \t Prob: 0.00021432837820611894\n",
      "Word: red \t Prob: 0.21043312549591064\n",
      "Word: of \t Prob: 0.008378743194043636\n",
      "Word: cap \t Prob: 0.00406852550804615\n",
      "Word: little \t Prob: 0.0036949850618839264\n",
      "Word: a \t Prob: 0.7968737483024597\n",
      "Word: her \t Prob: 0.003920089919120073\n",
      "Word: gave \t Prob: 0.09642218053340912\n",
      "Word: she \t Prob: 0.0006021691369824111\n",
      "Word: once \t Prob: 0.003435404971241951\n",
      "\n",
      "Normalized backward sentence prob: log(P(sentence)) / sent_length: -4.214129695095695\n",
      "\n",
      "\n",
      "Average normalized sentence prob: log(P(sentence)) / sent_length: -3.8367714131824098\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_sentence_prob(\"We will explore the elements used to construct sentences, and what parts of speech are used to expand and elaborate on them.\")\n",
    "get_sentence_prob(\"Wikipedia is a multilingual online encyclopedia created and maintained as an open collaboration project by a community of volunteer editors.\")\n",
    "get_sentence_prob(\"Once she gave her a little cap of red velvet, which suited her so well that she would never wear anything else.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model (weights)\n",
    "with torch.no_grad():\n",
    "    model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "    model.eval()\n",
    "    # Load pre-trained model tokenizer (vocabulary)\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_sentence_prob(\"I fed my cat some of it and he damn near passed out\")\n",
    "get_sentence_prob(\"He was born in Berlin.\")\n",
    "get_sentence_prob(\"He was born in Santiago.\")\n",
    "get_sentence_prob(\"He was born in France.\")\n",
    "get_sentence_prob(\"He was born in window.\")\n",
    "get_sentence_prob(\"He was born in was.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentence_prob(\"I fed my cat some of it and he damn near passed out.\")\n",
    "get_sentence_prob(\"I fed my dog some of it and he damn near passed out.\")\n",
    "get_sentence_prob(\"I fed my window some of it and he damn near passed out.\")\n",
    "get_sentence_prob(\"I fed my the some of it and he damn near passed out.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Should have similar/high probs\\n\")\n",
    "get_sentence_prob(\"I forgot to take my medicine.\")\n",
    "get_sentence_prob(\"I forgot to take my medicines.\")\n",
    "get_sentence_prob(\"I forgot to take my medication.\")\n",
    "get_sentence_prob(\"I forgot to take my pills.\")\n",
    "print(\"Should have low probs\\n\")\n",
    "get_sentence_prob(\"I forgot to take my turn.\")\n",
    "get_sentence_prob(\"I forgot to take my medical.\")\n",
    "get_sentence_prob(\"I forgot to take my medically.\")\n",
    "get_sentence_prob(\"I forgot to take my turned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:transformers]",
   "language": "python",
   "name": "conda-env-transformers-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
