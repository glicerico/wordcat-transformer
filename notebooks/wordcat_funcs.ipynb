{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word category formation using BERT predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The idea is to generate word categories as follows:\n",
    "- Get a list of sentences\n",
    "- Mask a word in each sentence (repeat a sentence in the list if you want to mask different positions)\n",
    "- For each sentence, obtain the logit vector for the masked word from BERT's prediction (last hidden layer)\n",
    "- Cluster sentences logit vectors. The clusters should reflect words that fit together both syntactically and semantically.\n",
    "- Build each word category by finding the highest valued words in the vectors belonging to a cluster (perhaps by most common top words, all words above some threshold, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "from sklearn.cluster import KMeans, OPTICS, DBSCAN, cluster_optics_dbscan\n",
    "\n",
    "tokenizer = None\n",
    "model = None\n",
    "MASK = '[MASK]'\n",
    "sentences = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(pretrained='bert-base-uncased'):\n",
    "    global tokenizer, model\n",
    "    with torch.no_grad():\n",
    "        tokenizer = BertTokenizer.from_pretrained(pretrained)\n",
    "        model = BertForMaskedLM.from_pretrained(pretrained)\n",
    "        model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process sentences with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def preproc_sents(text_sentences):\n",
    "    # Place [MASK] tokens\n",
    "    global sentences\n",
    "    sentences = re.sub(r'\\b_+\\b', MASK, text_sentences).split('\\n')\n",
    "    \n",
    "    # tokenize input\n",
    "    input_ids = [tokenizer.encode(s, add_special_tokens=True) for s in sentences]\n",
    "\n",
    "    # Make all sentence arrays equal length by padding\n",
    "    max_len = max(len(i) for i in input_ids)\n",
    "    padded_input = np.array([i + [0]* (max_len - len(i)) for i in input_ids])\n",
    "\n",
    "    return padded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_predictions(probs, top=5, thres=0.02):\n",
    "    \"\"\"\n",
    "    Print and return top-k predictions for a given probs list.\n",
    "    Also return predictions above threshold\n",
    "    \"\"\"\n",
    "    # Get top-k tokens\n",
    "    probs = probs.detach().numpy()\n",
    "    top_indexes = np.argpartition(probs, -top)[-top:]\n",
    "    sorted_indexes = top_indexes[np.argsort(-probs[top_indexes])]\n",
    "    top_tokens = tokenizer.convert_ids_to_tokens(sorted_indexes)\n",
    "    print(f\"Ordered top predicted tokens: {top_tokens}\")\n",
    "    print(f\"Ordered top predicted values: {probs[sorted_indexes]}\\n\")\n",
    "    \n",
    "    # Get all tokens above threshold\n",
    "    high_indexes = np.where(probs > thres)\n",
    "    high_tokens = tokenizer.convert_ids_to_tokens(high_indexes[0])\n",
    "    return top_tokens, high_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_predictions(padded_input, top=5, thres=0.02):\n",
    "    attention_mask = np.where(padded_input != 0, 1, 0)  # Create mask to ignore padding\n",
    "\n",
    "    input = torch.tensor(padded_input)\n",
    "    attention_mask = torch.tensor(attention_mask)\n",
    "    \n",
    "    # Get last hidden layers\n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model(input, attention_mask=attention_mask)\n",
    "        \n",
    "    # Find location of MASKS\n",
    "    id_MASK = tokenizer.convert_tokens_to_ids(MASK)\n",
    "\n",
    "    # Get last hidden state for the masked word of each sentence\n",
    "    mask_positions = [np.where(s == id_MASK)[0][0] for s in padded_input] \n",
    "    embeddings = [lh[m].numpy() for lh, m in zip(last_hidden_states[0], mask_positions)]\n",
    "    \n",
    "    # Convert last hidden state to probs and find tokens\n",
    "    sm = torch.nn.Softmax(dim=0) \n",
    "    #id_large = tokenizer.convert_tokens_to_ids('large')\n",
    "    all_high_tokens = []\n",
    "    i = 0\n",
    "    for lh, m in zip(last_hidden_states[0], mask_positions):\n",
    "        print(\"Sentence:\")\n",
    "        print(sentences[i])\n",
    "        i += 1\n",
    "        probs = sm(lh[m])\n",
    "        #print(f\"Probability of 'large': {probs[id_large]}\")\n",
    "        _, high_tokens = get_top_predictions(probs, top=top, thres=thres)\n",
    "        all_high_tokens.append(high_tokens)\n",
    "    \n",
    "    return embeddings, all_high_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert last layer logit predictions to probabilities\n",
    "We can see what are the highest predictions for the blank in each sentence, and their probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_embeddings(embeddings, k):\n",
    "    # Cluster embeddings with KMeans\n",
    "    estimator = KMeans(init=\"k-means++\", n_clusters=k, n_jobs=4)\n",
    "    estimator.fit(embeddings)\n",
    "    return estimator.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Form word categories\n",
    "Take all words above a threshold from vectors that belong to a cluster to form word categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_categories(labels, all_high_tokens, k):\n",
    "    word_categories = {}\n",
    "    for cl in range(k):\n",
    "        cluster_members = np.where(labels == cl)\n",
    "        word_categories[cl] = sum((all_high_tokens[i] for i in cluster_members[0]), [])\n",
    "        word_categories[cl] = set(word_categories[cl])\n",
    "        print(f\"Category {cl}:\")\n",
    "        print(\", \".join(word_categories[cl]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main entry point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_categories(text_sentences, k):\n",
    "    padded_input = preproc_sents(text_sentences)\n",
    "    embeddings, all_high_tokens = obtain_predictions(padded_input, thres=0.02)\n",
    "    labels = cluster_embeddings(embeddings, k)\n",
    "    form_categories(labels, all_high_tokens, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose some simple sentences with masked adjectives and nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_model(pretrained='bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sentences = \"\"\"The _ cat ate the mouse.\n",
    "She was wearing a lovely _ dress last night.\n",
    "He was receiving quite a _ salary.\n",
    "He also bought a _ sofa for his new apartment.\n",
    "I was born and grew up in _.\n",
    "The _ metropolitan area added more than a million people in the past decade.\n",
    "Bike races are held around the _ and farmlands.\n",
    "My racist _ called me last night.\n",
    "A device is considered to be available if it is not being used by another _.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:\n",
      "The [MASK] cat ate the mouse.\n",
      "Ordered top predicted tokens: ['black', 'cheshire', 'big', 'little', 'fat']\n",
      "Ordered top predicted values: [0.13267049 0.08640933 0.06516975 0.03538685 0.03100599]\n",
      "\n",
      "Sentence:\n",
      "She was wearing a lovely [MASK] dress last night.\n",
      "Ordered top predicted tokens: ['white', 'black', 'red', 'pink', 'blue']\n",
      "Ordered top predicted values: [0.20945124 0.16496556 0.13129269 0.08869011 0.05542691]\n",
      "\n",
      "Sentence:\n",
      "He was receiving quite a [MASK] salary.\n",
      "Ordered top predicted tokens: ['good', 'handsome', 'high', 'generous', 'decent']\n",
      "Ordered top predicted values: [0.18829058 0.09613485 0.09576207 0.0917473  0.0544567 ]\n",
      "\n",
      "Sentence:\n",
      "He also bought a [MASK] sofa for his new apartment.\n",
      "Ordered top predicted tokens: ['new', 'comfortable', 'luxurious', 'large', 'luxury']\n",
      "Ordered top predicted values: [0.6247967  0.05839209 0.02877485 0.0248212  0.01501671]\n",
      "\n",
      "Sentence:\n",
      "I was born and grew up in [MASK].\n",
      "Ordered top predicted tokens: ['chicago', 'california', 'texas', 'london', 'england']\n",
      "Ordered top predicted values: [0.03689728 0.03364525 0.02513845 0.02230389 0.018717  ]\n",
      "\n",
      "Sentence:\n",
      "The [MASK] metropolitan area added more than a million people in the past decade.\n",
      "Ordered top predicted tokens: ['chicago', 'washington', 'seattle', 'atlanta', 'detroit']\n",
      "Ordered top predicted values: [0.22472836 0.05055556 0.03419264 0.03207787 0.02761591]\n",
      "\n",
      "Sentence:\n",
      "Bike races are held around the [MASK] and farmlands.\n",
      "Ordered top predicted tokens: ['village', 'park', 'town', 'city', 'forest']\n",
      "Ordered top predicted values: [0.15070313 0.09536388 0.0665911  0.05703236 0.04966085]\n",
      "\n",
      "Sentence:\n",
      "My racist [MASK] called me last night.\n",
      "Ordered top predicted tokens: ['friend', 'neighbor', 'boyfriend', 'father', 'brother']\n",
      "Ordered top predicted values: [0.24061793 0.0719889  0.06706642 0.06234702 0.05771114]\n",
      "\n",
      "Sentence:\n",
      "A device is considered to be available if it is not being used by another [MASK].\n",
      "Ordered top predicted tokens: ['person', 'user', 'party', 'device', 'entity']\n",
      "Ordered top predicted values: [0.27529848 0.25013295 0.09434847 0.07847174 0.04001943]\n",
      "\n",
      "Category 0:\n",
      "seattle, california, chicago, atlanta, indianapolis, detroit, denver, pittsburgh, houston, washington, london, texas\n",
      "\n",
      "Category 1:\n",
      "high, large, nice, modest, decent, handsome, fine, generous, low, good, respectable\n",
      "\n",
      "Category 2:\n",
      "new, green, red, large, fat, brown, blue, luxurious, dead, yellow, pink, wedding, cheshire, little, big, white, black, comfortable\n",
      "\n",
      "Category 3:\n",
      "device, party, entity, user, person\n",
      "\n",
      "Category 4:\n",
      "father, boss, roommate, neighbors, neighbor, friend, brother, friends, boyfriend, husband\n",
      "\n",
      "Category 5:\n",
      "city, forests, forest, villages, hills, woods, lakes, lake, park, mountains, village, town\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = 6\n",
    "get_word_categories(text_sentences, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:transformers]",
   "language": "python",
   "name": "conda-env-transformers-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
