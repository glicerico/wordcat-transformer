{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAIL... arithmetic average is clearly not the way\n",
    "\n",
    "\n",
    "# Estimate sentence probability with BERT\n",
    "## Calculating probability more properly:\n",
    "P_f, P_b: Probability forward pass, backward pass, respectively\n",
    "P_f = P(w_0) * P(w_1|w_0) * P(w_2|w_0, w_1) * ... * P(w_N)\n",
    "P_b = P(w_N-1|w_N) * P(w_N-2|w_N-1, w_N) * ... * P(w_0|w_1, w_2, ... ,w_N)\n",
    "\n",
    "P_f, P_b become smaller as the sentence length increases, hence, I try normalizing them by sentence length.\n",
    "Here I use an arithmetic mean\n",
    "\n",
    "Finally, the sentence probability P(S) is the geometric mean of forward and backwards probabilities:\n",
    "```\n",
    "P(S) = (mean(P_f(S)) * mean(P_b(S))) ^ (1/2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "\n",
    "BOS_TOKEN = '[CLS]'\n",
    "EOS_TOKEN = '[SEP]'\n",
    "MASK_TOKEN = '[MASK]'\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "with torch.no_grad():\n",
    "    model = BertForMaskedLM.from_pretrained('bert-large-uncased')\n",
    "    model.eval()\n",
    "    # Load pre-trained model tokenizer (vocabulary)\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_predictions(probs, k=5):\n",
    "    probs = probs.detach().numpy()\n",
    "    top_indexes = np.argpartition(probs, -k)[-k:]\n",
    "    sorted_indexes = top_indexes[np.argsort(-probs[top_indexes])]\n",
    "    top_tokens = tokenizer.convert_ids_to_tokens(sorted_indexes)\n",
    "    print(f\"Ordered top predicted tokens: {top_tokens}\")\n",
    "    print(f\"Ordered top predicted values: {probs[sorted_indexes]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_prob(sentence, verbose=False):\n",
    "    # Pre-process sentence, adding special tokens\n",
    "    tokenized_input = tokenizer.tokenize(sentence)\n",
    "    if tokenized_input[0] != BOS_TOKEN:\n",
    "        tokenized_input.insert(0, BOS_TOKEN)\n",
    "    if tokenized_input[-1] != EOS_TOKEN:\n",
    "        tokenized_input.append(EOS_TOKEN)\n",
    "    sent_len = len(tokenized_input)\n",
    "    ids_input = tokenizer.convert_tokens_to_ids(tokenized_input)\n",
    "    print(f\"Processing sentence: {tokenized_input}\\n\")\n",
    "    \n",
    "    sm = torch.nn.Softmax(dim=0) # used to convert last hidden state to probs\n",
    "    \n",
    "    # Trying with arithmetic average\n",
    "    sent_prob_forward = 0\n",
    "    sent_prob_backwards = 0\n",
    "    # Mask non-special tokens in forward direction; calculate their probabilities\n",
    "    for i in range(1, len(tokenized_input) - 1): # Don't loop first and last tokens\n",
    "        probs_forward = get_directional_prob(sm, tokenized_input, i, 'forward', verbose=verbose)\n",
    "        probs_backwards = get_directional_prob(sm, tokenized_input, i, 'backwards', verbose=verbose)\n",
    "        prob_forward = probs_forward[ids_input[i]] # Prediction for masked word \n",
    "        prob_backwards = probs_backwards[ids_input[i]] # Prediction for masked word \n",
    "        sent_prob_forward += prob_forward\n",
    "        sent_prob_backwards += prob_backwards\n",
    "\n",
    "        print(f\"Word: {tokenized_input[i]} \\t Prob_forward: {prob_forward}; Prob_backwards: {prob_backwards}\")\n",
    "\n",
    "    sent_prob_forward = sent_prob_forward.detach().numpy() / sent_len\n",
    "    sent_prob_backwards = sent_prob_backwards.detach().numpy() / sent_len\n",
    "    print(f\"Geometric-mean forward sentence probability: {sent_prob_forward}\")\n",
    "    print(f\"Geometric-mean backward sentence probability: {sent_prob_backwards}\\n\")\n",
    "    \n",
    "    # Obtain geometric average of forward and backward probs\n",
    "    geom_mean_sent_prob = np.sqrt(sent_prob_forward * sent_prob_backwards)\n",
    "    print(f\"Average normalized sentence prob: {geom_mean_sent_prob}\\n\")\n",
    "    return geom_mean_sent_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_directional_prob(sm, tokenized_input, i, direction, verbose=False):\n",
    "    current_tokens = tokenized_input[:]\n",
    "    if direction == 'backwards':\n",
    "        current_tokens[1:i+1] = [MASK_TOKEN for j in range(i)]\n",
    "    elif direction == 'forward':\n",
    "        current_tokens[i:-1] = [MASK_TOKEN for j in range(len(tokenized_input) - 1 - i)]\n",
    "    else:\n",
    "        print(\"Direction can only be 'forward' or 'backwards'\")\n",
    "        exit()\n",
    "    if verbose: \n",
    "        print()\n",
    "        print(current_tokens)\n",
    "        \n",
    "    masked_input = torch.tensor([tokenizer.convert_tokens_to_ids(current_tokens)])\n",
    "    predictions = model(masked_input)\n",
    "    predictions = predictions[0]\n",
    "    probs = sm(predictions[0, i]) # Softmax to get probabilities\n",
    "    if verbose: \n",
    "        print_top_predictions(probs)\n",
    "    \n",
    "    return probs # Model redictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence: ['[CLS]', 'he', 'answered', 'une', '##qui', '##vo', '##cal', '##ly', '.', '[SEP]']\n",
      "\n",
      "Word: he \t Prob_forward: 0.0005044482531957328; Prob_backwards: 0.2814375162124634\n",
      "Word: answered \t Prob_forward: 0.0002913153439294547; Prob_backwards: 0.010978045873343945\n",
      "Word: une \t Prob_forward: 2.243901064957754e-07; Prob_backwards: 0.9987058639526367\n",
      "Word: ##qui \t Prob_forward: 0.0005762826185673475; Prob_backwards: 0.0008089180919341743\n",
      "Word: ##vo \t Prob_forward: 0.05035709589719772; Prob_backwards: 3.2233551792160142e-06\n",
      "Word: ##cal \t Prob_forward: 0.9999289512634277; Prob_backwards: 2.658714583958499e-05\n",
      "Word: ##ly \t Prob_forward: 0.9982821941375732; Prob_backwards: 0.0010952855227515101\n",
      "Word: . \t Prob_forward: 0.9998167157173157; Prob_backwards: 0.7406781911849976\n",
      "Geometric-mean forward sentence probability: 0.30497572422027586\n",
      "Geometric-mean backward sentence probability: 0.20337338447570802\n",
      "\n",
      "Average normalized sentence prob: 0.249046070472127\n",
      "\n",
      "Processing sentence: ['[CLS]', 'he', 'answered', 'quickly', '.', '[SEP]']\n",
      "\n",
      "\n",
      "['[CLS]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[SEP]']\n",
      "Ordered top predicted tokens: ['in', 'and', '\"', '[', '(']\n",
      "Ordered top predicted values: [0.04898074 0.04841739 0.04020055 0.03066272 0.02607192]\n",
      "\n",
      "['[CLS]', '[MASK]', 'answered', 'quickly', '.', '[SEP]']\n",
      "Ordered top predicted tokens: ['i', 'she', 'he', 'jack', 'nick']\n",
      "Ordered top predicted values: [0.2943303  0.2310972  0.21517508 0.00285249 0.00283264]\n",
      "Word: he \t Prob_forward: 0.0012037473497912288; Prob_backwards: 0.2151750773191452\n",
      "\n",
      "['[CLS]', 'he', '[MASK]', '[MASK]', '[MASK]', '[SEP]']\n",
      "Ordered top predicted tokens: ['was', 'looked', 'asked', 'said', 'is']\n",
      "Ordered top predicted values: [0.4028537  0.05901183 0.05432703 0.04291577 0.03971536]\n",
      "\n",
      "['[CLS]', '[MASK]', '[MASK]', 'quickly', '.', '[SEP]']\n",
      "Ordered top predicted tokens: ['asked', 'said', 'thought', 'nodded', 'blinked']\n",
      "Ordered top predicted values: [0.2587772  0.1465675  0.12193974 0.08968459 0.04111334]\n",
      "Word: answered \t Prob_forward: 0.003327467478811741; Prob_backwards: 0.016331685706973076\n",
      "\n",
      "['[CLS]', 'he', 'answered', '[MASK]', '[MASK]', '[SEP]']\n",
      "Ordered top predicted tokens: ['it', 'immediately', 'quickly', 'her', 'quietly']\n",
      "Ordered top predicted values: [0.3002007  0.1476826  0.06010275 0.03919926 0.03147311]\n",
      "\n",
      "['[CLS]', '[MASK]', '[MASK]', '[MASK]', '.', '[SEP]']\n",
      "Ordered top predicted tokens: ['vol', 'press', 'p', 'j', 'ii']\n",
      "Ordered top predicted values: [0.06490542 0.05437048 0.03844456 0.0262519  0.01432491]\n",
      "Word: quickly \t Prob_forward: 0.06010275334119797; Prob_backwards: 1.494371304033848e-06\n",
      "\n",
      "['[CLS]', 'he', 'answered', 'quickly', '[MASK]', '[SEP]']\n",
      "Ordered top predicted tokens: ['.', ';', '!', '?', '...']\n",
      "Ordered top predicted values: [9.9814069e-01 1.8559413e-03 2.1156122e-06 1.1307502e-06 6.6726315e-08]\n",
      "\n",
      "['[CLS]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[SEP]']\n",
      "Ordered top predicted tokens: ['.', ';', '|', '?', '!']\n",
      "Ordered top predicted values: [9.5748538e-01 4.0964618e-02 1.0687120e-03 2.2205077e-04 2.2124879e-04]\n",
      "Word: . \t Prob_forward: 0.9981406927108765; Prob_backwards: 0.9574853777885437\n",
      "Geometric-mean forward sentence probability: 0.17712910970052084\n",
      "Geometric-mean backward sentence probability: 0.19816561539967856\n",
      "\n",
      "Average normalized sentence prob: 0.18735233926749056\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.18735233926749056"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentence_prob(\"He answered unequivocally.\")\n",
    "get_sentence_prob(\"He answered quickly.\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence: ['[CLS]', 'the', 'guy', 'with', 'small', 'hands', 'demanded', 'a', 'qui', '##d', 'pro', 'quo', '.', '[SEP]']\n",
      "\n",
      "Word: the \t Prob_forward: 0.020117253065109253; Prob_backwards: 0.6742717027664185\n",
      "Word: guy \t Prob_forward: 4.888691910309717e-05; Prob_backwards: 0.0006307517760433257\n",
      "Word: with \t Prob_forward: 0.0006999199977144599; Prob_backwards: 0.06413324922323227\n",
      "Word: small \t Prob_forward: 4.887327304459177e-05; Prob_backwards: 0.008030521683394909\n",
      "Word: hands \t Prob_forward: 0.0014287744415923953; Prob_backwards: 7.560867379652336e-05\n",
      "Word: demanded \t Prob_forward: 2.932926236098865e-06; Prob_backwards: 1.76298769360983e-07\n",
      "Word: a \t Prob_forward: 0.000463048490928486; Prob_backwards: 0.06345833837985992\n",
      "Word: qui \t Prob_forward: 3.862149696942652e-06; Prob_backwards: 0.5241817235946655\n",
      "Word: ##d \t Prob_forward: 0.23301775753498077; Prob_backwards: 7.432691973008332e-07\n",
      "Word: pro \t Prob_forward: 3.778058089665137e-05; Prob_backwards: 0.004886653274297714\n",
      "Word: quo \t Prob_forward: 0.9989466071128845; Prob_backwards: 6.576073587893916e-07\n",
      "Word: . \t Prob_forward: 0.9850805401802063; Prob_backwards: 0.8537910580635071\n",
      "Geometric-mean forward sentence probability: 0.1599925926753453\n",
      "Geometric-mean backward sentence probability: 0.15667579855237687\n",
      "\n",
      "Average normalized sentence prob: 0.15832551032564174\n",
      "\n",
      "Processing sentence: ['[CLS]', 'the', 'guy', 'with', 'small', 'hands', 'demanded', 'an', 'exchange', '.', '[SEP]']\n",
      "\n",
      "Word: the \t Prob_forward: 0.00395584711804986; Prob_backwards: 0.6960532069206238\n",
      "Word: guy \t Prob_forward: 0.00023759041505400091; Prob_backwards: 0.0005619829171337187\n",
      "Word: with \t Prob_forward: 0.00551602290943265; Prob_backwards: 0.13349278271198273\n",
      "Word: small \t Prob_forward: 2.2452195480582304e-06; Prob_backwards: 0.007092668209224939\n",
      "Word: hands \t Prob_forward: 0.12713825702667236; Prob_backwards: 6.0928286984562874e-05\n",
      "Word: demanded \t Prob_forward: 0.0003027346101589501; Prob_backwards: 0.00019403055193834007\n",
      "Word: an \t Prob_forward: 0.0007860533078201115; Prob_backwards: 0.004323412664234638\n",
      "Word: exchange \t Prob_forward: 0.003408455988392234; Prob_backwards: 2.3502572730649263e-05\n",
      "Word: . \t Prob_forward: 0.9960935711860657; Prob_backwards: 0.7714381814002991\n",
      "Geometric-mean forward sentence probability: 0.10340370915152809\n",
      "Geometric-mean backward sentence probability: 0.14665824716741388\n",
      "\n",
      "Average normalized sentence prob: 0.12314628185524801\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12314628185524801"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentence_prob(\"The guy with small hands demanded a quid pro quo.\")\n",
    "get_sentence_prob(\"The guy with small hands demanded an exchange.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence: ['[CLS]', 'this', 'is', 'a', 'sentence', '.', '[SEP]']\n",
      "\n",
      "Word: this \t Prob_forward: 0.00012813373177777976; Prob_backwards: 0.060409143567085266\n",
      "Word: is \t Prob_forward: 0.3984246850013733; Prob_backwards: 0.06603307276964188\n",
      "Word: a \t Prob_forward: 0.06797751039266586; Prob_backwards: 0.23075106739997864\n",
      "Word: sentence \t Prob_forward: 0.00013198245142120868; Prob_backwards: 9.854356903815642e-07\n",
      "Word: . \t Prob_forward: 0.966092050075531; Prob_backwards: 0.8030216097831726\n",
      "Geometric-mean forward sentence probability: 0.20467919962746756\n",
      "Geometric-mean backward sentence probability: 0.16574512209211076\n",
      "\n",
      "Average normalized sentence prob: 0.1841862615179811\n",
      "\n",
      "Processing sentence: ['[CLS]', 'this', 'is', 'a', 'mac', '##ram', '##e', '.', '[SEP]']\n",
      "\n",
      "Word: this \t Prob_forward: 0.00017661201127339154; Prob_backwards: 0.055456843227148056\n",
      "Word: is \t Prob_forward: 0.13002026081085205; Prob_backwards: 0.1228228434920311\n",
      "Word: a \t Prob_forward: 0.7468298077583313; Prob_backwards: 0.03886374458670616\n",
      "Word: mac \t Prob_forward: 3.489916707621887e-05; Prob_backwards: 0.031789381057024\n",
      "Word: ##ram \t Prob_forward: 3.345703225932084e-05; Prob_backwards: 0.00035895415931008756\n",
      "Word: ##e \t Prob_forward: 0.9994305968284607; Prob_backwards: 0.0015561149921268225\n",
      "Word: . \t Prob_forward: 0.9644730091094971; Prob_backwards: 0.6934828162193298\n",
      "Geometric-mean forward sentence probability: 0.31566651662190753\n",
      "Geometric-mean backward sentence probability: 0.10492563247680664\n",
      "\n",
      "Average normalized sentence prob: 0.1819931562128204\n",
      "\n",
      "Processing sentence: ['[CLS]', 'this', 'is', 'a', 'joke', '.', '[SEP]']\n",
      "\n",
      "Word: this \t Prob_forward: 0.00012813373177777976; Prob_backwards: 0.9431005716323853\n",
      "Word: is \t Prob_forward: 0.3984246850013733; Prob_backwards: 0.013980957679450512\n",
      "Word: a \t Prob_forward: 0.06797751039266586; Prob_backwards: 0.8843458294868469\n",
      "Word: joke \t Prob_forward: 0.024301037192344666; Prob_backwards: 1.940953552548308e-06\n",
      "Word: . \t Prob_forward: 0.9846997857093811; Prob_backwards: 0.8030216097831726\n",
      "Geometric-mean forward sentence probability: 0.21079015731811523\n",
      "Geometric-mean backward sentence probability: 0.3777787004198347\n",
      "\n",
      "Average normalized sentence prob: 0.2821914805463306\n",
      "\n",
      "Processing sentence: ['[CLS]', 'are', 'you', 'kidding', 'me', '?', '[SEP]']\n",
      "\n",
      "Word: are \t Prob_forward: 1.7308737369603477e-05; Prob_backwards: 0.9999496936798096\n",
      "Word: you \t Prob_forward: 0.20984314382076263; Prob_backwards: 0.7853965759277344\n",
      "Word: kidding \t Prob_forward: 0.017895009368658066; Prob_backwards: 0.002946171211078763\n",
      "Word: me \t Prob_forward: 0.9998680353164673; Prob_backwards: 0.0023696625139564276\n",
      "Word: ? \t Prob_forward: 0.9999755620956421; Prob_backwards: 0.003331726649776101\n",
      "Geometric-mean forward sentence probability: 0.3182284491402762\n",
      "Geometric-mean backward sentence probability: 0.25628483295440674\n",
      "\n",
      "Average normalized sentence prob: 0.285582080896641\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.285582080896641"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentence_prob(\"This is a sentence.\")\n",
    "get_sentence_prob(\"This is a macrame.\", verbose=False)\n",
    "get_sentence_prob(\"This is a joke.\", verbose=False)\n",
    "get_sentence_prob(\"Are you kidding me?\", verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence: ['[CLS]', 'rachel', 'was', 'wearing', 'a', 'lovely', 'satin', 'dress', 'last', 'night', '.', '[SEP]']\n",
      "\n",
      "Word: rachel \t Prob_forward: 1.345694727206137e-05; Prob_backwards: 0.0008810244617052376\n",
      "Word: was \t Prob_forward: 0.2645097076892853; Prob_backwards: 0.9986034035682678\n",
      "Word: wearing \t Prob_forward: 3.774421929847449e-05; Prob_backwards: 0.1172424703836441\n",
      "Word: a \t Prob_forward: 0.9133190512657166; Prob_backwards: 0.8966140151023865\n",
      "Word: lovely \t Prob_forward: 0.0004488571430556476; Prob_backwards: 8.846891432767734e-05\n",
      "Word: satin \t Prob_forward: 0.0010469065746292472; Prob_backwards: 1.9559594875317998e-05\n",
      "Word: dress \t Prob_forward: 0.02077450044453144; Prob_backwards: 2.075352995234425e-06\n",
      "Word: last \t Prob_forward: 0.003023444674909115; Prob_backwards: 0.05977332592010498\n",
      "Word: night \t Prob_forward: 0.9490013122558594; Prob_backwards: 0.0001843223290052265\n",
      "Word: . \t Prob_forward: 0.9899153709411621; Prob_backwards: 0.8182555437088013\n",
      "Geometric-mean forward sentence probability: 0.26184086004892987\n",
      "Geometric-mean backward sentence probability: 0.24097204208374023\n",
      "\n",
      "Average normalized sentence prob: 0.2511898221404551\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2511898221404551"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentence_prob(\"Rachel was wearing a lovely satin dress last night.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence: ['[CLS]', 'rachel', 'was', 'wearing', 'a', 'lovely', 'satin', 'dress', 'last', 'night', '.', '[SEP]']\n",
      "\n",
      "Word: rachel \t Prob_forward: 1.345694727206137e-05; Prob_backwards: 0.0008810244617052376\n",
      "Word: was \t Prob_forward: 0.2645097076892853; Prob_backwards: 0.9986034035682678\n",
      "Word: wearing \t Prob_forward: 3.774421929847449e-05; Prob_backwards: 0.1172424703836441\n",
      "Word: a \t Prob_forward: 0.9133190512657166; Prob_backwards: 0.8966140151023865\n",
      "Word: lovely \t Prob_forward: 0.0004488571430556476; Prob_backwards: 8.846891432767734e-05\n",
      "Word: satin \t Prob_forward: 0.0010469065746292472; Prob_backwards: 1.9559594875317998e-05\n",
      "Word: dress \t Prob_forward: 0.02077450044453144; Prob_backwards: 2.075352995234425e-06\n",
      "Word: last \t Prob_forward: 0.003023444674909115; Prob_backwards: 0.05977332592010498\n",
      "Word: night \t Prob_forward: 0.9490013122558594; Prob_backwards: 0.0001843223290052265\n",
      "Word: . \t Prob_forward: 0.9899153709411621; Prob_backwards: 0.8182555437088013\n",
      "Geometric-mean forward sentence probability: 0.26184086004892987\n",
      "Geometric-mean backward sentence probability: 0.24097204208374023\n",
      "\n",
      "Average normalized sentence prob: 0.2511898221404551\n",
      "\n",
      "Processing sentence: ['[CLS]', 'grandma', 'was', 'wearing', 'a', 'lovely', 'satin', 'dress', 'last', 'night', '.', '[SEP]']\n",
      "\n",
      "Word: grandma \t Prob_forward: 3.624638566179783e-06; Prob_backwards: 0.00012786401202902198\n",
      "Word: was \t Prob_forward: 0.002532388549298048; Prob_backwards: 0.9986034035682678\n",
      "Word: wearing \t Prob_forward: 0.0006332382909022272; Prob_backwards: 0.1172424703836441\n",
      "Word: a \t Prob_forward: 0.898884654045105; Prob_backwards: 0.8966140151023865\n",
      "Word: lovely \t Prob_forward: 0.001705632428638637; Prob_backwards: 8.846891432767734e-05\n",
      "Word: satin \t Prob_forward: 0.0009882483864203095; Prob_backwards: 1.9559594875317998e-05\n",
      "Word: dress \t Prob_forward: 0.01763792522251606; Prob_backwards: 2.075352995234425e-06\n",
      "Word: last \t Prob_forward: 0.0032694607507437468; Prob_backwards: 0.05977332592010498\n",
      "Word: night \t Prob_forward: 0.9110978245735168; Prob_backwards: 0.0001843223290052265\n",
      "Word: . \t Prob_forward: 0.9937726855278015; Prob_backwards: 0.8182555437088013\n",
      "Geometric-mean forward sentence probability: 0.23587713638941446\n",
      "Geometric-mean backward sentence probability: 0.2409092585245768\n",
      "\n",
      "Average normalized sentence prob: 0.23837991952023624\n",
      "\n",
      "Processing sentence: ['[CLS]', 'mother', 'was', 'wearing', 'a', 'lovely', 'satin', 'dress', 'last', 'night', '.', '[SEP]']\n",
      "\n",
      "Word: mother \t Prob_forward: 4.2665709770517424e-05; Prob_backwards: 0.0005006226128898561\n",
      "Word: was \t Prob_forward: 0.007873929105699062; Prob_backwards: 0.9986034035682678\n",
      "Word: wearing \t Prob_forward: 7.239717524498701e-05; Prob_backwards: 0.1172424703836441\n",
      "Word: a \t Prob_forward: 0.8792627453804016; Prob_backwards: 0.8966140151023865\n",
      "Word: lovely \t Prob_forward: 0.000798792636487633; Prob_backwards: 8.846891432767734e-05\n",
      "Word: satin \t Prob_forward: 0.0017313766293227673; Prob_backwards: 1.9559594875317998e-05\n",
      "Word: dress \t Prob_forward: 0.019959256052970886; Prob_backwards: 2.075352995234425e-06\n",
      "Word: last \t Prob_forward: 0.0012650423450395465; Prob_backwards: 0.05977332592010498\n",
      "Word: night \t Prob_forward: 0.9516106843948364; Prob_backwards: 0.0001843223290052265\n",
      "Word: . \t Prob_forward: 0.9858760237693787; Prob_backwards: 0.8182555437088013\n",
      "Geometric-mean forward sentence probability: 0.2373744249343872\n",
      "Geometric-mean backward sentence probability: 0.24094033241271973\n",
      "\n",
      "Average normalized sentence prob: 0.23915073248888333\n",
      "\n",
      "Processing sentence: ['[CLS]', 'she', 'was', 'wearing', 'a', 'lovely', 'satin', 'dress', 'last', 'night', '.', '[SEP]']\n",
      "\n",
      "Word: she \t Prob_forward: 0.0002144854370271787; Prob_backwards: 0.6096646189689636\n",
      "Word: was \t Prob_forward: 0.9033569693565369; Prob_backwards: 0.9986034035682678\n",
      "Word: wearing \t Prob_forward: 0.00018437218386679888; Prob_backwards: 0.1172424703836441\n",
      "Word: a \t Prob_forward: 0.9347352981567383; Prob_backwards: 0.8966140151023865\n",
      "Word: lovely \t Prob_forward: 0.0006815208471380174; Prob_backwards: 8.846891432767734e-05\n",
      "Word: satin \t Prob_forward: 0.0013114860048517585; Prob_backwards: 1.9559594875317998e-05\n",
      "Word: dress \t Prob_forward: 0.024374864995479584; Prob_backwards: 2.075352995234425e-06\n",
      "Word: last \t Prob_forward: 0.00163528963457793; Prob_backwards: 0.05977332592010498\n",
      "Word: night \t Prob_forward: 0.9620522856712341; Prob_backwards: 0.0001843223290052265\n",
      "Word: . \t Prob_forward: 0.9905979037284851; Prob_backwards: 0.8182555437088013\n",
      "Geometric-mean forward sentence probability: 0.3182620406150818\n",
      "Geometric-mean backward sentence probability: 0.2917039791742961\n",
      "\n",
      "Average normalized sentence prob: 0.3046937867229176\n",
      "\n",
      "Processing sentence: ['[CLS]', 'he', 'was', 'wearing', 'a', 'lovely', 'satin', 'dress', 'last', 'night', '.', '[SEP]']\n",
      "\n",
      "Word: he \t Prob_forward: 0.0003202789230272174; Prob_backwards: 0.0063450220040977\n",
      "Word: was \t Prob_forward: 0.6659026145935059; Prob_backwards: 0.9986034035682678\n",
      "Word: wearing \t Prob_forward: 0.00015709105355199426; Prob_backwards: 0.1172424703836441\n",
      "Word: a \t Prob_forward: 0.9291734099388123; Prob_backwards: 0.8966140151023865\n",
      "Word: lovely \t Prob_forward: 0.00010252989159198478; Prob_backwards: 8.846891432767734e-05\n",
      "Word: satin \t Prob_forward: 0.0006155010196380317; Prob_backwards: 1.9559594875317998e-05\n",
      "Word: dress \t Prob_forward: 0.014229005202651024; Prob_backwards: 2.075352995234425e-06\n",
      "Word: last \t Prob_forward: 0.0015683234669268131; Prob_backwards: 0.05977332592010498\n",
      "Word: night \t Prob_forward: 0.9635945558547974; Prob_backwards: 0.0001843223290052265\n",
      "Word: . \t Prob_forward: 0.984560489654541; Prob_backwards: 0.8182555437088013\n",
      "Geometric-mean forward sentence probability: 0.2966853181521098\n",
      "Geometric-mean backward sentence probability: 0.2414273420969645\n",
      "\n",
      "Average normalized sentence prob: 0.2676339810275522\n",
      "\n",
      "Processing sentence: ['[CLS]', 'i', 'was', 'wearing', 'a', 'lovely', 'satin', 'dress', 'last', 'night', '.', '[SEP]']\n",
      "\n",
      "Word: i \t Prob_forward: 0.000585844274610281; Prob_backwards: 0.2957271933555603\n",
      "Word: was \t Prob_forward: 0.5617194771766663; Prob_backwards: 0.9986034035682678\n",
      "Word: wearing \t Prob_forward: 4.494710447033867e-05; Prob_backwards: 0.1172424703836441\n",
      "Word: a \t Prob_forward: 0.8895069360733032; Prob_backwards: 0.8966140151023865\n",
      "Word: lovely \t Prob_forward: 0.0006695505580864847; Prob_backwards: 8.846891432767734e-05\n",
      "Word: satin \t Prob_forward: 0.0009180004708468914; Prob_backwards: 1.9559594875317998e-05\n",
      "Word: dress \t Prob_forward: 0.02124287374317646; Prob_backwards: 2.075352995234425e-06\n",
      "Word: last \t Prob_forward: 0.006269972771406174; Prob_backwards: 0.05977332592010498\n",
      "Word: night \t Prob_forward: 0.9602768421173096; Prob_backwards: 0.0001843223290052265\n",
      "Word: . \t Prob_forward: 0.9892110824584961; Prob_backwards: 0.8182555437088013\n",
      "Geometric-mean forward sentence probability: 0.2858704725901286\n",
      "Geometric-mean backward sentence probability: 0.26554254690806073\n",
      "\n",
      "Average normalized sentence prob: 0.2755190980266045\n",
      "\n",
      "Processing sentence: ['[CLS]', 'angela', 'was', 'wearing', 'a', 'lovely', 'satin', 'dress', 'last', 'night', '.', '[SEP]']\n",
      "\n",
      "Word: angela \t Prob_forward: 8.668032023706473e-06; Prob_backwards: 2.9840008210157976e-05\n",
      "Word: was \t Prob_forward: 0.0008761899080127478; Prob_backwards: 0.9986034035682678\n",
      "Word: wearing \t Prob_forward: 6.847303302492946e-05; Prob_backwards: 0.1172424703836441\n",
      "Word: a \t Prob_forward: 0.9196966290473938; Prob_backwards: 0.8966140151023865\n",
      "Word: lovely \t Prob_forward: 0.00040084568900056183; Prob_backwards: 8.846891432767734e-05\n",
      "Word: satin \t Prob_forward: 0.001516903517767787; Prob_backwards: 1.9559594875317998e-05\n",
      "Word: dress \t Prob_forward: 0.015366233885288239; Prob_backwards: 2.075352995234425e-06\n",
      "Word: last \t Prob_forward: 0.0025214876513928175; Prob_backwards: 0.05977332592010498\n",
      "Word: night \t Prob_forward: 0.9481052756309509; Prob_backwards: 0.0001843223290052265\n",
      "Word: . \t Prob_forward: 0.9826761484146118; Prob_backwards: 0.8182555437088013\n",
      "Geometric-mean forward sentence probability: 0.23926973342895508\n",
      "Geometric-mean backward sentence probability: 0.24090111255645752\n",
      "\n",
      "Average normalized sentence prob: 0.24008403733718386\n",
      "\n",
      "Processing sentence: ['[CLS]', 'roberta', 'was', 'wearing', 'a', 'lovely', 'satin', 'dress', 'last', 'night', '.', '[SEP]']\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: roberta \t Prob_forward: 3.867816758429399e-06; Prob_backwards: 1.2631488971237559e-05\n",
      "Word: was \t Prob_forward: 0.0005287343519739807; Prob_backwards: 0.9986034035682678\n",
      "Word: wearing \t Prob_forward: 0.0002253064449178055; Prob_backwards: 0.1172424703836441\n",
      "Word: a \t Prob_forward: 0.8714913725852966; Prob_backwards: 0.8966140151023865\n",
      "Word: lovely \t Prob_forward: 0.0008630887023173273; Prob_backwards: 8.846891432767734e-05\n",
      "Word: satin \t Prob_forward: 0.0011990604689344764; Prob_backwards: 1.9559594875317998e-05\n",
      "Word: dress \t Prob_forward: 0.018998507410287857; Prob_backwards: 2.075352995234425e-06\n",
      "Word: last \t Prob_forward: 0.0027865259908139706; Prob_backwards: 0.05977332592010498\n",
      "Word: night \t Prob_forward: 0.9439453482627869; Prob_backwards: 0.0001843223290052265\n",
      "Word: . \t Prob_forward: 0.9862309098243713; Prob_backwards: 0.8182555437088013\n",
      "Geometric-mean forward sentence probability: 0.23552272717158\n",
      "Geometric-mean backward sentence probability: 0.2408996820449829\n",
      "\n",
      "Average normalized sentence prob: 0.23819603290147565\n",
      "\n",
      "Processing sentence: ['[CLS]', 'running', 'was', 'wearing', 'a', 'lovely', 'satin', 'dress', 'last', 'night', '.', '[SEP]']\n",
      "\n",
      "Word: running \t Prob_forward: 7.049769010336604e-06; Prob_backwards: 5.459548333419662e-07\n",
      "Word: was \t Prob_forward: 0.0003424289752729237; Prob_backwards: 0.9986034035682678\n",
      "Word: wearing \t Prob_forward: 8.576368600188289e-06; Prob_backwards: 0.1172424703836441\n",
      "Word: a \t Prob_forward: 0.7057843208312988; Prob_backwards: 0.8966140151023865\n",
      "Word: lovely \t Prob_forward: 0.00019137808703817427; Prob_backwards: 8.846891432767734e-05\n",
      "Word: satin \t Prob_forward: 0.0008118441910482943; Prob_backwards: 1.9559594875317998e-05\n",
      "Word: dress \t Prob_forward: 0.016466159373521805; Prob_backwards: 2.075352995234425e-06\n",
      "Word: last \t Prob_forward: 0.0014500269899144769; Prob_backwards: 0.05977332592010498\n",
      "Word: night \t Prob_forward: 0.9557685852050781; Prob_backwards: 0.0001843223290052265\n",
      "Word: . \t Prob_forward: 0.9879379868507385; Prob_backwards: 0.8182555437088013\n",
      "Geometric-mean forward sentence probability: 0.22239734729131064\n",
      "Geometric-mean backward sentence probability: 0.2408986488978068\n",
      "\n",
      "Average normalized sentence prob: 0.23146321625894048\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.23146321625894048"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentence_prob(\"Rachel was wearing a lovely satin dress last night.\")\n",
    "get_sentence_prob(\"Grandma was wearing a lovely satin dress last night.\")\n",
    "get_sentence_prob(\"Mother was wearing a lovely satin dress last night.\")\n",
    "get_sentence_prob(\"She was wearing a lovely satin dress last night.\")\n",
    "get_sentence_prob(\"He was wearing a lovely satin dress last night.\")\n",
    "get_sentence_prob(\"I was wearing a lovely satin dress last night.\")\n",
    "get_sentence_prob(\"Angela was wearing a lovely satin dress last night.\")\n",
    "get_sentence_prob(\"Roberta was wearing a lovely satin dress last night.\")\n",
    "get_sentence_prob(\"Running was wearing a lovely satin dress last night.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence: ['[CLS]', 'the', 'man', 'ate', 'the', 'steak', '.', '[SEP]']\n",
      "\n",
      "Word: the \t Prob_forward: 0.006482909899204969; Prob_backwards: 0.9430958032608032\n",
      "Word: man \t Prob_forward: 0.0008543190779164433; Prob_backwards: 4.835774234379642e-05\n",
      "Word: ate \t Prob_forward: 0.00030972290551289916; Prob_backwards: 0.014627532102167606\n",
      "Word: the \t Prob_forward: 0.16035766899585724; Prob_backwards: 0.024790508672595024\n",
      "Word: steak \t Prob_forward: 0.004650171846151352; Prob_backwards: 8.405078006035183e-06\n",
      "Word: . \t Prob_forward: 0.9944341778755188; Prob_backwards: 0.7197229266166687\n",
      "Geometric-mean forward sentence probability: 0.1458861231803894\n",
      "Geometric-mean backward sentence probability: 0.2127866894006729\n",
      "\n",
      "Average normalized sentence prob: 0.17618917441504126\n",
      "\n",
      "Processing sentence: ['[CLS]', 'the', 'man', 'who', 'arrived', 'late', 'ate', 'the', 'steak', 'with', 'a', 'glass', 'of', 'wine', '.', '[SEP]']\n",
      "\n",
      "Word: the \t Prob_forward: 0.08750123530626297; Prob_backwards: 0.9333303570747375\n",
      "Word: man \t Prob_forward: 0.00010430917609483004; Prob_backwards: 0.032015156000852585\n",
      "Word: who \t Prob_forward: 0.29403290152549744; Prob_backwards: 0.5149261951446533\n",
      "Word: arrived \t Prob_forward: 1.564584999869112e-05; Prob_backwards: 0.0010477282339707017\n",
      "Word: late \t Prob_forward: 0.0014849362196400762; Prob_backwards: 4.160567641520174e-06\n",
      "Word: ate \t Prob_forward: 2.5576040570740588e-05; Prob_backwards: 0.005243169609457254\n",
      "Word: the \t Prob_forward: 0.04323061928153038; Prob_backwards: 0.19019478559494019\n",
      "Word: steak \t Prob_forward: 0.013004593551158905; Prob_backwards: 8.301284651679453e-06\n",
      "Word: with \t Prob_forward: 0.42883676290512085; Prob_backwards: 0.05156519636511803\n",
      "Word: a \t Prob_forward: 0.7873855233192444; Prob_backwards: 0.9149152040481567\n",
      "Word: glass \t Prob_forward: 0.00016356499691028148; Prob_backwards: 0.039599135518074036\n",
      "Word: of \t Prob_forward: 0.9950628876686096; Prob_backwards: 0.004286559764295816\n",
      "Word: wine \t Prob_forward: 0.6224004626274109; Prob_backwards: 1.0455462870595511e-05\n",
      "Word: . \t Prob_forward: 0.9916564226150513; Prob_backwards: 0.7609730958938599\n",
      "Geometric-mean forward sentence probability: 0.26655659079551697\n",
      "Geometric-mean backward sentence probability: 0.21550747752189636\n",
      "\n",
      "Average normalized sentence prob: 0.23967673750111462\n",
      "\n",
      "Processing sentence: ['[CLS]', 'the', 'steak', 'was', 'eaten', 'by', 'the', 'man', '.', '[SEP]']\n",
      "\n",
      "Word: the \t Prob_forward: 0.0031236112117767334; Prob_backwards: 0.8093088269233704\n",
      "Word: steak \t Prob_forward: 8.519217772118282e-06; Prob_backwards: 0.0003375005326233804\n",
      "Word: was \t Prob_forward: 0.07083046436309814; Prob_backwards: 0.7328842878341675\n",
      "Word: eaten \t Prob_forward: 0.00020068850426468998; Prob_backwards: 0.0015599207254126668\n",
      "Word: by \t Prob_forward: 0.1012411043047905; Prob_backwards: 0.0018896032124757767\n",
      "Word: the \t Prob_forward: 0.5529958009719849; Prob_backwards: 0.024415303021669388\n",
      "Word: man \t Prob_forward: 0.002768035512417555; Prob_backwards: 0.00042284070514142513\n",
      "Word: . \t Prob_forward: 0.9761257767677307; Prob_backwards: 0.7406781911849976\n",
      "Geometric-mean forward sentence probability: 0.170729398727417\n",
      "Geometric-mean backward sentence probability: 0.23114962577819825\n",
      "\n",
      "Average normalized sentence prob: 0.1986555728520578\n",
      "\n",
      "Processing sentence: ['[CLS]', 'the', 'stake', 'ate', 'the', 'man', '.', '[SEP]']\n",
      "\n",
      "Word: the \t Prob_forward: 0.006482909899204969; Prob_backwards: 0.850401759147644\n",
      "Word: stake \t Prob_forward: 4.5493732613977045e-05; Prob_backwards: 5.784730092273094e-05\n",
      "Word: ate \t Prob_forward: 1.0680463446988142e-06; Prob_backwards: 9.676985428086482e-06\n",
      "Word: the \t Prob_forward: 0.09574969112873077; Prob_backwards: 0.06275036931037903\n",
      "Word: man \t Prob_forward: 0.0020853555761277676; Prob_backwards: 0.00013108947314321995\n",
      "Word: . \t Prob_forward: 0.9986978769302368; Prob_backwards: 0.7197229266166687\n",
      "Geometric-mean forward sentence probability: 0.137882798910141\n",
      "Geometric-mean backward sentence probability: 0.20413421094417572\n",
      "\n",
      "Average normalized sentence prob: 0.16776947385712362\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.16776947385712362"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentence_prob(\"The man ate the steak.\")\n",
    "get_sentence_prob(\"The man who arrived late ate the steak with a glass of wine.\")\n",
    "get_sentence_prob(\"The steak was eaten by the man.\")\n",
    "get_sentence_prob(\"The stake ate the man.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence: ['[CLS]', 'he', 'was', 'born', 'in', 'berlin', '.', '[SEP]']\n",
      "\n",
      "Word: he \t Prob_forward: 0.0006875116960145533; Prob_backwards: 0.7967859506607056\n",
      "Word: was \t Prob_forward: 0.611086905002594; Prob_backwards: 0.999992847442627\n",
      "Word: born \t Prob_forward: 0.0001007601385936141; Prob_backwards: 0.0007875352748669684\n",
      "Word: in \t Prob_forward: 0.9955852031707764; Prob_backwards: 0.07671105861663818\n",
      "Word: berlin \t Prob_forward: 0.02386103756725788; Prob_backwards: 7.354922854574397e-05\n",
      "Word: . \t Prob_forward: 0.9999347925186157; Prob_backwards: 0.7197229266166687\n",
      "Geometric-mean forward sentence probability: 0.3289070129394531\n",
      "Geometric-mean backward sentence probability: 0.3242592215538025\n",
      "\n",
      "Average normalized sentence prob: 0.326574848969319\n",
      "\n",
      "Processing sentence: ['[CLS]', 'he', 'was', 'born', 'in', 'santiago', '.', '[SEP]']\n",
      "\n",
      "Word: he \t Prob_forward: 0.0006875116960145533; Prob_backwards: 0.7612152695655823\n",
      "Word: was \t Prob_forward: 0.611086905002594; Prob_backwards: 0.9999200105667114\n",
      "Word: born \t Prob_forward: 0.0001007601385936141; Prob_backwards: 0.0027990778908133507\n",
      "Word: in \t Prob_forward: 0.9955852031707764; Prob_backwards: 0.002953069983050227\n",
      "Word: santiago \t Prob_forward: 0.001118713291361928; Prob_backwards: 1.3199482964409981e-05\n",
      "Word: . \t Prob_forward: 0.9998825788497925; Prob_backwards: 0.7197229266166687\n",
      "Geometric-mean forward sentence probability: 0.32605770230293274\n",
      "Geometric-mean backward sentence probability: 0.31082794070243835\n",
      "\n",
      "Average normalized sentence prob: 0.31835176166779616\n",
      "\n",
      "Processing sentence: ['[CLS]', 'he', 'was', 'born', 'in', 'france', '.', '[SEP]']\n",
      "\n",
      "Word: he \t Prob_forward: 0.0006875116960145533; Prob_backwards: 0.7930527329444885\n",
      "Word: was \t Prob_forward: 0.611086905002594; Prob_backwards: 0.9999494552612305\n",
      "Word: born \t Prob_forward: 0.0001007601385936141; Prob_backwards: 0.0343296080827713\n",
      "Word: in \t Prob_forward: 0.9955852031707764; Prob_backwards: 0.19816343486309052\n",
      "Word: france \t Prob_forward: 0.002361555816605687; Prob_backwards: 3.507085784804076e-05\n",
      "Word: . \t Prob_forward: 0.9997918009757996; Prob_backwards: 0.7197229266166687\n",
      "Geometric-mean forward sentence probability: 0.3262017071247101\n",
      "Geometric-mean backward sentence probability: 0.3431566655635834\n",
      "\n",
      "Average normalized sentence prob: 0.3345718011400006\n",
      "\n",
      "Processing sentence: ['[CLS]', 'he', 'was', 'born', 'in', 'window', '.', '[SEP]']\n",
      "\n",
      "Word: he \t Prob_forward: 0.0006875116960145533; Prob_backwards: 0.6543523073196411\n",
      "Word: was \t Prob_forward: 0.611086905002594; Prob_backwards: 0.9994819760322571\n",
      "Word: born \t Prob_forward: 0.0001007601385936141; Prob_backwards: 2.647951987455599e-05\n",
      "Word: in \t Prob_forward: 0.9955852031707764; Prob_backwards: 0.008949845097959042\n",
      "Word: window \t Prob_forward: 1.2145428627263755e-06; Prob_backwards: 4.7352070396300405e-05\n",
      "Word: . \t Prob_forward: 0.9915589094161987; Prob_backwards: 0.7197229266166687\n",
      "Geometric-mean forward sentence probability: 0.3248775601387024\n",
      "Geometric-mean backward sentence probability: 0.29782262444496155\n",
      "\n",
      "Average normalized sentence prob: 0.3110560843060045\n",
      "\n",
      "Processing sentence: ['[CLS]', 'he', 'was', 'born', 'in', 'was', '.', '[SEP]']\n",
      "\n",
      "Word: he \t Prob_forward: 0.0006875116960145533; Prob_backwards: 0.7139879465103149\n",
      "Word: was \t Prob_forward: 0.611086905002594; Prob_backwards: 0.999850869178772\n",
      "Word: born \t Prob_forward: 0.0001007601385936141; Prob_backwards: 0.00020530555048026145\n",
      "Word: in \t Prob_forward: 0.9955852031707764; Prob_backwards: 5.982379298075102e-05\n",
      "Word: was \t Prob_forward: 1.0944118002953473e-06; Prob_backwards: 5.345148383639753e-05\n",
      "Word: . \t Prob_forward: 0.9949527978897095; Prob_backwards: 0.7197229266166687\n",
      "Geometric-mean forward sentence probability: 0.32530176639556885\n",
      "Geometric-mean backward sentence probability: 0.30423504114151\n",
      "\n",
      "Average normalized sentence prob: 0.3145921109671407\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3145921109671407"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentence_prob(\"He was born in Berlin.\")\n",
    "get_sentence_prob(\"He was born in Santiago.\")\n",
    "get_sentence_prob(\"He was born in France.\")\n",
    "get_sentence_prob(\"He was born in window.\")\n",
    "get_sentence_prob(\"He was born in was.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence: ['[CLS]', 'i', 'fed', 'my', 'cat', 'some', 'of', 'it', 'and', 'he', 'damn', 'near', 'passed', 'out', '.', '[SEP]']\n",
      "\n",
      "Word: i \t Prob_forward: 0.0005238083540461957; Prob_backwards: 0.9958482980728149\n",
      "Word: fed \t Prob_forward: 1.7332116840407252e-05; Prob_backwards: 0.17128999531269073\n",
      "Word: my \t Prob_forward: 0.012338080443441868; Prob_backwards: 0.10841826349496841\n",
      "Word: cat \t Prob_forward: 0.00244920514523983; Prob_backwards: 1.8786481632560026e-06\n",
      "Word: some \t Prob_forward: 0.007367619778960943; Prob_backwards: 0.0040093897841870785\n",
      "Word: of \t Prob_forward: 1.723681816656608e-05; Prob_backwards: 0.06822692602872849\n",
      "Word: it \t Prob_forward: 0.00012771011097356677; Prob_backwards: 2.4723083697608672e-05\n",
      "Word: and \t Prob_forward: 0.5446289777755737; Prob_backwards: 0.5079375505447388\n",
      "Word: he \t Prob_forward: 0.0061583081260323524; Prob_backwards: 0.048276130110025406\n",
      "Word: damn \t Prob_forward: 2.3060283638187684e-05; Prob_backwards: 0.7008697390556335\n",
      "Word: near \t Prob_forward: 0.4169158637523651; Prob_backwards: 0.00010126514098374173\n",
      "Word: passed \t Prob_forward: 7.57075467845425e-05; Prob_backwards: 0.0015395785449072719\n",
      "Word: out \t Prob_forward: 0.9994945526123047; Prob_backwards: 0.0001479800557717681\n",
      "Word: . \t Prob_forward: 0.9991564750671387; Prob_backwards: 0.7609730958938599\n",
      "Geometric-mean forward sentence probability: 0.18683087825775146\n",
      "Geometric-mean backward sentence probability: 0.21047905087471008\n",
      "\n",
      "Average normalized sentence prob: 0.19830276329335414\n",
      "\n",
      "Processing sentence: ['[CLS]', 'i', 'fed', 'my', 'dog', 'some', 'of', 'it', 'and', 'he', 'damn', 'near', 'passed', 'out', '.', '[SEP]']\n",
      "\n",
      "Word: i \t Prob_forward: 0.0005238083540461957; Prob_backwards: 0.9969239830970764\n",
      "Word: fed \t Prob_forward: 1.7332116840407252e-05; Prob_backwards: 0.16240531206130981\n",
      "Word: my \t Prob_forward: 0.012338080443441868; Prob_backwards: 0.25622084736824036\n",
      "Word: dog \t Prob_forward: 0.001873779227025807; Prob_backwards: 1.8579952666186728e-05\n",
      "Word: some \t Prob_forward: 0.024183275178074837; Prob_backwards: 0.0040093897841870785\n",
      "Word: of \t Prob_forward: 6.944186316104606e-05; Prob_backwards: 0.06822692602872849\n",
      "Word: it \t Prob_forward: 0.00018041624571196735; Prob_backwards: 2.4723083697608672e-05\n",
      "Word: and \t Prob_forward: 0.5516229867935181; Prob_backwards: 0.5079375505447388\n",
      "Word: he \t Prob_forward: 0.0019600701052695513; Prob_backwards: 0.048276130110025406\n",
      "Word: damn \t Prob_forward: 2.8778084015357308e-05; Prob_backwards: 0.7008697390556335\n",
      "Word: near \t Prob_forward: 0.425414502620697; Prob_backwards: 0.00010126514098374173\n",
      "Word: passed \t Prob_forward: 8.339445776073262e-05; Prob_backwards: 0.0015395785449072719\n",
      "Word: out \t Prob_forward: 0.9994495511054993; Prob_backwards: 0.0001479800557717681\n",
      "Word: . \t Prob_forward: 0.9986190795898438; Prob_backwards: 0.7609730958938599\n",
      "Geometric-mean forward sentence probability: 0.18852278590202332\n",
      "Geometric-mean backward sentence probability: 0.21922969818115234\n",
      "\n",
      "Average normalized sentence prob: 0.20329730311435656\n",
      "\n",
      "Processing sentence: ['[CLS]', 'i', 'fed', 'my', 'window', 'some', 'of', 'it', 'and', 'he', 'damn', 'near', 'passed', 'out', '.', '[SEP]']\n",
      "\n",
      "Word: i \t Prob_forward: 0.0005238083540461957; Prob_backwards: 0.9672557711601257\n",
      "Word: fed \t Prob_forward: 1.7332116840407252e-05; Prob_backwards: 0.00012052484089508653\n",
      "Word: my \t Prob_forward: 0.012338080443441868; Prob_backwards: 0.055196020752191544\n",
      "Word: window \t Prob_forward: 3.074419146287255e-05; Prob_backwards: 4.564195023704087e-06\n",
      "Word: some \t Prob_forward: 5.5066415370674804e-05; Prob_backwards: 0.0040093897841870785\n",
      "Word: of \t Prob_forward: 0.0002885802823584527; Prob_backwards: 0.06822692602872849\n",
      "Word: it \t Prob_forward: 0.0003021394950337708; Prob_backwards: 2.4723083697608672e-05\n",
      "Word: and \t Prob_forward: 0.3958088457584381; Prob_backwards: 0.5079375505447388\n",
      "Word: he \t Prob_forward: 5.880855678697117e-05; Prob_backwards: 0.048276130110025406\n",
      "Word: damn \t Prob_forward: 9.875305295281578e-06; Prob_backwards: 0.7008697390556335\n",
      "Word: near \t Prob_forward: 0.23852427303791046; Prob_backwards: 0.00010126514098374173\n",
      "Word: passed \t Prob_forward: 0.00013139680959284306; Prob_backwards: 0.0015395785449072719\n",
      "Word: out \t Prob_forward: 0.9993270635604858; Prob_backwards: 0.0001479800557717681\n",
      "Word: . \t Prob_forward: 0.999427080154419; Prob_backwards: 0.7609730958938599\n",
      "Geometric-mean forward sentence probability: 0.16542768478393555\n",
      "Geometric-mean backward sentence probability: 0.19466769695281982\n",
      "\n",
      "Average normalized sentence prob: 0.17945313151105993\n",
      "\n",
      "Processing sentence: ['[CLS]', 'i', 'fed', 'my', 'the', 'some', 'of', 'it', 'and', 'he', 'damn', 'near', 'passed', 'out', '.', '[SEP]']\n",
      "\n",
      "Word: i \t Prob_forward: 0.0005238083540461957; Prob_backwards: 0.8631967306137085\n",
      "Word: fed \t Prob_forward: 1.7332116840407252e-05; Prob_backwards: 0.004314483143389225\n",
      "Word: my \t Prob_forward: 0.012338080443441868; Prob_backwards: 6.479790317825973e-05\n",
      "Word: the \t Prob_forward: 0.0005163894966244698; Prob_backwards: 0.00020219777070451528\n",
      "Word: some \t Prob_forward: 3.3537235140101984e-05; Prob_backwards: 0.0040093897841870785\n",
      "Word: of \t Prob_forward: 0.017259739339351654; Prob_backwards: 0.06822692602872849\n",
      "Word: it \t Prob_forward: 0.00356102897785604; Prob_backwards: 2.4723083697608672e-05\n",
      "Word: and \t Prob_forward: 0.40840384364128113; Prob_backwards: 0.5079375505447388\n",
      "Word: he \t Prob_forward: 0.00035771005786955357; Prob_backwards: 0.048276130110025406\n",
      "Word: damn \t Prob_forward: 2.1192281565163285e-06; Prob_backwards: 0.7008697390556335\n",
      "Word: near \t Prob_forward: 0.21973887085914612; Prob_backwards: 0.00010126514098374173\n",
      "Word: passed \t Prob_forward: 0.00019226186850573868; Prob_backwards: 0.0015395785449072719\n",
      "Word: out \t Prob_forward: 0.9997089505195618; Prob_backwards: 0.0001479800557717681\n",
      "Word: . \t Prob_forward: 0.998624324798584; Prob_backwards: 0.7609730958938599\n",
      "Geometric-mean forward sentence probability: 0.16632987558841705\n",
      "Geometric-mean backward sentence probability: 0.18499279022216797\n",
      "\n",
      "Average normalized sentence prob: 0.17541330560253213\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17541330560253213"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentence_prob(\"I fed my cat some of it and he damn near passed out.\")\n",
    "get_sentence_prob(\"I fed my dog some of it and he damn near passed out.\")\n",
    "get_sentence_prob(\"I fed my window some of it and he damn near passed out.\")\n",
    "get_sentence_prob(\"I fed my the some of it and he damn near passed out.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Should have similar/high probs\\n\")\n",
    "get_sentence_prob(\"I forgot to take my medicine.\")\n",
    "get_sentence_prob(\"I forgot to take my medicines.\")\n",
    "get_sentence_prob(\"I forgot to take my medication.\")\n",
    "get_sentence_prob(\"I forgot to take my pills.\")\n",
    "print(\"Should have low probs\\n\")\n",
    "get_sentence_prob(\"I forgot to take my turn.\")\n",
    "get_sentence_prob(\"I forgot to take my medical.\")\n",
    "get_sentence_prob(\"I forgot to take my medically.\")\n",
    "get_sentence_prob(\"I forgot to take my turned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence: ['[CLS]', 'we', 'will', 'explore', 'the', 'elements', 'used', 'to', 'construct', 'sentences', ',', 'and', 'what', 'parts', 'of', 'speech', 'are', 'used', 'to', 'expand', 'and', 'elaborate', 'on', 'them', '.', '[SEP]']\n",
      "\n",
      "Word: we \t Prob_forward: 1.6642563423374668e-05; Prob_backwards: 0.01786622405052185\n",
      "Word: will \t Prob_forward: 0.002434785244986415; Prob_backwards: 0.06851402670145035\n",
      "Word: explore \t Prob_forward: 1.6068875993369147e-05; Prob_backwards: 0.0008845478878356516\n",
      "Word: the \t Prob_forward: 0.6480313539505005; Prob_backwards: 0.5417339205741882\n",
      "Word: elements \t Prob_forward: 0.00011011799506377429; Prob_backwards: 8.632599201519042e-05\n",
      "Word: used \t Prob_forward: 4.9860776925925165e-05; Prob_backwards: 0.7221975922584534\n",
      "Word: to \t Prob_forward: 0.041129741817712784; Prob_backwards: 0.9706997871398926\n",
      "Word: construct \t Prob_forward: 0.003627343336120248; Prob_backwards: 5.39941611350514e-05\n",
      "Word: sentences \t Prob_forward: 7.629900551364699e-07; Prob_backwards: 0.0035804409999400377\n",
      "Word: , \t Prob_forward: 0.0999969020485878; Prob_backwards: 0.78018718957901\n",
      "Word: and \t Prob_forward: 0.08384449779987335; Prob_backwards: 0.008881714195013046\n",
      "Word: what \t Prob_forward: 0.0009997623274102807; Prob_backwards: 0.008585299365222454\n",
      "Word: parts \t Prob_forward: 0.005878846161067486; Prob_backwards: 0.29922837018966675\n",
      "Word: of \t Prob_forward: 0.005989460740238428; Prob_backwards: 0.022704225033521652\n",
      "Word: speech \t Prob_forward: 0.0002994531823787838; Prob_backwards: 3.847288462566212e-05\n",
      "Word: are \t Prob_forward: 0.9055652022361755; Prob_backwards: 0.2639956772327423\n",
      "Word: used \t Prob_forward: 0.10661078989505768; Prob_backwards: 0.008128069341182709\n",
      "Word: to \t Prob_forward: 0.9451584219932556; Prob_backwards: 0.626500129699707\n",
      "Word: expand \t Prob_forward: 2.0943292838637717e-05; Prob_backwards: 3.0438391718234925e-07\n",
      "Word: and \t Prob_forward: 0.09903806447982788; Prob_backwards: 0.111882783472538\n",
      "Word: elaborate \t Prob_forward: 0.0006932351971045136; Prob_backwards: 2.6263696781825274e-05\n",
      "Word: on \t Prob_forward: 0.039937544614076614; Prob_backwards: 0.06231745705008507\n",
      "Word: them \t Prob_forward: 0.423604816198349; Prob_backwards: 0.00023009766300674528\n",
      "Word: . \t Prob_forward: 0.9987418055534363; Prob_backwards: 0.6952449679374695\n",
      "Geometric-mean forward sentence probability: 0.16968448345477766\n",
      "Geometric-mean backward sentence probability: 0.20052181757413423\n",
      "\n",
      "Average normalized sentence prob: 0.1844598629417254\n",
      "\n",
      "Processing sentence: ['[CLS]', 'wikipedia', 'is', 'a', 'multi', '##ling', '##ual', 'online', 'encyclopedia', 'created', 'and', 'maintained', 'as', 'an', 'open', 'collaboration', 'project', 'by', 'a', 'community', 'of', 'volunteer', 'editors', '.', '[SEP]']\n",
      "\n",
      "Word: wikipedia \t Prob_forward: 2.4891001885407604e-05; Prob_backwards: 0.26914334297180176\n",
      "Word: is \t Prob_forward: 0.00014022781397216022; Prob_backwards: 0.983816385269165\n",
      "Word: a \t Prob_forward: 0.01839929260313511; Prob_backwards: 0.6362264156341553\n",
      "Word: multi \t Prob_forward: 0.0018113007536157966; Prob_backwards: 0.9434198141098022\n",
      "Word: ##ling \t Prob_forward: 0.00010994893818860874; Prob_backwards: 0.0009888175409287214\n",
      "Word: ##ual \t Prob_forward: 0.9995064735412598; Prob_backwards: 4.4531649479040425e-08\n",
      "Word: online \t Prob_forward: 0.004548950586467981; Prob_backwards: 0.5335986018180847\n",
      "Word: encyclopedia \t Prob_forward: 0.31564435362815857; Prob_backwards: 7.978633931315926e-08\n",
      "Word: created \t Prob_forward: 0.0002835589984897524; Prob_backwards: 0.13486841320991516\n",
      "Word: and \t Prob_forward: 0.014770678244531155; Prob_backwards: 0.0005246482905931771\n",
      "Word: maintained \t Prob_forward: 0.019900022074580193; Prob_backwards: 0.0007075816974975169\n",
      "Word: as \t Prob_forward: 0.0014062287518754601; Prob_backwards: 0.0015125788049772382\n",
      "Word: an \t Prob_forward: 0.005623962730169296; Prob_backwards: 0.9430293440818787\n",
      "Word: open \t Prob_forward: 0.25152459740638733; Prob_backwards: 0.00010294946696376428\n",
      "Word: collaboration \t Prob_forward: 5.353112101147417e-06; Prob_backwards: 0.003476595738902688\n",
      "Word: project \t Prob_forward: 0.0010910829296335578; Prob_backwards: 1.046458328346489e-05\n",
      "Word: by \t Prob_forward: 0.5551554560661316; Prob_backwards: 0.016397399827837944\n",
      "Word: a \t Prob_forward: 0.0042177168652415276; Prob_backwards: 0.6050601005554199\n",
      "Word: community \t Prob_forward: 0.005989608354866505; Prob_backwards: 0.0655047670006752\n",
      "Word: of \t Prob_forward: 0.9838712215423584; Prob_backwards: 0.014275266788899899\n",
      "Word: volunteer \t Prob_forward: 0.042091891169548035; Prob_backwards: 7.905096572358161e-05\n",
      "Word: editors \t Prob_forward: 0.7438857555389404; Prob_backwards: 2.0948000383214094e-05\n",
      "Word: . \t Prob_forward: 0.9994000196456909; Prob_backwards: 0.7018031477928162\n",
      "Geometric-mean forward sentence probability: 0.19877609252929687\n",
      "Geometric-mean backward sentence probability: 0.2341826629638672\n",
      "\n",
      "Average normalized sentence prob: 0.21575429238386615\n",
      "\n",
      "Processing sentence: ['[CLS]', 'once', 'she', 'gave', 'her', 'a', 'little', 'cap', 'of', 'red', 'velvet', ',', 'which', 'suited', 'her', 'so', 'well', 'that', 'she', 'would', 'never', 'wear', 'anything', 'else', '.', '[SEP]']\n",
      "\n",
      "Word: once \t Prob_forward: 1.7992379071074538e-05; Prob_backwards: 0.003435404971241951\n",
      "Word: she \t Prob_forward: 0.009854196570813656; Prob_backwards: 0.0006021691369824111\n",
      "Word: gave \t Prob_forward: 0.0009010668145492673; Prob_backwards: 0.09642218053340912\n",
      "Word: her \t Prob_forward: 0.07317624986171722; Prob_backwards: 0.003920089919120073\n",
      "Word: a \t Prob_forward: 0.007067261263728142; Prob_backwards: 0.7968737483024597\n",
      "Word: little \t Prob_forward: 0.02135993354022503; Prob_backwards: 0.0036949850618839264\n",
      "Word: cap \t Prob_forward: 1.70629245985765e-05; Prob_backwards: 0.00406852550804615\n",
      "Word: of \t Prob_forward: 0.03889670968055725; Prob_backwards: 0.008378743194043636\n",
      "Word: red \t Prob_forward: 0.04231778904795647; Prob_backwards: 0.21043312549591064\n",
      "Word: velvet \t Prob_forward: 0.03853045776486397; Prob_backwards: 0.00021432837820611894\n",
      "Word: , \t Prob_forward: 0.33217841386795044; Prob_backwards: 0.9712464213371277\n",
      "Word: which \t Prob_forward: 0.11341851204633713; Prob_backwards: 0.008497748523950577\n",
      "Word: suited \t Prob_forward: 5.303218131302856e-06; Prob_backwards: 0.40232884883880615\n",
      "Word: her \t Prob_forward: 0.5320029258728027; Prob_backwards: 0.019590923562645912\n",
      "Word: so \t Prob_forward: 0.0020743473432958126; Prob_backwards: 0.20700880885124207\n",
      "Word: well \t Prob_forward: 0.14377108216285706; Prob_backwards: 3.3975436963373795e-05\n",
      "Word: that \t Prob_forward: 0.6603685617446899; Prob_backwards: 0.007416556589305401\n",
      "Word: she \t Prob_forward: 0.6794349551200867; Prob_backwards: 0.05965884402394295\n",
      "Word: would \t Prob_forward: 0.09173430502414703; Prob_backwards: 0.016262738034129143\n",
      "Word: never \t Prob_forward: 0.5110812783241272; Prob_backwards: 0.06443699449300766\n",
      "Word: wear \t Prob_forward: 0.12809838354587555; Prob_backwards: 2.900141453210381e-06\n",
      "Word: anything \t Prob_forward: 0.006769491825252771; Prob_backwards: 0.07401714473962784\n",
      "Word: else \t Prob_forward: 0.7910427451133728; Prob_backwards: 2.3227063138619997e-05\n",
      "Word: . \t Prob_forward: 0.9912789463996887; Prob_backwards: 0.6952449679374695\n",
      "Geometric-mean forward sentence probability: 0.2005922427544227\n",
      "Geometric-mean backward sentence probability: 0.1405312831585224\n",
      "\n",
      "Average normalized sentence prob: 0.1678972461534877\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1678972461534877"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentence_prob(\"We will explore the elements used to construct sentences, and what parts of speech are used to expand and elaborate on them.\")\n",
    "get_sentence_prob(\"Wikipedia is a multilingual online encyclopedia created and maintained as an open collaboration project by a community of volunteer editors.\")\n",
    "get_sentence_prob(\"Once she gave her a little cap of red velvet, which suited her so well that she would never wear anything else.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model (weights)\n",
    "with torch.no_grad():\n",
    "    model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "    model.eval()\n",
    "    # Load pre-trained model tokenizer (vocabulary)\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_sentence_prob(\"I fed my cat some of it and he damn near passed out\")\n",
    "get_sentence_prob(\"He was born in Berlin.\")\n",
    "get_sentence_prob(\"He was born in Santiago.\")\n",
    "get_sentence_prob(\"He was born in France.\")\n",
    "get_sentence_prob(\"He was born in window.\")\n",
    "get_sentence_prob(\"He was born in was.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentence_prob(\"I fed my cat some of it and he damn near passed out.\")\n",
    "get_sentence_prob(\"I fed my dog some of it and he damn near passed out.\")\n",
    "get_sentence_prob(\"I fed my window some of it and he damn near passed out.\")\n",
    "get_sentence_prob(\"I fed my the some of it and he damn near passed out.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Should have similar/high probs\\n\")\n",
    "get_sentence_prob(\"I forgot to take my medicine.\")\n",
    "get_sentence_prob(\"I forgot to take my medicines.\")\n",
    "get_sentence_prob(\"I forgot to take my medication.\")\n",
    "get_sentence_prob(\"I forgot to take my pills.\")\n",
    "print(\"Should have low probs\\n\")\n",
    "get_sentence_prob(\"I forgot to take my turn.\")\n",
    "get_sentence_prob(\"I forgot to take my medical.\")\n",
    "get_sentence_prob(\"I forgot to take my medically.\")\n",
    "get_sentence_prob(\"I forgot to take my turned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:transformers]",
   "language": "python",
   "name": "conda-env-transformers-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
