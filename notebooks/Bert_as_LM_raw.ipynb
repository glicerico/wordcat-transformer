{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate sentence probability with BERT\n",
    "## Calculating probability more properly:\n",
    "P_f, P_b: Probability forward pass, backward pass, respectively\n",
    "```\n",
    "P_f = P(w_0) * P(w_1|w_0) * P(w_2|w_0, w_1) * ... * P(w_N)\n",
    "P_b = P(w_N-1|w_N) * P(w_N-2|w_N-1, w_N) * ... * P(w_0|w_1, w_2, ... ,w_N)\n",
    "```\n",
    "In this notebook, probabilities are not normalized by sentence length, so `P_f`, `P_b` become smaller as the sentence length increases.\n",
    "\n",
    "Finally, the sentence probability P(S) is the geometric mean of forward and backwards probabilities:\n",
    "```\n",
    "P(S) = (P_f(S) * P_b(S)) ^ (1/2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "\n",
    "BOS_TOKEN = '[CLS]'\n",
    "EOS_TOKEN = '[SEP]'\n",
    "MASK_TOKEN = '[MASK]'\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "with torch.no_grad():\n",
    "    model = BertForMaskedLM.from_pretrained('bert-large-uncased')\n",
    "#     model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "    model.eval()\n",
    "    # Load pre-trained model tokenizer (vocabulary)\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "#     tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_predictions(probs, k=5):\n",
    "    probs = probs.detach().numpy()\n",
    "    top_indexes = np.argpartition(probs, -k)[-k:]\n",
    "    sorted_indexes = top_indexes[np.argsort(-probs[top_indexes])]\n",
    "    top_tokens = tokenizer.convert_ids_to_tokens(sorted_indexes)\n",
    "    print(f\"Ordered top predicted tokens: {top_tokens}\")\n",
    "    print(f\"Ordered top predicted values: {probs[sorted_indexes]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_prob(sentence, verbose=False):\n",
    "    # Pre-process sentence, adding special tokens\n",
    "    tokenized_input = tokenizer.tokenize(sentence)\n",
    "    if tokenized_input[0] != BOS_TOKEN:\n",
    "        tokenized_input.insert(0, BOS_TOKEN)\n",
    "    if tokenized_input[-1] != EOS_TOKEN:\n",
    "        tokenized_input.append(EOS_TOKEN)\n",
    "    sent_len = len(tokenized_input)\n",
    "    ids_input = tokenizer.convert_tokens_to_ids(tokenized_input)\n",
    "    print(f\"Processing sentence: {tokenized_input}\\n\")\n",
    "    \n",
    "    sm = torch.nn.Softmax(dim=0) # used to convert last hidden state to probs\n",
    "    \n",
    "    log_sent_prob_forward = 0\n",
    "    log_sent_prob_backwards = 0\n",
    "    # Mask non-special tokens in forward and backwards directions; calculate their probabilities\n",
    "    for i in range(1, len(tokenized_input) - 1):  # Don't loop first and last tokens\n",
    "        probs_forward = get_directional_prob(sm, tokenized_input, i, 'forward', verbose=verbose)\n",
    "        probs_backwards = get_directional_prob(sm, tokenized_input, i, 'backwards', verbose=verbose)\n",
    "        log_prob_forward = probs_forward[ids_input[i]]  # Prediction for masked word\n",
    "        log_prob_forward = np.log10(log_prob_forward.detach().numpy())\n",
    "        log_prob_backwards = probs_backwards[ids_input[i]]  # Prediction for masked word\n",
    "        log_prob_backwards = np.log10(log_prob_backwards.detach().numpy())\n",
    "        log_sent_prob_forward += log_prob_forward\n",
    "        log_sent_prob_backwards += log_prob_backwards\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Word: {tokenized_input[i]} \\t Log-Prob_forward: {log_prob_forward}; Log-Prob_backwards: {log_prob_backwards}\")\n",
    "\n",
    "    # Obtain geometric average of forward and backward probs\n",
    "    log_geom_mean_sent_prob = 0.5 * (log_sent_prob_forward + log_sent_prob_backwards)\n",
    "    if verbose:\n",
    "        print(f\"Raw forward sentence probability: {log_sent_prob_forward}\")\n",
    "        print(f\"Raw backward sentence probability: {log_sent_prob_backwards}\\n\")\n",
    "        print(f\"Average normalized sentence prob: {log_geom_mean_sent_prob}\\n\")\n",
    "    sentence_prob = np.power(10, log_geom_mean_sent_prob)\n",
    "    print(sentence_prob)\n",
    "    return sentence_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_directional_prob(sm, tokenized_input, i, direction, verbose=False):\n",
    "    current_tokens = tokenized_input[:]\n",
    "    if direction == 'backwards':\n",
    "        current_tokens[1:i+1] = [MASK_TOKEN for j in range(i)]\n",
    "    elif direction == 'forward':\n",
    "        current_tokens[i:-1] = [MASK_TOKEN for j in range(len(tokenized_input) - 1 - i)]\n",
    "    else:\n",
    "        print(\"Direction can only be 'forward' or 'backwards'\")\n",
    "        exit()\n",
    "    if verbose: \n",
    "        print()\n",
    "        print(current_tokens)\n",
    "        \n",
    "    masked_input = torch.tensor([tokenizer.convert_tokens_to_ids(current_tokens)])\n",
    "    predictions = model(masked_input)\n",
    "    predictions = predictions[0]\n",
    "    probs = sm(predictions[0, i]) # Softmax to get probabilities\n",
    "    if verbose: \n",
    "        print_top_predictions(probs)\n",
    "    \n",
    "    return probs # Model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence: ['[CLS]', 'the', 'fat', 'cat', 'ate', 'the', 'last', 'mouse', 'quickly', '.', '[SEP]']\n",
      "\n",
      "1.5699080230392615e-23\n",
      "Processing sentence: ['[CLS]', 'there', 'are', 'many', 'health', 'risks', 'associated', 'with', 'fat', '.', '[SEP]']\n",
      "\n",
      "8.689618845171052e-20\n",
      "Processing sentence: ['[CLS]', 'they', 'will', 'fly', 'out', 'of', 'santiago', 'tomorrow', 'morning', '.', '[SEP]']\n",
      "\n",
      "3.506387431159266e-22\n",
      "Processing sentence: ['[CLS]', 'she', 'bought', 'the', 'last', 'microsoft', 'mouse', 'for', 'santiago', '.', '[SEP]']\n",
      "\n",
      "2.933483879831623e-28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.933483879831623e-28"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentence_prob(\"The fat cat ate the last mouse quickly.\", verbose=False)\n",
    "get_sentence_prob(\"There are many health risks associated with fat.\")\n",
    "get_sentence_prob(\"They will fly out of Santiago tomorrow morning.\")\n",
    "get_sentence_prob(\"She bought the last Microsoft mouse for Santiago.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9354396584371938e-23"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power((1.5699080230392615e-23 * 8.689618845171052e-20 * 3.506387431159266e-22 * 2.933483879831623e-28), 1/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence: ['[CLS]', 'the', 'deteriorated', 'cat', 'ate', 'the', 'last', 'mouse', 'quickly', '.', '[SEP]']\n",
      "\n",
      "1.552863016010471e-26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.000802330886029461"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentence_prob(\"The deteriorated cat ate the last mouse quickly.\")/1.9354396584371938e-23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sentence: ['[CLS]', 'there', 'are', 'many', 'health', 'risks', 'associated', 'with', 'time', '.', '[SEP]']\n",
      "\n",
      "5.7637240939881745e-22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29.779921419209725"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentence_prob(\"There are many health risks associated with time.\")/1.9354396584371938e-23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentence_prob(\"penguins are birds.\")\n",
    "get_sentence_prob(\"penguins have wings.\")\n",
    "get_sentence_prob(\"wings are useful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentence_prob(\"The kids eat the candy.\")\n",
    "get_sentence_prob(\"The kids eat the apple.\")\n",
    "get_sentence_prob(\"The kids ate the apple.\")\n",
    "get_sentence_prob(\"The kids ate the apple quickly.\")\n",
    "get_sentence_prob(\"The kids ate the apple slowly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentence_prob(\"The kids eat the candy.\")\n",
    "get_sentence_prob(\"kids eat.\")\n",
    "get_sentence_prob(\"eat kids.\")\n",
    "get_sentence_prob(\"kids eat candy.\")\n",
    "get_sentence_prob(\"the kids eat.\")\n",
    "get_sentence_prob(\"small kids eat.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentence_prob(\"Smurfs eat the ancient nuns ungracefully.\")\n",
    "get_sentence_prob(\"Smurfs eat ancient the nuns ungracefully.\")\n",
    "get_sentence_prob(\"eat smurfs the ancient nuns ungracefully.\")\n",
    "get_sentence_prob(\"Smurfs eat the ancient ungracefully nuns.\")\n",
    "get_sentence_prob(\"Smurfs the eat ancient nuns ungracefully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentence_prob(\"kids eat the red grapes quickly.\")\n",
    "get_sentence_prob(\"quickly eat the red grapes kids.\")\n",
    "get_sentence_prob(\"the kids eat the red grapes quickly.\")\n",
    "get_sentence_prob(\"girls eat the red grapes quickly.\")\n",
    "get_sentence_prob(\"the red grapes eat kids quickly.\")\n",
    "get_sentence_prob(\"kids eat red the grapes quickly.\")\n",
    "get_sentence_prob(\"eat kids the red grapes quickly.\")\n",
    "get_sentence_prob(\"kids eat the red quickly grapes.\")\n",
    "get_sentence_prob(\"kids the eat red grapes quickly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentence_prob(\"Colorless green ideas sleep furiously.\")\n",
    "get_sentence_prob(\"Confused dumb benches eat endlessly.\")\n",
    "get_sentence_prob(\"Hairless ugly men complain constantly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentence_prob(\"The test was a success.\")\n",
    "get_sentence_prob(\"The was test a success.\")\n",
    "get_sentence_prob(\"The test was success a.\")\n",
    "get_sentence_prob(\"The party was a success.\")\n",
    "get_sentence_prob(\"The farewell party was definitely not a success.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentence_prob(\"He answered unequivocally.\")\n",
    "get_sentence_prob(\"He answered quickly.\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentence_prob(\"The guy with small hands demanded a quid pro quo.\")\n",
    "get_sentence_prob(\"The guy with small hands demanded an exchange.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentence_prob(\"This is a sentence.\")\n",
    "get_sentence_prob(\"This is a macrame.\", verbose=False)\n",
    "get_sentence_prob(\"This is a joke.\", verbose=False)\n",
    "get_sentence_prob(\"Are you kidding me?\", verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentence_prob(\"Rachel was wearing a lovely satin dress last night.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentence_prob(\"Rachel was wearing a lovely satin dress last night.\")\n",
    "get_sentence_prob(\"Grandma was wearing a lovely satin dress last night.\")\n",
    "get_sentence_prob(\"Mother was wearing a lovely satin dress last night.\")\n",
    "get_sentence_prob(\"She was wearing a lovely satin dress last night.\")\n",
    "get_sentence_prob(\"He was wearing a lovely satin dress last night.\")\n",
    "get_sentence_prob(\"I was wearing a lovely satin dress last night.\")\n",
    "get_sentence_prob(\"Angela was wearing a lovely satin dress last night.\")\n",
    "get_sentence_prob(\"Roberta was wearing a lovely satin dress last night.\")\n",
    "get_sentence_prob(\"Running was wearing a lovely satin dress last night.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentence_prob(\"The man ate the steak.\")\n",
    "get_sentence_prob(\"The stake ate the man.\")\n",
    "get_sentence_prob(\"The man who arrived late ate the steak with a glass of wine.\")\n",
    "get_sentence_prob(\"The steak was eaten by the man.\")\n",
    "get_sentence_prob(\"The man was eaten by the stake.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentence_prob(\"He was born in Berlin.\")\n",
    "get_sentence_prob(\"He was born in Santiago.\")\n",
    "get_sentence_prob(\"He was born in France.\")\n",
    "get_sentence_prob(\"He was born in window.\")\n",
    "get_sentence_prob(\"He was born in was.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentence_prob(\"I fed my cat some of it and he damn near passed out.\")\n",
    "get_sentence_prob(\"I fed my dog some of it and he damn near passed out.\")\n",
    "get_sentence_prob(\"I fed my window some of it and he damn near passed out.\")\n",
    "get_sentence_prob(\"I fed my the some of it and he damn near passed out.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Should have similar/high probs\\n\")\n",
    "get_sentence_prob(\"I forgot to take my medicine.\")\n",
    "get_sentence_prob(\"I forgot to take my medicines.\")\n",
    "get_sentence_prob(\"I forgot to take my medication.\")\n",
    "get_sentence_prob(\"I forgot to take my pills.\")\n",
    "get_sentence_prob(\"I forgot to take my turn.\")\n",
    "print(\"Should have low probs\\n\")\n",
    "get_sentence_prob(\"I forgot to take my medical.\")\n",
    "get_sentence_prob(\"I forgot to take my medically.\")\n",
    "get_sentence_prob(\"I forgot to take my turned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentence_prob(\"We will explore the elements used to construct sentences, and what parts of speech are used to expand and elaborate on them.\")\n",
    "get_sentence_prob(\"Wikipedia is a multilingual online encyclopedia created and maintained as an open collaboration project by a community of volunteer editors.\")\n",
    "get_sentence_prob(\"Once she gave her a little cap of red velvet, which suited her so well that she would never wear anything else.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model (weights)\n",
    "with torch.no_grad():\n",
    "    model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "    model.eval()\n",
    "    # Load pre-trained model tokenizer (vocabulary)\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_sentence_prob(\"I fed my cat some of it and he damn near passed out\")\n",
    "get_sentence_prob(\"He was born in Berlin.\")\n",
    "get_sentence_prob(\"He was born in Santiago.\")\n",
    "get_sentence_prob(\"He was born in France.\")\n",
    "get_sentence_prob(\"He was born in window.\")\n",
    "get_sentence_prob(\"He was born in was.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentence_prob(\"I fed my cat some of it and he damn near passed out.\")\n",
    "get_sentence_prob(\"I fed my dog some of it and he damn near passed out.\")\n",
    "get_sentence_prob(\"I fed my window some of it and he damn near passed out.\")\n",
    "get_sentence_prob(\"I fed my the some of it and he damn near passed out.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Should have similar/high probs\\n\")\n",
    "get_sentence_prob(\"I forgot to take my medicine.\")\n",
    "get_sentence_prob(\"I forgot to take my medicines.\")\n",
    "get_sentence_prob(\"I forgot to take my medication.\")\n",
    "get_sentence_prob(\"I forgot to take my pills.\")\n",
    "print(\"Should have low probs\\n\")\n",
    "get_sentence_prob(\"I forgot to take my turn.\")\n",
    "get_sentence_prob(\"I forgot to take my medical.\")\n",
    "get_sentence_prob(\"I forgot to take my medically.\")\n",
    "get_sentence_prob(\"I forgot to take my turned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:transformers]",
   "language": "python",
   "name": "conda-env-transformers-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
